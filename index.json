[{"categories":["中间件"],"content":"Elasticsearch介绍 Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 ","date":"2022-09-03","objectID":"/Elasticsearch-1/:1:0","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"Docker安装Elasticsearch mkdir -p es/data es/plugins vim es/docker-compose.yml docker-compose.yml version:'3'services:elasticsearch:image:elasticsearch:8.4.1ports:- \"9200:9200\"- \"9300:9300\"environment:- \"discovery.type=single-node\"- \"ES_JAVA_OPTS=-Xms64m -Xmx512m\"- \"HTTP_HOST=0.0.0.0\"volumes:- ./data:/usr/share/elasticsearch/data:rw- ./plugins:/usr/share/elasticsearch/pluginskibana:image:kibana:8.4.1ports:- \"5601:5601\"# 本处用户名密码之后获取重新填写，注意不能使用elasticsearch账号# environment:# - \"ELASTICSEARCH_USERNAME=kibana\"# - \"ELASTICSEARCH_PASSWORD=A4xbHdr20mgbcAkENhlA\"depends_on:- elasticsearch cd es docker-compose up -d docker exec -it es-elasticsearch-1 bin/elasticsearch-setup-passwords auto 该步骤是为每个账户随机生成密码，效果如下（elasticsearch-setup-passwords 在 8.0 版本被弃用，以后将被删除） ****************************************************************************** Note: The 'elasticsearch-setup-passwords' tool has been deprecated. This command will be removed in a future release. ****************************************************************************** Initiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user. The passwords will be randomly generated and printed to the console. Please confirm that you would like to continue [y/N]y Changed password for user apm_system PASSWORD apm_system = FloDE5YBuURSV0kc3fIk Changed password for user kibana_system PASSWORD kibana_system = A4xbHdr20mgbcAkENhlA Changed password for user kibana # 用于kibana组件获取相关信息用于web展示 PASSWORD kibana = A4xbHdr20mgbcAkENhlA Changed password for user logstash_system PASSWORD logstash_system = ry05C9RmhGvWALhtIYEE Changed password for user beats_system PASSWORD beats_system = 8XfsSkR3pz8H0IHgDGoJ Changed password for user remote_monitoring_user PASSWORD remote_monitoring_user = B79ufRafdqS4gisw32IF Changed password for user elastic # 超级管理员，拥有所有权限 PASSWORD elastic = RUikbaL7AvegIbk4xC4j 接着浏览器访问http://127.0.0.1:9200以及http://127.0.0.1:5601，输入上一步获取到的 elastic 账号密码即可访问 ","date":"2022-09-03","objectID":"/Elasticsearch-1/:2:0","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"使用Elasticsearch API 本文使用 Elasticsearch 8.4.1 版本，而 ES8 已去除 type，默认身份验证 ","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:0","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"_cat GET /_cat/nodes 查看所有节点 GET /_cat/health 查看 ES 健康状况 GET /_cat/master 查看主节点 GET /_cat/indices 查看所有索引 ","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:1","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"文档 索引文档 接口 PUT /\u003ctarget\u003e/_doc/\u003c_id\u003e POST /\u003ctarget\u003e/_doc/ PUT /\u003ctarget\u003e/_create/\u003c_id\u003e POST /\u003ctarget\u003e/_create/\u003c_id\u003e 路径参数： \u003ctarget\u003e（必填，字符串）目标数据流或索引的名称。 如果目标不存在且与数据流模板不匹配，则此请求将创建索引。 \u003c_id\u003e（可选，字符串）文档的唯一标识符。 使用POST /\u003ctarget\u003e/_doc/将自动生成文档 ID 请求正文：\u003cfield\u003e（必填，字符串）包含文档数据的 JSON 源。 PUT用于新建文档 POST用于更新文档 实例 POST /test/_doc 请求正文： { \"name\": \"sukun\" } 响应：201 { \"_index\": \"test\", //文档添加到的索引的名称 \"_id\": \"sTOACIMByqhncvtAVIy1\", //添加的文档的唯一标识符 \"_version\": 1, //文档版本。每次更新文档时递增 \"result\": \"created\", //索引操作的结果，created或updated \"_shards\": { //提供有关索引操作的复制过程的信息 \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 0, //序列号，用于开放式并发控制 \"_primary_term\": 1 //主项，用于开放式并发控制 } PUT /test/_doc/sTOACIMByqhncvtAVIy1 请求正文： { \"name\": \"test\" } 响应：200 { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\", \"_version\": 2, \"result\": \"updated\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 1, \"_primary_term\": 1 } 查询文档 接口 GET \u003cindex\u003e/_doc/\u003c_id\u003e HEAD \u003cindex\u003e/_doc/\u003c_id\u003e GET \u003cindex\u003e/_source/\u003c_id\u003e HEAD \u003cindex\u003e/_source/\u003c_id\u003e 路径参数： \u003cindex\u003e（必填，字符串）包含文档的索引的名称。 \u003c_id\u003e（必填，字符串）文档的唯一标识符。 使用GET从特定索引中检索文档及其源或存储的字段。 使用HEAD验证文档是否存在。 使用_source仅检索文档源或验证它是否存在。 实例 GET \u003cindex\u003e/_doc/\u003c_id\u003e响应：200 { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\", \"_version\": 2, \"_seq_no\": 1, \"_primary_term\": 1, \"found\": true, //指示文档是否存在，true或false \"_source\": { //found为true，包含文档数据；_source为false或查询参数stored_fields为true，则排除。 \"name\": \"test\" } } HEAD \u003cindex\u003e/_doc/\u003c_id\u003e响应：200 GET \u003cindex\u003e/_source/\u003c_id\u003e响应：200 { \"name\": \"test\" } HEAD \u003cindex\u003e/_source/\u003c_id\u003e响应：200 开放式并发操作 实现 使用乐观锁 为确保较旧版本的文档不会覆盖较新版本，对文档执行的每个操作都由协调该更改的主分片分配一个序列号。 序列号随着每个操作的增加而增加，因此较新的操作保证具有比旧操作更高的序列号。 然后，Elasticsearch 可以使用操作的序列号来确保较新的文档版本永远不会被分配了较小序列号的更改所覆盖。 Elasticsearch 会跟踪上次操作的序列号和主项，以更改其存储的每个文档。 序列号和主项：_seq_no _primary_term 在索引、更新、删除文档时，使用查询参数if_seq_no if_primary_term可以确保仅在检索文档后未对其进行任何其他更改时才更改文档。 实例 PUT /test/_doc/sTOACIMByqhncvtAVIy1?if_seq_no=1\u0026if_primary_term=1 请求正文： { \"name\": \"sukun\" } 响应：200 { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\", \"_version\": 3, \"result\": \"updated\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 2, \"_primary_term\": 1 } 紧接着再次执行相同操作（模拟并发） PUT /test/_doc/sTOACIMByqhncvtAVIy1?if_seq_no=1\u0026if_primary_term=1 请求正文： { \"name\": \"sukun\" } 响应：409 { \"error\": { \"root_cause\": [ { \"type\": \"version_conflict_engine_exception\", \"reason\": \"[sTOACIMByqhncvtAVIy1]: version conflict, required seqNo [1], primary term [1]. current document has seqNo [2] and primary term [1]\", \"index_uuid\": \"4yncACgnS0CVAWh0hz-LKA\", \"shard\": \"0\", \"index\": \"test\" } ], \"type\": \"version_conflict_engine_exception\", \"reason\": \"[sTOACIMByqhncvtAVIy1]: version conflict, required seqNo [1], primary term [1]. current document has seqNo [2] and primary term [1]\", \"index_uuid\": \"4yncACgnS0CVAWh0hz-LKA\", \"shard\": \"0\", \"index\": \"test\" }, \"status\": 409 } 更新文档 接口 POST /\u003cindex\u003e/_update/\u003c_id\u003e 路径参数： \u003cindex\u003e（必填，字符串）目标索引的名称。默认情况下，如果索引不存在，则会自动创建索引。 \u003c_id\u003e（必填，字符串）要更新的文档的唯一标识符。 作用：用于编写文档更新脚本。该脚本可以更新、删除或跳过修改文档，还支持传递部分文档，该部分文档合并到现有文档中。（若要完全替换现有文档，请使用索引 API） 过程： 从索引中获取文档（与分片并置）。 运行指定的脚本。 为结果编制索引。 实例 更新部分文档 POST /test/_update/sTOACIMByqhncvtAVIy1 请求正文： { \"doc\": { \"new_name\": \"new_name\" } } 响应：200 { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\", \"_version\": 4, \"result\": \"updated\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 3, \"_primary_term\": 1 } 再次查询该文档： { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\", \"_version\": 4, \"_seq_no\": 3, \"_primary_term\": 1, \"found\": true, \"_source\": { \"name\": \"sukun\", \"new_name\": \"new_name\" } } 检测noop更新 再次执行上述更新操作，响应：200 { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\", \"_version\": 4, \"result\": \"noop\", // 如果没设置在请求正文中设置\"detect_noop\": false，不更改任何内容的更新会返回no operation \"_shards\": { \"total\": 0, \"successful\": 0, \"failed\": 0 }, \"_seq_no\": 3, \"_primary_term\": 1 } 删除文档\u0026索引 接口 DELETE /\u003cindex\u003e 路径参数： \u003cindex\u003e（必填，字符串）要删除的以逗号分隔的索引列表。不能用索引别名，默认不支持通配符。 DELETE /\u003cindex\u003e/_doc/\u003c_id\u003e 路径参数： \u003cindex\u003e（必填，字符串）目标索引的名称。 \u003c_id\u003e（必填，字符串）文档的唯一标识符。 实例 DELETE /test/_doc/sTOACIMByqhncvtAVIy1 响应：200 { \"_index\": \"test\", \"_id\": \"sTOACIMByqhncvtAVIy1\",","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:2","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"Search API 首先导入官网测试数据：https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip 接口 GET /\u003ctarget\u003e/_search GET /test/_search POST /\u003ctarget\u003e/_search POST /_search 路径参数： \u003ctarget\u003e（可选，字符串）要搜索的数据流、索引和别名的逗号分隔列表。支持通配符*。要搜索所有数据流和索引，请省略此参数或使用* 或_all 可以使用查询参数或请求正文参数指定此 API 的多个选项。如果同时指定了这两个参数，则仅使用查询参数。 实例 GET /test/_search?from=40\u0026size=20\u0026sort=account_number:asc 响应：200 { \"took\": 1, //（整数）Elasticsearch执行请求需要几毫秒 \"timed_out\": false, //布尔值）如果为true，则请求在完成之前超时;返回的结果可以是部分结果，也可以是空的 \"_shards\": { //（对象）包含用于请求的分片计数 \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { //（对象）包含返回的文档和元数据 \"total\": { //（对象）有关匹配文档数的元数据 \"value\": 1000, //（整数）匹配文档的总数 \"relation\": \"eq\" //（字符串）指示参数中匹配文档的数量是准确eq还是下限get }, \"max_score\": null, //（浮点数）返回次数最高的文档_score。此值适用于不按null _score排序的请求 \"hits\": [ //（对象数组）返回的文档对象的数组。 { \"_index\": \"test\", \"_id\": \"40\", \"_score\": null, //（浮点数）正32位浮点数，用于确定返回文档的相关性 \"_source\": { //（对象）文档正文。使用_source参数从响应中排除此属性，或指定要返回的源字段。 \"account_number\": 40, \"balance\": 33882, \"firstname\": \"Pace\", \"lastname\": \"Molina\", \"age\": 40, \"gender\": \"M\", \"address\": \"263 Ovington Court\", \"employer\": \"Cytrak\", \"email\": \"pacemolina@cytrak.com\", \"city\": \"Silkworth\", \"state\": \"OR\" }, \"sort\": [ 40 ] }, { \"_index\": \"test\", \"_id\": \"41\", \"_score\": null, \"_source\": { \"account_number\": 41, \"balance\": 36060, \"firstname\": \"Hancock\", \"lastname\": \"Holden\", \"age\": 20, \"gender\": \"M\", \"address\": \"625 Gaylord Drive\", \"employer\": \"Poochies\", \"email\": \"hancockholden@poochies.com\", \"city\": \"Alamo\", \"state\": \"KS\" }, \"sort\": [ 41 ] }, { \"_index\": \"test\", \"_id\": \"42\", \"_score\": null, \"_source\": { \"account_number\": 42, \"balance\": 21137, \"firstname\": \"Harding\", \"lastname\": \"Hobbs\", \"age\": 26, \"gender\": \"F\", \"address\": \"474 Ridgewood Place\", \"employer\": \"Xth\", \"email\": \"hardinghobbs@xth.com\", \"city\": \"Heil\", \"state\": \"ND\" }, \"sort\": [ 42 ] }, { \"_index\": \"test\", \"_id\": \"43\", \"_score\": null, \"_source\": { \"account_number\": 43, \"balance\": 33474, \"firstname\": \"Ryan\", \"lastname\": \"Howe\", \"age\": 25, \"gender\": \"M\", \"address\": \"660 Huntington Street\", \"employer\": \"Microluxe\", \"email\": \"ryanhowe@microluxe.com\", \"city\": \"Clara\", \"state\": \"CT\" }, \"sort\": [ 43 ] }, { \"_index\": \"test\", \"_id\": \"44\", \"_score\": null, \"_source\": { \"account_number\": 44, \"balance\": 34487, \"firstname\": \"Aurelia\", \"lastname\": \"Harding\", \"age\": 37, \"gender\": \"M\", \"address\": \"502 Baycliff Terrace\", \"employer\": \"Orbalix\", \"email\": \"aureliaharding@orbalix.com\", \"city\": \"Yardville\", \"state\": \"DE\" }, \"sort\": [ 44 ] } ] } } POST /test/_search 请求正文 { \"query\": { \"range\": { \"balance\": { \"gte\": 30000, \"lte\": 30500 } } }, \"sort\": { \"account_number\": \"asc\" } } 响应：200 { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 6, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [ { \"_index\": \"test\", \"_id\": \"31\", \"_score\": null, \"_source\": { \"account_number\": 31, \"balance\": 30443, \"firstname\": \"Kristen\", \"lastname\": \"Santana\", \"age\": 22, \"gender\": \"F\", \"address\": \"130 Middagh Street\", \"employer\": \"Dogspa\", \"email\": \"kristensantana@dogspa.com\", \"city\": \"Vale\", \"state\": \"MA\" }, \"sort\": [ 31 ] }, { \"_index\": \"test\", \"_id\": \"262\", \"_score\": null, \"_source\": { \"account_number\": 262, \"balance\": 30289, \"firstname\": \"Tameka\", \"lastname\": \"Levine\", \"age\": 36, \"gender\": \"F\", \"address\": \"815 Atlantic Avenue\", \"employer\": \"Acium\", \"email\": \"tamekalevine@acium.com\", \"city\": \"Winchester\", \"state\": \"SD\" }, \"sort\": [ 262 ] }, { \"_index\": \"test\", \"_id\": \"513\", \"_score\": null, \"_source\": { \"account_number\": 513, \"balance\": 30040, \"firstname\": \"Maryellen\", \"lastname\": \"Rose\", \"age\": 37, \"gender\": \"F\", \"address\": \"428 Durland Place\", \"employer\": \"Waterbaby\", \"email\": \"maryellenrose@waterbaby.com\", \"city\": \"Kiskimere\", \"state\": \"RI\" }, \"sort\": [ 513 ] }, { \"_index\": \"test\", \"_id\": \"514\", \"_score\": null, \"_source\": { \"account_number\": 514, \"balance\": 30125, \"firstname\": \"Solomon\", \"lastname\": \"Bush\", \"age\": 34, \"gender\": \"M\", \"address\": \"409 Harkness Avenue\", \"employer\": \"Snacktion\", ","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:3","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"Query DSL 在上述 Search API 中 query 参数使用查询 DSL 定义。 Elasticsearch 提供了基于 JSON 的完整查询 DSL（域特定语言）来定义查询。将查询 DSL 视为查询的 AST（抽象语法树），由两种类型的子句组成： 叶查询子句 叶查询子句在特定字段中查找特定值，例如匹配项、术语或范围查询。这些查询可以单独使用。 复合查询子句 复合查询子句包装其他叶查询或复合查询，用于以逻辑方式组合多个查询（如 bool 或 dis_max 查询），或更改其行为（如constant_score查询）。 查询子句的行为有所不同，具体取决于它们是在查询上下文还是在筛选器上下文中使用。 查询和筛选器上下文 GET /test/_search 请求正文 { \"_source\": [ \"balance\", \"age\", \"state\" ], \"query\": { //指示查询上下文 \"bool\": { //bool和match意味着这将用于对每个文档的匹配程度进行评分 \"must\": { //必须出现在匹配的文档中，并有助于分数。 \"match\": { \"state\": \"NM\" //state字段包含NM } }, \"must_not\": { //不得出现在匹配的文档中 \"range\":{ \"age\": { \"gte\": 30 //age字段大于30 } } }, \"filter\": { //筛指示选器上下文。筛选出不匹配的文档，但不会影响匹配文档的分数。 \"range\": { \"balance\": { \"lte\": \"30000\" //balance字段小于于30000 } } } } } } 响应：200 { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 3, \"relation\": \"eq\" }, \"max_score\": 4.2346063, \"hits\": [ { \"_index\": \"test\", \"_id\": \"688\", \"_score\": 4.2346063, \"_source\": { \"balance\": 17931, \"state\": \"NM\", \"age\": 22 } }, { \"_index\": \"test\", \"_id\": \"942\", \"_score\": 4.2346063, \"_source\": { \"balance\": 21299, \"state\": \"NM\", \"age\": 26 } }, { \"_index\": \"test\", \"_id\": \"375\", \"_score\": 4.2346063, \"_source\": { \"balance\": 23860, \"state\": \"NM\", \"age\": 25 } } ] } } match 用于执行全文搜索的标准查询，包括模糊匹配选项 全文检索，根据评分排序，会进行分词匹配 GET /test/_search 请求实体 { \"query\": { \"match\": { \"address\": { //\u003cfield\u003e（必需，对象）要搜索的字段 \"query\": \"mill lane\", //（必填）您希望在提供的\u003cfield\u003e中找到的文本、数字、布尔值或日期 \"fuzziness\": \"AUTO\" //（可选，字符串）模糊查询，允许匹配的最大距离。 } } } } 响应：200 { \"took\": 4, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 27, \"relation\": \"eq\" }, \"max_score\": 9.507477, \"hits\": [ { \"_index\": \"test\", \"_id\": \"136\", \"_score\": 9.507477, \"_source\": { \"account_number\": 136, \"balance\": 45801, \"firstname\": \"Winnie\", \"lastname\": \"Holland\", \"age\": 38, \"gender\": \"M\", \"address\": \"198 Mill Lane\", \"employer\": \"Neteria\", \"email\": \"winnieholland@neteria.com\", \"city\": \"Urie\", \"state\": \"IL\" } }, { \"_index\": \"test\", \"_id\": \"970\", \"_score\": 5.4032025, \"_source\": { \"account_number\": 970, \"balance\": 19648, \"firstname\": \"Forbes\", \"lastname\": \"Wallace\", \"age\": 28, \"gender\": \"M\", \"address\": \"990 Mill Road\", \"employer\": \"Pheast\", \"email\": \"forbeswallace@pheast.com\", \"city\": \"Lopezo\", \"state\": \"AK\" } }, { \"_index\": \"test\", \"_id\": \"345\", \"_score\": 5.4032025, \"_source\": { \"account_number\": 345, \"balance\": 9812, \"firstname\": \"Parker\", \"lastname\": \"Hines\", \"age\": 38, \"gender\": \"M\", \"address\": \"715 Mill Avenue\", \"employer\": \"Baluba\", \"email\": \"parkerhines@baluba.com\", \"city\": \"Blackgum\", \"state\": \"KY\" } }, { \"_index\": \"test\", \"_id\": \"472\", \"_score\": 5.4032025, \"_source\": { \"account_number\": 472, \"balance\": 25571, \"firstname\": \"Lee\", \"lastname\": \"Long\", \"age\": 32, \"gender\": \"F\", \"address\": \"288 Mill Street\", \"employer\": \"Comverges\", \"email\": \"leelong@comverges.com\", \"city\": \"Movico\", \"state\": \"MT\" } }, { \"_index\": \"test\", \"_id\": \"1\", \"_score\": 4.1042743, \"_source\": { \"account_number\": 1, \"balance\": 39225, \"firstname\": \"Amber\", \"lastname\": \"Duke\", \"age\": 32, \"gender\": \"M\", \"address\": \"880 Holmes Lane\", \"employer\": \"Pyrami\", \"email\": \"amberduke@pyrami.com\", \"city\": \"Brogan\", \"state\": \"IL\" } }, { \"_index\": \"test\", \"_id\": \"70\", \"_score\": 4.1042743, \"_source\": { \"account_number\": 70, \"balance\": 38172, \"firstname\": \"Deidre\", \"lastname\": \"Thompson\", \"age\": 33, \"gender\": \"F\", \"address\": \"685 School Lane\", \"employer\": \"Netplode\", \"email\": \"deidrethompson@netplode.com\", \"city\": \"Chestnut\", \"state\": \"GA\" } }, { \"_index\": \"test\", \"_id\": \"556\", \"_score\": 4.1042743, \"_source\": { \"account_number\": 556, \"balance\": 36420, \"firstname\": \"Collier\", \"lastname\": \"Odonnell\", \"age\": 35, \"gender\": \"M\", \"address\": \"591 Nolans Lane\", \"employer\": \"Sultraxin\", \"email\": \"collierodonnell@sultraxin.com\", \"city\": \"Fulford\", \"state\": \"MD\" } }, { \"_index\": \"test\", \"_id\": \"568\", \"_score\": 4.1042743, \"_source\": { \"account_number\": 568, \"balance\": 36628, \"firstname\": \"Lesa\", \"lastname\": \"Ma","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:4","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"Mapping 映射是定义文档及其包含的字段的存储和索引方式的过程。 每个文档都是字段的集合，每个字段都有自己的数据类型。映射数据时，将创建一个映射定义，其中包含与文档相关的字段列表。映射定义还包括元数据字段（如_source字段），这些字段自定义如何处理文档的关联元数据。 使用动态映射和显式映射来定义数据。每种方法都根据您在数据旅程中所处的位置提供不同的优势。例如，将不想使用默认值的字段显式映射，或者更好地控制创建哪些字段。然后，您可以允许弹性搜索动态添加其他字段。 注意：ES 8 已不再支持映射类型！ 字段类型 常见类型 binary：编码为 Base64 字符串的二进制值。 boolean：true和false值。 关键字：关键字系列，包括keyword、constant_keyword和wildcard 。 数字：数值类型，如long和double，用于表示金额。 日期 日期类型，包括日期和date_nanos。 alias：定义现有字段的别名。 对象和关系类型 object：一个 JSON 对象。 flattened：作为单个字段值的整个 JSON 对象。 nested：保留其子字段之间关系的 JSON 对象。 join：为同一索引中的文档定义父/子关系。 结构化数据类型 范围：范围类型，如long_range、double_range、date_range和ip_range。 ip：互联网地址和 IPv6 地址。 version：软件版本。支持语义版本控制优先规则。 murmur3：计算和存储值的哈希。 聚合数据类型 aggregate_metric_double：预先聚合的指标值。 histogram：直方图形式的预聚合数值。 文本搜索类型 文本字段：文本系列，包括text和match_only_text。经过分析的非结构化文本。 annotated-text：包含特殊标记的文本。用于标识命名实体。 completion：用于自动完成建议。 search_as_you_type：text-like 类型，用于键入完成。 token_count：文本中的标记计数。 文档排名类型 dense_vector：记录浮点值的密集矢量。 rank_feature：记录数字要素以在查询时提高命中率。 rank_features：记录数字特征以在查询时提高命中率。 空间数据类型 geo_point：纬度和经度点。 geo_shape：复杂形状，如多边形。 point：任意笛卡尔点。 shape：任意笛卡尔几何。 其他类型 percolator：索引在查询 DSL 中编写的查询。 映射 ","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:5","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["中间件"],"content":"SQL API","date":"2022-09-03","objectID":"/Elasticsearch-1/:3:6","tags":["Elasticsearch"],"title":"Elasticsearch学习(一)","uri":"/Elasticsearch-1/"},{"categories":["生活"],"content":"2022一年走完，我的收获","date":"2022-06-21","objectID":"/2022%E5%AD%A6%E5%B9%B4%E6%80%BB%E7%BB%93/","tags":["学年总结"],"title":"2022学年总结","uri":"/2022%E5%AD%A6%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"categories":["生活"],"content":" W3C（大概了解，仅处于能看懂的地步） html css js C语言 docker Sockets Nginx 代理（搭梯子） GitHub actions Linux-Ubuntu、Centos（基本使用，指令记不全，现用现查） 多线程 数据结构 Python 爬虫 MongoDB RabbitMQ Flask MySQL Redis JavaSE JavaWeb JDBC Serverlet XML …… ","date":"2022-06-21","objectID":"/2022%E5%AD%A6%E5%B9%B4%E6%80%BB%E7%BB%93/:0:0","tags":["学年总结"],"title":"2022学年总结","uri":"/2022%E5%AD%A6%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"categories":["web"],"content":"讲述了数据库的设计，包括多表之间的关系以及三大数据库范式","date":"2022-05-12","objectID":"/mysql-2/","tags":["mysql"],"title":"MySQL学习(二)","uri":"/mysql-2/"},{"categories":["web"],"content":"MySQL学习(二) ","date":"2022-05-12","objectID":"/mysql-2/:1:0","tags":["mysql"],"title":"MySQL学习(二)","uri":"/mysql-2/"},{"categories":["web"],"content":"数据库的设计 多表之间的关系 分类： 一对一 eg，人与身份证号码 一对多（多对一） eg，员工与部门 多对多 学生与课程 一对多（多对一） emp员工表——1 eid name age emp_dept_fk 1 张三 24 1 2 李四 24 1 3 王五 35 2 dept部门表——n id name 1 财务部 2 销售部 在多的一方建立外键，指向一的一方的主键。 多对多 stu学生表——m sid name age 1 张三 18 2 李四 18 3 王五 19 class课程表——n cid name 1 语文 2 数学 t_stu_class中间表 sid cid 1 1 1 2 3 2 多对多关系实现需要借助第三张中间表。中间表至少包含两个字段，这两个字段作为第三张表的外键，分别指向两张表的主键。 一对一 stu学生表 id name age cid 1 张三 18 1 2 李四 19 2 card身份证表 id number 1 5105242 2 5105241 一对一关系实现，可以在任意―方添加唯―外键指向另一方的主键。 当然，对于一对一关系我们还可以直接合为一张表。 注意事项 在实际开发中，我们应该尽量避免使用外键，而应该利用程序逻辑保证数据的正确性。 数据库范式 设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。 关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。 在日常工作生活中，仅学习前三种范式已经足以应付大多数情况。 本处数据库范式与离散数学中的范式并无直接联系。 第一范式（1NF） 每一列都是不可分割的原子数据项 规范化： 一个低一级的关系模式通过模式分解可以转化为若干个高一级范式的关系模式的集合，这个过程叫做规范化。 而上表显然不满足不可分割的要求，因此不满足第一范式，可改为 第二范式（2NF） 在 1NF 的基础上，非码属性必须完全依赖于候选码（在 1NF 基础上消除非主属性对主码的部分函数依赖） 函数依赖： 设 R(U) 是属性集 U 上的关系模式，X、Y 是 U 的子集。若对于 R(U) 的任意一个可能的关系 r，r 中不可能存在两个元组在 X 上的属性值相等，而在 Y 上的属性值不等，则称 Y 函数依赖于 X 或 X 函数确定 Y。 简单地说，通过 X 属性（属性组）的值，可以确定唯一 Y 属性的值，则称 Y 函数依赖于 X。 例如： 学号 –\u003e 姓名，称姓名函数依赖于学号。 (学号，课程名称) –\u003e 分数，称分数函数依赖于 (学号、课程名称) 。 完全函数依赖： 设 R(U) 是属性集 U 上的关系模式，X、Y 是 U 的子集。如果 Y 函数依赖于 X，且对于 X 的任何一个真子集 X’，都有Y 不函数依赖于 X’，则称 Y 对 X 完全函数依赖。如果 Y 函数依赖于 X，但 Y 不完全函数依赖于 X，则称 Y 对 X 部分函数依赖。 简单地说，X –\u003e Y，如果 X 是一个属性组，则 Y 属性值的确定需要依赖于 X 属性组中所有的属性值。 例如： 学号 -/-\u003e 分数，称分数不函数依赖于学号。 (学号，课程名称) –\u003e 姓名，学号 –\u003e 姓名，称姓名对 (学号、课程名称) 部分函数依赖。 (学号，课程名称) –\u003e 分数，称分数对 (学号、课程名称) 完全函数依赖。 候选码： 若关系中的某一属性组的值能唯一地标识一个元组，而其子集不能，则称该属性组为候选码。若一个关系中有多个候选码，则选定其中一个为主码。 主属性： 所有候选码的属性称为主属性。不包含在任何候选码中的属性称为非主属性或非码属性。 显然，对于上表，(学号，课程名称) 为候选码，分数对其完全函数依赖，但姓名、系名、系主任对其部分函数依赖，因此可分为课程表+学生表： 简单地说，第二范式是指每个表有且仅有一个数据项作为关键字或主键，其他数据项与关键字或者主键一一对应，即其他数据项完全依赖于关键字或主键。由此可知单主属性的关系均属于第二范式。 第三范式（3NF） 在 2NF 基础上，任何非主属性不依赖于其它非主属性（在 2NF 基础上消除传递依赖）。 传递函数依赖： 例如：学号 –\u003e 系名，系名 –\u003e 系主任，称系主任对学号传递函数依赖。 显然，对于上表，系主任依赖于系名，可将学生表进一步分表为学生表+系表，而选课表不变： 对于初始表，其存在以下问题： 存在非常严重的数据冗余：姓名、系名、系主任 数据添加存在问题：添加新开设的系和系主任时，数据不合法 数据删除存在问题：同学毕业了，删除数据，会将系的数据一起删除。 现在，已全部解决！ ","date":"2022-05-12","objectID":"/mysql-2/:1:1","tags":["mysql"],"title":"MySQL学习(二)","uri":"/mysql-2/"},{"categories":["web"],"content":"讲述了Redis入门知识，包括Redis概述、安装、基础知识（五大数据类型及事务）、配置文件解释、Redis持久化","date":"2022-05-07","objectID":"/redis-1/","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"Redis学习(一)——Redis入门 ","date":"2022-05-07","objectID":"/redis-1/:1:0","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"Redis概述 Redis是什么？来自CRUG网站 (redis.cn) Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作==数据库==、==缓存==和==消息中间件MQ==。它支持多种类型的数据结构，如字符串（strings），散列（hashes），列表（lists），集合（sets），有序集合（sortedsets）与范围查询，bitmaps，hyperloglogs和地理空间（geospatial）索引半径查询。Redis 内置了复制（replication），LUA 脚本（Luascripting），LRU驱动事件（LRUeviction），事务（transactions）和不同级别的磁盘持久化（persistence），并通过 Redis 哨兵（Sentinel）和自动分区（Cluster）提供高可用性（highavailability）。 Redis（Remote Dictionary Server），即远程字典服务。 是一个免费开源的使用 ANSl C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-value 数据库，并提供多种语言的 API。 是当下最热门的 NoSQL 技术之一。 Redis能干什么？ 内存存储、持久化，内存中是断电即失、所以说持久化很重要（rdb、aof）效率高，可以用于高速缓存 发布订阅系统 地图信息分析 计时器、计数器（浏览量） 特效 多样的数据类型 持久化 集群事务 ","date":"2022-05-07","objectID":"/redis-1/:1:1","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"Redis安装 我这里采用最为便捷的方法——docker 容器启动。 我们可以前往 Redis 中文官网下载压缩包，解压取得配置文件：redis 6.0.6 下载 – Redis中国用户组（CRUG） 然后你需要修改配置文件的部分内容： bind 127.0.0.1 注释掉这部分，使 redis 可以从外部访问 daemonize yes守护线程的方式启动 requirepass 密码给 redis 设置密码 appendonly yesredis持久化，默认是 no tcp-keepalive 300 防止出现远程主机强迫关闭了一个现有的连接的错误，默认是 300 依然是给出 shell 和 docker-compose 两种启动，注意修改配置： shell docker run -itd --name redis -h redis -p 6379:6379 -v /root/redis/redis.conf:/etc/redis/redis.conf -v /root/redis/data:/data redis redis-server /etc/redis/redis.conf --appendonly yes docker-compose.yml version:\"3\"services:db:image:rediscontainer_name:redisstdin_open:truetty:trueports:- \"6379:6379\"volumes:- /root/redis/redis.conf:/etc/redis/redis.conf- /root/redis/data:/datacommand:redis-server /etc/redis/redis.conf --appendonly yesrestart:alwayshostname:redis ","date":"2022-05-07","objectID":"/redis-1/:1:2","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"基础知识 执行以下命令进入 Redis 命令行工具： docker exec -it redis bash cd /usr/local/bin redis-cli Redis 默认有 16 个数据库（0-15），默认使用数据库 0 即第一个数据库，select切换数据库。 flushdb清空当前数据库，flushall 清空所有数据库。 Redis6.0多线程 Redis 6.0 开始支持多线程，Redis 分主线程和 IO 线程，IO 线程只用于读取客户端命令和发送回复数据给客户端，客户端命令依旧是由主线程来执行。 为什么要使用多线程呢？ Redis 将所有数据放在内存中，内存的响应速度在纳秒级别，对于小数据包，Redis服务器可以处理 80,000到 100,000 QPS，所以大多数情况下，单线程的 Redis 足够了。并且多线程的 CPU 上下文会切换是一个耗时的操作，对于内存系统来说，如果没有上下文切换效率就是最高的！多次读写都是在一个 CPU 上的，在内存情况下，这个就是最佳的方案。 但是 Redis 从自身的角度来说，因为读写网络的 read/write 系统调用占用了 Redis 执行期间大部分 CPU 时间，瓶颈主要在于网络 IO 消耗，网络 IO 主要延时由服务器响应延时+带宽限制+网络延时+跳转路由延时组成，其一般在毫秒级别。 多线程 Redis 主要为了利用多核 CPU，目前主线程只能利用一个核，多线程任务可以分摊 Redis 同步 IO 读写的负荷。 Redis6.0多线程开启方法 要开启 Redis 的IO线程功能，需要修改 redis.conf 配置文件： io-threads-do-reads yes # 开启IO线程 io-threads 6 # 设置IO线程数 线程数的设置，官方建议：4 核的设置 2 或 3 个线程，8 核的建议设置 6 个线程，线程数一定要小于机器核数，线程数并不是越大越好，官方认为超过 8 个基本没什么意义了。 五大数据类型 Redis-Key 所有命令都可以在官网查询：Redis命令中心（Redis commands） – Redis中国用户组（CRUG） 127.0.0.1:6379\u003e SELECT 1 OK 127.0.0.1:6379[1]\u003e SET name su OK 127.0.0.1:6379[1]\u003e MOVE name 0 # 移动name到数据库0 (integer) 1 127.0.0.1:6379[1]\u003e SELECT 0 OK 127.0.0.1:6379\u003e TYPE name # 查看name的类型 string 127.0.0.1:6379\u003e EXPIRE name 10 # 设置name过期时间10秒 (integer) 1 127.0.0.1:6379\u003e TTL name # 查看name剩余时间 (integer) 7 127.0.0.1:6379\u003e TTL name (integer) -2 # -1表示永久，-2表示过期 127.0.0.1:6379\u003e FLUSHDB # 清空当前数据库 OK String（字符串） 127.0.0.1:6379\u003e SET name su # 设置值set key value OK 127.0.0.1:6379\u003e GET name # 获得值 \"su\" 127.0.0.1:6379\u003e KEYS * # 获得所有的key 1) \"name\" 127.0.0.1:6379\u003e EXISTS name # 判断某一个key是否存在 (integer) 1 127.0.0.1:6379\u003e APPEND name \"kun\" # 追加字符串，如果当前key不存在，就相当于set key value (integer) 5 127.0.0.1:6379\u003e STRLEN name # 获取字符串的长度 (integer) 5 ######################################################################################################## # 自增、自减 127.0.0.1:6379\u003e SET views 0 OK 127.0.0.1:6379\u003e INCR views # 自增1 (integer) 1 127.0.0.1:6379\u003e DECR views # 自减1 (integer) 0 127.0.0.1:6379\u003e INCRBY views 10 # 设置步长，指定增量 (integer) 10 127.0.0.1:6379\u003e FLUSHDB OK ######################################################################################################## # 字符串范围 127.0.0.1:6379\u003e SET name \"hello world\" OK 127.0.0.1:6379\u003e GET name \"hello world\" 127.0.0.1:6379\u003e GETRANGE name 0 4 # 截取字符串[0,4]，正索引，从第一个字符开始到第五个字符 \"hello\" 127.0.0.1:6379\u003e GETRANGE name 0 -1 # -1为倒索引，从第一个字符到最后一个字符 \"hello world\" 127.0.0.1:6379\u003e SETRANGE name 6 sukun # 替换指定位置开始的字符串 (integer) 11 127.0.0.1:6379\u003e GET name \"hello sukun\" 127.0.0.1:6379\u003e FLUSHDB OK ######################################################################################################## # setex (set with expire) # setnx (set if not exists) 127.0.0.1:6379\u003e SETEX name 10 su # 设置name值su，10秒后过期 OK 127.0.0.1:6379\u003e TTL name (integer) 7 127.0.0.1:6379\u003e TTL name (integer) -2 127.0.0.1:6379\u003e SETNX name sukun # 如果name不存在，则设置name值sukun (integer) 1 # 成功返回1 127.0.0.1:6379\u003e SETNX name kun (integer) 0 # 失败返回0 127.0.0.1:6379\u003e FLUSHDB OK ######################################################################################################## 127.0.0.1:6379\u003e MSET k1 v1 k2 v2 k3 v3 # 同时设置多个值 OK 127.0.0.1:6379\u003e KEYS * 1) \"k3\" 2) \"k2\" 3) \"k1\" 127.0.0.1:6379\u003e MGET k1 k2 k3 # 同时获取多个值 1) \"v1\" 2) \"v2\" 3) \"v3\" 127.0.0.1:6379\u003e MSETNX k1 v1 k4 v4 # 原子性操作，要么一起成功，要么一起失败 (integer) 0 127.0.0.1:6379\u003e GET k4 (nil) 127.0.0.1:6379\u003e SET user:1 {name:sukun,age:18} # 设置一个user:1对象，值为json字符串 OK 127.0.0.1:6379\u003e GET user:1 \"{name:sukun,age:18}\" 127.0.0.1:6379\u003e MSET user:1:name sukun user:1:age 18 # 利用:区分层级，实现user:{id}:{filed} OK 127.0.0.1:6379\u003e MGET user:1:name user:1:age 1) \"sukun\" 2) \"18\" ######################################################################################################## # getset 先get再set 127.0.0.1:6379\u003e GETSET db redis # 如果不存在值，返回nil (nil) 127.0.0.1:6379\u003e GET db \"redis\" 127.0.0.1:6379\u003e GETSET db mongodb # 如果存在值，获取原来的值，再设置新值 \"redis\" 127.0.0.1:6379\u003e GET db \"mongodb\" String 使用场景：value 除了字符串还可以是数字 计数器 统计多单位数量 对象缓存存储 List 基本数据类型：列表，但在 Redis 也可以为队列、阻塞队列、栈。 所有 List 的命令都是 L 开头： 127.0.0.1:6379\u003e LPUSH list 1 # 将一个值或多个值，从左边插入列表 (integer) 1 127.","date":"2022-05-07","objectID":"/redis-1/:1:3","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"Redis.conf解释 完整的配置文件之前已经提供，内有完整注释，请自行查阅！ units 单位对大小写不敏感 配置文件可用include包含 网络 bind 127.0.0.1 # 绑定IP protected-mode yes # 开启保护模式 port 6379 # 端口设置 通用 daemonize yes # 守护线程的方式启动 pidfile # 如果以后台的方式运行，需要指定一个进程文件 loglevel notice # 日志等级 logfile '' # 指定日志文件 databases 16 # 数据库数量默认16 always-show-logo yes # 启动时输出redis的logo 快照 持久化，在规定的时间内，执行了多少次操作，则会持久化到文件 .rdb .aof。 由于 Redis 是内存数据库，如果没有持久化，那么数据断电即失！ save 900 1 # 如果900s内，如果至少有一个1 key进行了修改，则进行持久化操作 stop-writes-on-bgsave-error no # 持久化如果出错，仍继续工作 rdbcompression yes # 是否压缩rdb文件（需要消耗一些cpu资源） rdbchecksum yes # 保存rdb文件时进行错误校验 dir ./ # rdb文件目录 安全 127.0.0.1:6379\u003e config get requirepass #获取redis的密码 1) \"requirepass\" 2) \"\" 127.0.0.1:6379\u003e config set requirepass \"123456\" #设置redis的密码 OK 127.0.0.1:6379\u003e ping # 没有权限 (error) NOAUTH Authentication required. 127.0.0.1:6379\u003e auth 123456 #使用密码进行登录! OK 限制 CLIENTS maxclients 10000 #设置能连接上redis的最大客户端的数量 maxmemory \u003cbytes\u003e # redis配置最大的内存容量 maxmemory-policy noeviction # 内存到达上限之后的处理策略 1、volatile-lru: 只对设置了过期时间的key进行LRU（默认值) 2、allkeys-lru: 删除1ru算法的key 3、volatile-random: 随机删除即将过期key 4、allkeys-random: 随机删除 5、volatile-ttl: 删除即将过期的 6、noeviction: 永不过期，返回错误 APPEND ONLY 模式 aof 配置 appendon1y no # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用 appendfilename \"appendon1y.aof\" # 持久化的文件的名字 # appendfsync always # 每次修改都会sync消耗性能 appendfsync everysec # 每秒执行一次 # appendfsync no # 不执行sync，这个时候操作系统自己同步数据，速度最快 ","date":"2022-05-07","objectID":"/redis-1/:1:4","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"Redis持久化 Redis 是内存数据库，如果不将内存中的数据库状态保存到磁盘，一旦服务器进程退出，服务器中的数据库状态也会消失。所以 Redis 提供了持久化功能。 RDB(Redis DataBase) 在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的 Snapshot 快照，它恢复时是将快照文件直接读到内存里。 Redis 会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 IO 操作的。这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。RDB 的缺点是最后一次持久化后的数据可能丢失。 默认 RDB，一般情况不需要修改配置。 生产环境中需进行备份。 RDB 保存的文件是 dump.rdb dbfilename dump.rdb 触发机制： save 规则满足的情况下，触发 rdb 规则 执行 flushall 命令，触发 rdb 规则 退出 redis ，也会产生 rdb 文件 备份就自动生成一个 dump.rdb 文件 只需要将 rdb 文件放在 redis 启动目录，redis 启动的时候会自动检查 dump.rdb 并恢复数据。 优点∶ 适合大规模的数据恢复 对数据的完整性要不高 缺点︰ 需要一定的时间间隔进程操作！如果 redis 意外宕机了，这个最后一次修改数据就丢失了！ fork 进程的时候，会占用一定的内容空间！ AOF(Append Only File) 以日志的形式来记录每个写操作，将 Redis 执行过的所有指令记录下来(读操作不记录），只许追加文件但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 AOF 保存的是 appendonly.aof 文件。 appendon1y no # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用 appendfilename \"appendon1y.aof\" # 持久化的文件的名字 # appendfsync always # 每次修改都会sync消耗性能 appendfsync everysec # 每秒执行一次 # appendfsync no # 不执行sync，这个时候操作系统自己同步数据，速度最快 重启之后 aof 即可生效 如果 aof 文件错位，redis 无法启动，需要使用redis-check-aof来修复。 如果 aof 文件正常，重启 redis 即可恢复数据。 优点： 每一次修改都同步，文件的完整性会更加好 每秒同步一次，可能会丢失—秒的数据 从不同步，效率最高 缺点： 相对于数据文件来说，aof 远远大于 rdb，修复的速度也比 rdb 慢 aof 运行效率也要比 rdb 慢，所以 redis 默认的配置就是 rdb 持久化 重写规则说明： aof 默认就是文件的无限追加，文件会越来越大。 如果 aof 文件大于 64m，太大了会 fork 一个新的进程来对文件进行重写。 扩展知识 RDB 持久化方式能够在指定的时间间隔内对你的数据进行快照存储 AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF 命令以 Redis 协自加保存每次写的操作到文件末尾，Redis 还能对 AOF 文件进行后台重写，使得 AOF 文件的体积不至于过大。 只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化 同时开启两种持久化方式 在这种情况下，当 redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比RDB 文件保存的数据集要完整。 RDB 的数据不实时，同时使用两者时服务器重启也只会找 AOF 文件，建议不要只使用 AOF，因为 RDB 更适合用于备份数据库（AOF 在不断变化不好备份），快速重启，而且不会有 AOF 可能潜在的 Bug，留着作为一个万一的手段。 性能建议 因为 RDB 文件只用作后备用途，建议只在 Slave 上持久化 RDB 文件，而且只要 15 分钟备份一次就够了，只保留save 900 1这条规则。 如果 Enable AOF ，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只 load 自己的 AOF 文件就可以了，代价一是带来了持续的 lO ，二是 AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少 AOF rewrite 的频率，AOF 重写的基础大小默认值 64M 太小了，可以设到 5G 以上，默认超过原大小 100% 大小重写可以改到适当的数值。 如果不 Enable AOF，仅靠 Master-Slave Repllcation 实现高可用性也可以，能省掉一大笔 IO，也减少了 rewrite 时带来的系统波动。代价是如果 Master/Slave 同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个 Master/Slave 中的 RDB 文件，载入较新的那个，微博就是这种架构。 ","date":"2022-05-07","objectID":"/redis-1/:1:5","tags":["redis"],"title":"Redis学习(一)","uri":"/redis-1/"},{"categories":["web"],"content":"讲述了什么是sql以及什么是mysql，并介绍了mysql安装方法，进一步讲解mysql使用包括sql通用语法和约束","date":"2022-04-30","objectID":"/mysql-1/","tags":["mysql"],"title":"MySQL学习(一)","uri":"/mysql-1/"},{"categories":["web"],"content":"MySQL学习(一) ","date":"2022-04-30","objectID":"/mysql-1/:1:0","tags":["mysql"],"title":"MySQL学习(一)","uri":"/mysql-1/"},{"categories":["web"],"content":"什么是SQL Structured Query Language：结构化查询语言——定义了操作所有关系型数据库的规则。 以下是当前数据库 TOP10 所对应的数据库类型。 Rank DBMS Database Model Score 1 Oracle Relational 1254.82 2 MySQL Relational 1204.16 3 Microsoft SQL Server Relational 938.46 4 PostgreSQL Relational 614.46 5 MongoDB Document 483.38 6 Redis Key-value 177.61 7 Elasticsearch Search engine 160.83 8 IBM Db2 Relational 160.46 9 Microsoft Access Relational 142.78 10 SQLite Relational 132.80 以上数据来自来自于 DB-Engines 发布的 DB-Engines Ranking of database management systems, April 2022 我们发现其中大部分都是关系型数据库，也就是说，我们既可以用 SQL 操作 MySQL，也可以用其操作 Oracle。当然，对于不同的数据库，SQL 语句有细微差异，我们称其为方言。 ","date":"2022-04-30","objectID":"/mysql-1/:1:1","tags":["mysql"],"title":"MySQL学习(一)","uri":"/mysql-1/"},{"categories":["web"],"content":"什么是MySQL MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL 是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件。MySQL 软件采用了双授权政策，分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。 MySQL 所使用的 SQL 语言是用于访问数据库的最常用标准化语言。 MySQL 将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。 ","date":"2022-04-30","objectID":"/mysql-1/:1:2","tags":["mysql"],"title":"MySQL学习(一)","uri":"/mysql-1/"},{"categories":["web"],"content":"MySQL安装 我这里采用最为便捷的方法——docker 容器启动。 依然是给出 shell 和 docker-compose 两种启动，注意修改密码等内容： shell docker run -itd --name mysql -h mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=\u003cyour passwd\u003e mysql docker-compose.yml version:\"3\"services:db:image:mysqlcontainer_name:mysqlstdin_open:truetty:trueenvironment:MYSQL_ROOT_PASSWORD:\"root\"ports:- \"3306:3306\"restart:alwayshostname:mysql 这就安装好了，输入命令docker exec -it mysql bash即可进入容器，按下{ctrl}+{p}+{q}即可退出容器但保持容器活跃，输入命令mysql -u root -p即可进入 mysql 命令行。 ","date":"2022-04-30","objectID":"/mysql-1/:1:3","tags":["mysql"],"title":"MySQL学习(一)","uri":"/mysql-1/"},{"categories":["web"],"content":"MySQL使用 SQL通用语法 SQL 语句以;或\\g结尾。 SQL 语句应用空格或缩进以代码格式化，便于阅读。 SQL 语句中关键词尽量大写，但 SQL 语句对大小写不敏感。 SQL 语句中注释有三种： # 单行注释，MySQL特有 -- 单行注释 /* 多行注释 */ SQL 分类： DDL（Data Definition Language）数据定义语言： 用来定义数据库对象︰数据库，表，列等。关键字： create，drop，alter等。 DML（Data Manipulation Language）数据操作语言： 用来对数据库中表的数据进行增删改。关键字：insert，delete，update等。 DQL（Data Query Language）数据查询语言： 用来查询数据库中表的记录（数据）。关键字：select，where等。 DCL（Data Control Language）数据控制语言（了解即可）： 用来定义数据库的访问权限和安全级别，及创建用户。关键字：GRANT，REVOKE等。 DDL：操作数据库、表 操作数据库 C（Create）：创建 创建数据库CREATE DATABASE 数据库名称; 判断不存在才创建CREATE DATABASE IF NOT EXISTS test; 指定字符集创建CREATE DATABASE test CHARACTER SET gbk; 综合：CREATE DATABASE IF NOT EXISTS test CHARACTER SET gbk——如果该数据库不存在则创建之，并指定字符集为 gbk。 R（Retrieve）：查询 查询数据库名称SHOW DATABASES; 我们会看到有四个数据库information_schema、mysql、performance_schema、sys，其用途如下： information_schema：信息数据库，在其中的是视图而非基本表，这个库提供访问数据库元数据的方式。 mysql：核心数据库，存储数据库的用户、权限设置、关键字等控制管理信息。比如说，我们可以在user表中修改用户密码。 performance_schema：收集数据库服务器性能参数 sys：其中数据来自：performance_schema。目的是将performance_schema复杂度降低，让 DBA 能更好的阅读这个库里的内容，让 DBA 更快的了解 DB 的运行情况。 查询数据库创建语句SHOW CREATE DATABASE 数据库名称; U（Update）：修改 修改数据库字符集ALTER DATABASE 数据库名称 CHARACTER SET 字符集; 值得注意的是，该操作时修改库，不会对其中已有的表的字符集做出修改！ D（Delete）：删除 删除数据库DROP DATABASE 数据库名称; 判断存在才删除DROP DATABASE IF EXISTS 数据库名称; 使用数据库 查询当前正在使用的数据库名称SELECT DATABASE(); 操作表 C（Create）：创建 语法 CREATETABLE表名(列名1数据类型1,列名2数据类型2); 数据类型：详细见MySQL 数据类型 | 菜鸟教程 (runoob.com) int整数类型——age INT double小数类型——score DOUBLE(5,2)，小数最多五位，小数点后保留两位 date日期类型，yyyy-MM-dd格式 datetime日期类型，yyyy-MM-dd HH:mm:ss格式 timestamp时间戳，yyyy-MM-dd HH:mm:ss格式，若不赋值则获取当前系统时间 varchar字符串类型——name VARCHAR(20)，最大 20 个字符。 示例： CREATETABLEstudent(idINT,nameVARCHAR(20),ageINT,scoreDOUBLE(5,2),birthdayDATE,insert_timeTIMESTAMPDEFAULTCURRENT_TIMESTAMPONUPDATECURRENT_TIMESTAMP); 复制表CREATE TABLE 表名 LIKE 源表名; R（Retrieve）：查询 查询库中所有表名称SHOW TABLES; 查询表结构DESC 表名; 查询表创建语句SHOW CREATE TABLE 表名 U（Update）：修改 修改表名ALTER TABLE 原表名 RENAME TO 新表名; 修改表字符集ALTER TABLE 表名 CHARACTER SET 字符集; 添加列ALTER TABLE 表名 ADD 列名 数据类型; 修改列ALTER TABLE 表名 CHANGE 原列名 新列名 新数据类型; 或ALTER TABLE 表名 MODIFY 原列名 新数据类型 删除列 D（Delete）：删除 DROP TABLE 表名 DROP TABLE IF EXISTS 表名 DML：增删改表中数据 添加数据 语法：INSERT INTO 表名(列名1,列名2,...,列名n) VALUES(值1,值2,...,值n); 注意事项： 列名与值一一对应。 如果表名后不定义列名，则默认给所有列添加值 除了数字类型，其他数据类型均需要用单引号（或双引号）括起来 删除数据 语法：DELETE FROM 表名 [WHERE 条件]; 注意事项: 如果不添加条件，则删除所有记录！ 不推荐使用DELETE FROM 表名;来删除表中所有记录，推荐使用TRUNCATE TABLE 表名; TRUNCATE TABLE 表名;与DROP TABLE 表名;以及DELETE FROM 表名;区别： TRUNCATE TABLE 表名直接删除所有记录再创建相同表 DROP TABLE 表名直接删除表 DELETE FROM 表名重复执行DELETE以删除表中每一条记录，但不删除表结构。 修改数据 语法：UPDATE 表名 SET 列1=值1,列2=值2,...,列n=值n [WHERE 条件] 注意事项：如果不添加条件，则修改所有记录！ DQL：查询表中记录 语法 SELECT字段列表FROM表名列表WHERE条件列表GROUPBY分组字段HAVING分组之后的条件ORDER排序LIMIT分页限定; 基础查询 多字段查询SELECT 列名1,列名2,...,列名n FROM 表名; 如果是查询所有字段，可以用SELECT * FROM 表名;，但这样写的可读性不高。 去除重复DISTINCT 计算列SELECT 四则运算式 FROM 表名; SELECTmath+englishFROMstu; 值得注意的是，如果有NULL参与，则计算结果也为NULL，解决方法：使用函数IFNULL(字段,替换值) SELECTmath+IFNULL(english,0)FROMstu; 起别名AS（该关键字可省略） SELECTmath数学,english英语,math+IFNULL(english,0)AS总分FROMstu; 条件查询 WHERE子句后跟条件 运算符： \u003e, \u003c, \u003e=, \u003c=, =, \u003c\u003e \u003c\u003e在 SQL 中表示不等于，在 MySQL 中也可以用!=表示不等于，但请注意，没有==！ BETWEEN...AND IN(集合) LIKE模糊查询 占位符：_单个字符，%多个任意字符 eg，查询name字段包含’马’的人：SELECT name FROM stu WHERE name LIKE '%马%' IS NULL NULL 值不可以做大小比较，只能用IS或IS NOT来判断 AND 或 \u0026\u0026 在 SQL 中建议使用前者，后者不通用 OR 或 || NOT 或 ! 排序查询 语法：ORDER BY 排序字段1 排序方式1, 排序字段2 排序方式2...; 默认排序方式为ASC即升序，而DESC为降序，当且仅当第一条件无法完全判断时才执行后续条件 SELECTid,name,scoreFROMstuORDERBYscoredesc,id;-- 按照 score 降序排列，相同成绩则按 id 升序排列 聚合函数 将—列数据作为一个整体，进行纵向的计算。 COUNT：计算个数 MAX：计算最大值 MIN：计算最小值 SUM：求和 AVG：求平均值 SELECTCOUNT(id)FROMstu; 注意，所有聚合函数的计算会排除 NULL 值，解决方案： 选择不包含 NULL 值的列进行计算 使用IFNULL函数 分组查询 语法：GROUP BY 分组字段 HAVING 分组后查询条件 注意事项： 分组之后查询的字段：分组字段、聚合函数 WHERE和HAVING的区别： WHERE在分组之前进行限定，如果不满足条件，则不参与分组。HAVING在分组之后进行限定，如果不满足结果，则不会被查询出来 WHERE后不可跟聚合函数，HAVING可以进行聚合函数的判断。 SELECTgender,AVG(score)FROMstuWHEREscore\u003e=70GROUPBYgenderHAVINGCOUNT(id)\u003e2;-- 按 gender 分组，查询 score 平均数且 score 低于 70 的参与，分组之后，人数要大于二： 分页查询 语法：LIMIT 开始的索引，每页显示的条数 公式：$$开始的索引 = (当前的页码 - 1) * 每页显示的条数$$ eg，从0开始，显示3条 SELECT * FROM stu LIMI","date":"2022-04-30","objectID":"/mysql-1/:1:4","tags":["mysql"],"title":"MySQL学习(一)","uri":"/mysql-1/"},{"categories":["中间件"],"content":"本文介绍Docker客户端与服务器机制及相关知识点，如Unix域套接字、守护进程、Docker Daemon、dind、docker api，并实践演示了如何远程连接Docker服务端","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"Docker客户端与服务器机制 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:0:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"简单介绍 当我们使用docker version命令查询docker 版本信息时，我们发现有两块内容，事实上这是由 docker 的客户端与服务器机制决定的。 Docker 使用了常见的CS架构，也就是 client-server 模式，Docker Client 负责处理用户输入的各种命令，比如docker build、docker run，真正工作的其实是 Docker 服务端，也就是 Docker Engine 或者说是 Docker Daemon。 值得注意的是，docker 客户端和 Docker Daemon 可以运行在同一台机器上。 当我们写完 dockerfile 交给 docker “编译”，使用docker build，那么 client 在接收到请求后转发给 docker daemon，接着 docker daemon根据 dockerfile 创建出“可执行程序” image。 接下来使用命令docker run，docker daemon 接收到该命令后找到具体的 image，然后加载到内存开始执行，image 执行起来就是所谓的 container。 用户通过 docker client 发送命令docker pull，docker daemon 接收到命令后向 docker registry 发送 image 下载请求，下载后存放在本地，这样我们就可以使用别人的 image 了。 举个栗子 docker for Windows ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:1:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"Linux Daemon（守护进程） Linux Daemon（守护进程）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。它不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。Linux 系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括系统日志进程 syslogd、 web 服务器 httpd、邮件服务器 sendmail 和数据库服务器 mysqld 等。 守护进程一般在系统启动时开始运行，除非强行终止，否则直到系统关机都保持运行。守护进程经常以超级用户（root）权限运行，因为它们要使用特殊的端口（1-1024）或访问某些特殊的资源。 一个守护进程的父进程是 init 进程，因为它真正的父进程在 fork 出子进程后就先于子进程 exit 退出了，所以它是一个由 init 继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备 stdout 还是标准出错设备 stderr 的输出都需要特殊处理。 守护进程的名称通常以 d 结尾，比如 sshd、xinetd、crond 等。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:2:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"Docker Daemon Docker Daemon 即 Docker 的守护进程。 Docker Client 通过命令行与 Docker Damon 通信，Daemon 的主要功能包括镜像管理、镜像构建、REST API、身份验证、安全、核心网络以及编排。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:3:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"工作机制 Docker Daemon 可以认为是通过 Docker Server 模块接受 Docker Client 的请求，并在 Engine 中处理请求，然后根据请求类型，创建出指定的 Job 并运行，运行过程的作用有以下几种可能：向 Docker Registry 获取镜像，通过 graphdriver 执行容器镜像的本地化操作，通过 networkdriver 执行容器网络环境的配置，通过 execdriver 执行容器内部运行的执行工作等。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:3:1","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"Unix域套接字（Unix Domain Socket） Docker 守护进程会生成一个 /var/run/docker.sock文件来进行本地进程通信，因此只能在本地使用 Docker 客户端或者使用 Docker API 进行操作。 sock 文件是 UNIX 域套接字，它可以通过文件系统（而非网络地址）进行寻址和访问。 socket按域分类 域 描述 AF_INET ipv4因特网域 AF_INET6 ipv6因特网域 AF_UNIX Unix域（本地套接字） AF_UPSPEC 未指定 Unix 域套接字用于在同一台机器上运行的进程之间的通信。虽然因特网域套接字可用于同一目的，但 Unix 域套接字的效率更高。UNIX 域套接字仅复制数据；它们并不执行协议处理，不需要添加或删除网络报头，无需计算检验和，不要产生顺序号，无需发送确认报文。 Unix 域套接字提供流和数据报两种接口。UNIX域数据报服务是可靠的，既不会丢失消息也不会传递出错。Unix 域套接字是套接字和管道之间的混合物。 管道 pipe 和 socket 都是比较常用的 IPC 方式（Inter-Process Communication） 管道是一种两个进程间进行单向通信的机制。因为管道传递数据的单向性，管道又称为半双工管道。 每一个 socket 都有两个数据缓冲区，读缓冲区，写缓冲区。用户往 socket 写数据其实就是往 socket 的写缓冲区拷贝数据，然后内核再把写缓冲区的数据拷贝到接收方 socket 的读缓冲区。两个缓冲区。 而对于 pipe，写的时候是在管道一端pipefd[1]塞数据，读的时候从另一端pipefd[0]读，两端是在共用一个缓冲区。pipe也仅仅是数据拷贝，不需要处理协议。pipe 中写操作是阻塞的，那么当缓冲区满了之后发送方的 write 操作将会被阻塞，而不会发生缓冲区溢出丢包这种情况。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:4:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"docker in docker（dind） 有时需要在容器内执行 docker 命令，比如：在 jenkins 容器内运行 docker 命令执行构建镜像，但直接在 docker 容器内嵌套安装 docker 未免太过臃肿。 更好的办法是：容器内仅部署 docker 命令行工具（作为客户端），实际执行交由宿主机内的 docker-engine（服务器）。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:5:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"方法 在docker容器内启动一个docker daemon，对外提供服务。 每个运行中的容器，都是一个进程，这个进程都托管在docker daemon中。 优点在于镜像和容器都在一个隔离的环境，保持宿主机的环境。 通过宿主机的docker.sock 只要以数据卷的形式将 Docker 客户端和上述 Unix 域套接字挂载到容器内部，就能实现 “Docker in Docker”，在容器内使用 Docker 命令了。 通过类似docker run -v /var/run/docker.sock:/var/run/docker.sock的命令将宿主机 docker.sock 文件挂载到容器， 并且直接 挂载宿主机的/usr/bin/docker， 这样容器内就不需安装 Docker 程序。 当容器内使用 docker 命令时，实际上调用的是宿主机的 Docker Daemon 和 docker 命令。 也就是说，容器内实际并未运行 docker server，但是能够通过宿主机执行 docker 任务，从而实现简单的 dind。 需要特别说明的是，真正执行 docker 命令的是跑在宿主机上的 docker-engine（服务器），因此这并不是真正的 “Docker in Docker”，或许可以称之为“Docker outside Docker”。 通过docker:dind镜像 先启动一个docker:dind容器A，再启动一个 docker 容器 B，容器 B 指定 host 为 A 容器内的 Docker Daemon。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:5:1","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"示例1 version: '3.3'services: jenkins-master: image: jenkinsci/blueocean:latest container_name: jenkins-master environment: - TZ=Asia/Shanghai # 时区 ports: - \"8080:8080\" - \"50000:50000\" volumes: - ./jenkins_home:/var/jenkins_home # 将容器中的数据映射到宿主机 - /usr/bin/docker:/usr/bin/docker # 为容器内部提供 docker 命令行工具（这个随意） - /var/run/docker.sock:/var/run/docker.sock # 容器内部通过 unix socket 使用宿主机 docker engine user: root # 容器以有权限读写 docker.socket 的用户启动 restart: always ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:5:2","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"示例2 本处示例来自https://www.cnblogs.com/anliven/p/13551614.html#_label2 docker network create jenkins docker volume create jenkins-docker-certs docker volume create jenkins-data docker run --name jenkins-docker -d --privileged --network jenkins --network-alias docker --env DOCKER_TLS_CERTDIR=/certs --volume jenkins-docker-certs:/certs/client --volume jenkins-data:/var/jenkins_home docker:dind docker run --name jenkins-blueocean -d --network jenkins --env DOCKER_HOST=tcp://docker:2376 --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 --volume jenkins-data:/var/jenkins_home --volume jenkins-docker-certs:/certs/client:ro --publish 8080:8080 --publish 50000:50000 jenkinsci/blueocean docker exec jenkins-blueocean cat var/jenkins_home/secrets/initialAdminPassword # 获取初始密码 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:5:3","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"Docker API ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:6:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"API 什么是API 维基百科： 应用程序编程接口 （application programming interface，缩写 API） 是计算机之间或计算机程序之间的连接。它是一种软件接口，为其他软件提供服务。描述如何构建或使用此类连接或接口的文档或标准称为 API 规范。符合此标准的计算机系统称为实现或公开API。术语 API 可以指规范或实现。 与将计算机连接到人的用户界面相比，应用程序编程接口将计算机或软件片段相互连接。它不打算由将它合并到软件中的计算机程序员以外的人（最终用户）直接使用。API通常由不同的部分组成，这些部分充当程序员可用的工具或服务。使用这些部分之一的程序或程序员被称为API的该部分。组成 API 的调用也称为子例程、方法、请求或终结点。API 规范定义了这些调用，这意味着它解释了如何使用或实现它们。 API的一个目的是隐藏系统如何工作的内部细节，只公开程序员会发现有用的部分，并保持它们的一致性，即使内部细节以后发生变化。API可以是针对特定系统对定制的，也可以是允许许多系统之间互操作性的共享标准。 打个比方，程序员 A 开发了一个程序，里面有个功能是图像识别，然后程序员 B 现在也需要这个功能，但是他不想再走一遍图像识别的路，又不可能直接用别人的程序。这时 A 想到了一个办法，我把这个功能单独从整个程序中抽出来，然后给出了一个入口，别人只要按照约定好的方法来调用，就可以实现这个功能。这就是一个简单的 API 的例子。 什么是REST REST（Representational State Transfer），意为表现层状态转化。 REST 是面向资源的，每个资源都有一个唯一的资源定位符（URI）。每个URI代表一种资源（resource），所以URI中不能有动词，只能有名词，而且所用的名词往往与数据库的表名对应。一般来说，数据库中的表都是同种记录的\"集合\"（collection），所以URI中的名词也应该使用复数。 什么是表现层？ 指资源的表现层。资源用 URI 标识了，我们可以理解为这个资源已经在网络上“表现”了。表现层就是把\"资源\"具体呈现出来的形式。 什么是状态转化？ 请求方式 含义 GET 从服务器取出资源（一项或多项） POST 在服务器新建一个资源 PUT 在服务器更新资源（更新完整资源） PATCH 在服务器更新资源， PATCH更新个别属性 DELETE 从服务器删除资源 通过上述方法可以对网络上的资源进行状态转化操作。 所以，REST 就是表现层的状态转化，简单粗暴的可以理解为：方法 + URI资源。 简单对比 查询 传统 REST 查询所有 http://localhost:8080/employee/list http://localhost:8080/employees 即 GET /employees @RequestMapping(value = \"/employees”, method = RequestMethod.GET) ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:6:1","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"Docker API Docker API 也遵循 RESETFUL 风格。 docker官方主要有三大对外api Docker Registry API 镜像仓库的 API，通过操作这套 API，你可以自由的自动化、程序化的管理你的镜像仓库 Docker Hub API 用户管理操作的 API，docker hub是使用校验和公共 namespaces 的方式来存储账户信息、认证账户、进行账户授权。API 同时也允许操作相关的用户仓库和 library 仓库。 Docker Remote API 控制主机 Docker 服务端的 API，等价于 docker 命令行客户端。 能远程操作docker容器，更重要的是你可以通过程序自动化运维docker进程。 Docker API使用前准备 首先要开启 Docker RESET API vim /usr/lib/systemd/system/docker.service 在ExecStart=/usr/bin/dockerd后面直接添加-H tcp://0.0.0.0:8088 -H unix:///var/run/docker.sock（为任意可用端口） 然后重启即可。 sudo systemctl daemon-reload sudo systemctl restart docker 接着我们可以用curl 127.0.0.1:8088/info | python3 -mjson.tool 来测试成果，得到的是docker的状态，此处不作演示。 使用Docker API 我们可以在 Docker 官网上查询各版本的 API 使用手册：Docker Engine API v1.41 Reference curl方式 使用curl -X GET http://127.0.0.1:8088/images/json | python3 -mjson.tool查看所有镜像 使用curl -X GET http://127.0.0.1:8088/containers/json | python3 -mjson.tool查看所有容器 python程序脚本方式 docker给 python 提供了一个非常强大的库 docker，采用 pip 即可安装。 pip3 install docker 示例 import docker if __name__ == '__main__': client = docker.from_env() print(client.containers.run('alpine', 'echo hello world')) 这段代码能新建一个容器，仅是一个最简单的测试。 现在我们尝试更多的 API。 import docker if __name__ == '__main__': client = docker.DockerClient(\"unix://var/run/docker.sock\") # 拉取镜像 image = client.images.pull(\"hello-world\") # 运行镜像 # detach=False时，返回运行过程中的日志;detach=True时，返回Container对象 print(client.containers.run(\"hello-world\", detach=False)) # 查询镜像 images = client.images.list() for img in images: print(img) # 查询容器 for container in client.containers.list(): print(container.name + \" image:\" + container.image.attrs[\"RepoTags\"][0]) ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:6:2","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"远程连接docker服务端 前面我们已经介绍了 Unix 域套接字来进行进程间通信以及本地连接 docker，而现在我要进行远程连接 docker。对此，我们可以采用 TCP 连接。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:7:0","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"TCP连接 /etc/systemd/system/docker.service.d/docker.conf vim /etc/systemd/system/docker.service.d/docker.conf [Service] ExecStart= ExecStart=/usr/bin/dockerd /etc/docker/daemon.json vim /etc/docker/daemon.json { \"hosts\":[ \"unix:///var/run/docker.sock\", \"tcp://0.0.0.0:2375\" ] } 重启docker sudo systemctl daemon-reload sudo systemctl restart docker 现在我们用客户端测试 docker -H 104.225.234.14:2375 info 显然这对于远程连接是不安全的，我们可以采用 TLS 连接即 TCP + SSL （HTTPS）来实现安全通信。 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:7:1","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["中间件"],"content":"TLS（HTTPS）连接 服务器只允许来自服务器 CA 签名的证书进行身份验证的客户端的连接。客户端仅连接到具有由该 CA 签名的证书的服务器。 使用 OpenSSL 创建 CA、服务器和客户端密钥 首先，在 docker 服务器上，生成 CA 私钥和公钥： openssl genrsa -aes256 -out ca-key.pem 4096 openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem 创建服务器密钥和证书签名请求 （CSR），请确保公用名（common name）与您用于连接到 Docker 的主机名匹配： openssl genrsa -out server-key.pem 4096 openssl req -subj \"/CN=localhost\" -sha256 -new -key server-key.pem -out server.csr 使用 CA 对公钥进行签名： TLS 连接可以通过 IP 地址和 DNS 名称进行，因此在创建证书时需要指定 IP 地址 echo subjectAltName = DNS:localhost,DNS:bandwagon,IP:104.225.234.14,IP:127.0.0.1 \u003e\u003e extfile.cnf 将 Docker 守护程序密钥的扩展用法属性设置为仅用于服务器身份验证： echo extendedKeyUsage = serverAuth \u003e\u003e extfile.cnf 现在，生成签名证书： openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem -extfile extfile.cnf 对于客户端身份验证，请创建客户端密钥和证书签名请求： openssl genrsa -out key.pem 4096 openssl req -subj '/CN=client' -new -key key.pem -out client.csr 要使密钥适合客户端身份验证，请创建一个新的扩展配置文件： echo extendedKeyUsage = clientAuth \u003e extfile-client.cnf 现在，生成签名证书： openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\ -CAcreateserial -out cert.pem -extfile extfile-client.cnf 生成后，您可以安全地删除两个证书签名请求和扩展配置文件：cert.pem server-cert.pem rm -v client.csr server.csr extfile.cnf extfile-client.cnf 如果默认值为 022，则密钥对您和您的组来说是全局可读和可写的。umask 若要保护密钥免受意外损坏，请删除其写入权限。要使它们只能由您读取，请按如下方式更改文件模式： chmod -v 0400 ca-key.pem key.pem server-key.pem 证书可以全域可读，但您可能希望删除写入访问权限以防止意外损坏： chmod -v 0444 ca.pem server-cert.pem cert.pem 现在，您可以使 Docker 守护程序仅接受来自提供 CA 信任的证书的客户端的连接： dockerd \\ --tlsverify \\ --tlscacert=ca.pem \\ --tlscert=server-cert.pem \\ --tlskey=server-key.pem \\ -H=0.0.0.0:2376 要连接到 Docker 并验证其证书，请提供您的客户端密钥、证书和受信任的 CA，注意修改 Host： docker --tlsverify \\ --tlscacert=ca.pem \\ --tlscert=cert.pem \\ --tlskey=key.pem \\ -H=Bandwagon:2376 version 在客户端计算机上运行它 在客户端计算机上运行它，此步骤应在 Docker 客户端计算机上运行。因此，您需要将 CA 证书、服务器证书和客户端证书复制到该计算机。 注意 基于 TLS 的 Docker 应在 TCP 端口 2376 上运行。 警告 如上面的示例所示，使用证书身份验证时，不需要运行客户端或组。这意味着任何拥有密钥的人都可以向您的 Docker 守护程序提供任何指令，从而为他们提供对托管守护程序的计算机的根访问权限。像保护 root 密码一样保护这些密钥！docker sudo docker 如果要在默认情况下保护 Docker 客户端连接，则可以将文件移动到主目录中的目录—并设置 and 变量（而不是在每次调用时传递）.docker DOCKER_HOST DOCKER_TLS_VERIFY -H=tcp://$HOST:2376 --tlsverify mkdir -pv ~/.docker cp -v {ca,cert,key}.pem ~/.docker export DOCKER_HOST=tcp://localhost:2376 DOCKER_TLS_VERIFY=1 默认情况下，Docker 现在安全地连接： docker ps 当你全部执行上述命令后，此时的文件结构如下： ├── ca-key.pem ├── ca.pem # 客户端\u0026服务端 ├── ca.srl ├── cert.pem # 客户端 ├── key.pem # 客户端 ├── server-cert.pem # 服务端 └── server-key.pem # 服务端 ","date":"2022-04-04","objectID":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/:7:2","tags":["docker"],"title":"Docker客户端与服务器机制","uri":"/docker%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"categories":["算法与数据结构"],"content":"递归时间复杂度求解 ","date":"2022-03-15","objectID":"/%E9%80%92%E5%BD%92%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%B1%82%E8%A7%A3/:0:0","tags":["算法","学习"],"title":"递归时间复杂度求解","uri":"/%E9%80%92%E5%BD%92%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%B1%82%E8%A7%A3/"},{"categories":["算法与数据结构"],"content":"master公式使用 $$ T(N)=a*T(\\frac{N}{b})+O(N^d)\\\\ \\log(b,a)\u003ed\\qquad时间复杂度O(N^{\\log(b,a)})\\\\ \\log(b,a)=d\\qquad时间复杂度O(N^d*\\log{N})\\\\ \\log(b,a)\u003cd\\qquad时间复杂度O(N^d)\\\\ $$ N为母问题的规模级别，子问题规模都是$\\frac{N}{b}$，a是子问题调用次数，$O(N^d)$是除了调用子问题以外的过程的时间复杂度 举个栗子 int process(int arr[], int L, int R) { if (L == R) return arr[L]; int mid = L + (R - L) \u003e\u003e 1; //求中点 int LMax = process(arr, L, mid); int RMax = process(arr, mid + 1, R); return RMax \u003e LMax ? LMax : RMax; } 该递归算法时间复杂度： $$ T(N)=2*T(\\frac{N}{2})+O(1) $$ ","date":"2022-03-15","objectID":"/%E9%80%92%E5%BD%92%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%B1%82%E8%A7%A3/:1:0","tags":["算法","学习"],"title":"递归时间复杂度求解","uri":"/%E9%80%92%E5%BD%92%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%B1%82%E8%A7%A3/"},{"categories":["常见问题"],"content":"如何在本地Windows系统上定时执行python脚本。","date":"2022-02-22","objectID":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/","tags":["windows","python"],"title":"本地定时脚本","uri":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/"},{"categories":["常见问题"],"content":"本地定时脚本 ","date":"2022-02-22","objectID":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/:0:0","tags":["windows","python"],"title":"本地定时脚本","uri":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/"},{"categories":["常见问题"],"content":"python脚本 本脚本修改自GitHub开源项目 本脚本功能：乐健体育跑 3.5km 并活动打卡。 要执行本脚本，你需要安装legym模块 pip install -i https://test.pypi.org/simple legym==0.4 代码： from _datetime import datetime import legym # 注意修改本处账户密码 def run(activity, username='#', password='#', distance='3.5'): print(\"Login...\", end=\"\") user = legym.login(username, password) print(\"success\") print(\"Running...\", end=\"\") actual_distance, success = user.running(float(distance)) if success: print(f\"{actual_distance}km\") else: print(\"failed\") print(\"Registering...\", end=\"\") _, success, _ = user.register(name=activity) if success: print(\"success\") else: print(\"failed\") print(\"Signing...\", end=\"\") results = user.sign() for result in results: if result[1]: print(\"success\") else: print(\"failed\") def weekday(): week = datetime.today().isoweekday() week_chinese = {1: '周一', 2: '周二', 3: '周三', 4: '周四', 5: '周五', 6: '周六', 7: '周日'} return week_chinese[week] if __name__ == '__main__': act = '第三空间'+weekday()+'沙河校区体育场' run(act) ","date":"2022-02-22","objectID":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/:1:0","tags":["windows","python"],"title":"本地定时脚本","uri":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/"},{"categories":["常见问题"],"content":"任务计划程序 打开计算机管理 点击 系统工具 »\u003e 任务计划程序 »\u003e 创建基本任务 自主填写任务名称与描述 »\u003e 选择每天 »\u003e 选择执行时间 »\u003e 选择启动程序 程序或脚本：python.exe 或 pythonw.exe 的路径，选择后者不会出现 IDE 窗口 添加参数：python脚本路径 起始于：Python编译器路径 当然，你也可以用pyinstaller将 python 文件打包为 exe 可执行文件，这样一来只需要将可执行文件路径添加到程序或脚本栏即可。 完成后可在 任务计划程序库 中查看。 ","date":"2022-02-22","objectID":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/:2:0","tags":["windows","python"],"title":"本地定时脚本","uri":"/%E6%9C%AC%E5%9C%B0%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述数据结构技术中的排序。","date":"2022-02-19","objectID":"/data_structure-9/","tags":["数据结构","学习"],"title":"数据结构学习(九)","uri":"/data_structure-9/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(九) ","date":"2022-02-19","objectID":"/data_structure-9/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(九)","uri":"/data_structure-9/"},{"categories":["算法与数据结构"],"content":"技术 ","date":"2022-02-19","objectID":"/data_structure-9/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(九)","uri":"/data_structure-9/"},{"categories":["算法与数据结构"],"content":"排序 内部排序 排序的基本概念 排序 记录序列：{$R_1,R_2,…,R_n$} 关键字序列：{$K_1,K_2,…,K_n$} 重排记录序列，得{$Rp_1,Rp_2,…,Rp_n$}，使相应关键字满足非递减（或非递增）关系， 即$Kp_1≤Kp_2≤…≤Kp_n$ 内部排序与外部排序 根据排序时数据所占用存储器的不同，可将排序分为两类： 内部排序：整个排序过程完全在内存中进行 外部排序：由于待排序数据量太大，内存无法容纳全部数据，排序需借外存才能完成 排序的稳定性 稳定排序：在排序过程中，相同关键字（$K_i=K_j$,i\u003cj）其领先关系不发生变化——需从算法本身步骤中证明 不稳定排序：在排序过程中，相同关键字（$K_i=K_j$,i\u003cj）其领先关系发生变化——仅需举反例即可证明不稳定 基本操作 比较两个关键字的大小 将记录从一个位置移动到另一个位置 存储方法 向量结构： 将待排序的记录存放在一组地址连续的存储单元中 链表结构 地址排序 插入类排序 插入排序基本思想 已排序记录子集基础上，将下一个待排序记录有序插入到已排序记录子集，直到将所有待排序记录全部插入。 直接插入排序 算法思想：将第 i 个插入到前 i-1 个有序集合。 算法要点： 监视哨r[0]保存待插入的记录 方向从后往前查找插入位置 查找与移动用同一循环完成 算法实现： void InsSort(RecordType r[], int length) //对记录数组r做直接插入排序, length为数组的长度 { int i, j; for (i = 2; i \u003c length; i++) //将待插入记录存放到监视哨r[0]中 { r[0] = r[i]; j = i - 1; while (r[0].key \u003c r[j].key) //寻找插入位置 { r[j + 1] = r[j]; j--; } r[j + 1] = r[0]; //将待插入记录插入已排序的序列中} } } 算法分析： 最好情况： 有序的待排序序列——比较次数 n-1 次，移动次数 2(n-1) 次 最坏情况： 待排序记录为逆序排列——总比较次数： $$ \\sum_{i=2}^ni=\\frac{(n+2)(n-1)}{2} $$ 记录移动次数： $$ \\sum_{i=2}^n(i+1)=\\frac{(n+4)(n-1)}{2} $$ 故直接插入排序的时间复杂度为$T(n)=O(n^2)$ 直接插入排序是稳定排序： 从后向前进行算法while(r[0].key\u003cr[j] key)相同元素插入到r[j+1] 折半排序 算法改进要点：改进确定插入位置方法 算法描述： void BinSort(RecordType r[], int length) //对数组r进行折半插入排序，length为数组长度 { int i, j, low, high, mid; RecordType x; for (i = 2; i \u003c length; i++) { x = r[i]; low = 1; high = i - 1; while (low \u003c= high) //确定插入位置 { mid = (low + high) / 2; if (x.key \u003c r[mid].key) high = mid - 1; else low = mid + 1; } for (j = i - 1; j \u003e= low; --j) r[j + 1] = r[j]; //记录依次向后移动 r[low] = x; //插入记录 } } 算法分析： 折半插入可减少关键字的比较次数，但移动次数没有减少，故折半插入排序的总的时间复杂度仍然是$O(n^2)$。 每插入一个元素，最大的比较次数为折半判定树的深度。 插入第 i 个元素，设$i=2^j$，则需进行$\\log_2i$次比较，插入 n-1 个元素的平均关键字的比较次数为$O(n\\log_2n)$ 折半排序是稳定排序：待插入元素 x 位于有序序列之后，经过条件比较，元素相等时，其插入位置low=mid+1右部子表 希尔排序（缩小增量排序） 算法改进要点： 利用直接插入排序的最佳性质：n 比较小、基本有序。 将记录序列分成若干个子序列分别进行直接插入排序 经多次调整序列记录已基本有序最后再对记录进行直接插入排序 算法思想： 对整个文件，按间隔$d_1$分组，组内排序 取$d_2\u003cd_1$（缩小增量），继续以$d_2$为距离排序，直到$d_t=1$（同直接插入排序）为止 算法描述： void ShellInsert(RecordType r[], int length, int delta) //对记录数组r做一趟希尔插入排序，length为数组长度，delta为增量 { int i, j; for (i = 1 + delta; i \u003c= length; i++) // 1+delta为第一个子序列的第二个元素的下标 if (r[i].key \u003c r[i - delta].key) { r[0] = r[i]; //备份r[i]（不做监视哨） for (j = i - delta; j \u003e 0 \u0026\u0026 r[0].key \u003c r[j].key; j -= delta) r[j + delta] = r[j]; r[j + delta] = r[0]; } } void ShellSort(RecordType r[], int length, int delta[], int n) //对记录数组r做希尔排序，length为数组r长度，delta为增量数组，n为delta[]的长度 { for (int i = 0; i \u003c= n - 1; i++) ShellInsert(r, length, delta[i]); } 算法分析： 信息 逆转数是指在此关键字之前比它大的数据个数 待排序序列 46 55 13 42 94 17 05 90 逆转数$B_i$ 0 0 2 2 0 4 6 1 希尔排序比直接插入排序更快： 直接插入排序：一次比较移动只减少一个逆转数 希尔排序：一次比较移动减少逆转数有可能不止一个 根据经验公式可给出缩小增量的取法： Shell 提出$d=\\frac{n}{2}$，$d=\\frac{d}{2}$，直到 d=1为止 奇数位置元素在最后一趟才会与偶数位置比较，效率较低 knuth 提出$d=\\frac{d}{3}+1$ 希尔排序时间复杂度为$O(n^{\\frac{3}{2}})$ 希尔排序是不稳定排序： 例如待排序列 {2,4,1,2}，进行希尔排序后变为 {1,2,2,4}，其中相同关键字 2 的领先关系发生了变化。 交换类排序 交换排序基本思想 通过一系列交换逆序元素进行排序 冒泡排序（相邻比序法） 算法思想 顺次比较相邻两元素大小，若逆序就交换位置，反复扫描，直到待排序记录没有逆序为止。 算法描述 void BubbSort(RecordType r[], int length) //冒泡排序 { int i, j, n, change; RecordType x; n = length; change = true; for (i = 1; i \u003c= n - 1 \u0026\u0026 change; i++) { change = false; for (j = 1; j \u003c= n - i; j++) if (r[j].key \u003e r[j + 1].key) { x = r[j]; r[j] = r[j + 1]; r[j + 1] = x; change = true; } } } 算法分析： 最坏情况——关键字逆序排列，第 i 趟需 n-i 次比较，3(n-i) 次移动经过 n-1 趟冒泡排序： 比较次数$\\frac{n(n-1)}{2}$ 移动次数$\\frac{3n(n-1)}{2}$ 时间复杂度$O(n^2)$ 空间复杂度$O(1)$ 快速排序 改进要点： 通过两个不相邻元素的比较，一次交换可能消除多个逆序，大大加快排序速度。 算法思想： 选序列中一个枢轴元（选第 1 个其关键字$K_1$）以枢轴元素为界，分为两个子表小于$K_1$在前部子表，大于$K_1$在后部子表，对两个子表继续如上过程，直到所有子表的表长不超过 1 为止。 算法描述： int QKPass(RecordType r[], int left, int right) //一趟排序 { int low, high; RecordType x; x = r[left]; low = left; high = right; while (low \u003c high) { while (low \u003c high \u0026\u0026 r[high].key \u003e= x.key) high--; //从右到左找小于x.key的记录 if (low \u003c high) { r[low] = r[high]; low++; //置入左r[low] } while (low \u003c high \u0026\u0026 r[low].key \u003c= x.key) low++; //从左到右找大于x.key的记录 if (low \u003c high) { r[high] = r[low]; high--; //置入右r[high] } } r[low] = x; return low; } void QKSort(RecordType r[], int low, int high) //快速排序 { int pos; if (low \u003c high) { pos = QKPass(r, low, h","date":"2022-02-19","objectID":"/data_structure-9/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(九)","uri":"/data_structure-9/"},{"categories":["青龙面板"],"content":"docker部署青龙面板教程及常见问题解决","date":"2022-02-18","objectID":"/qinglong/","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"青龙面板教程 ","date":"2022-02-18","objectID":"/qinglong/:0:0","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"前期准备 首先你要有一台服务器（国内鸡需要有代理），一个域名和 SSL证书（可选）。我这里的服务器系统为 Ubuntu-20.03 ssh 登录上去，安装 docker，此处采用官方脚本一键安装并设置开机自启。 curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo systemctl enable docker ","date":"2022-02-18","objectID":"/qinglong/:1:0","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"青龙面板部署 ","date":"2022-02-18","objectID":"/qinglong/:2:0","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"docker启动容器 启动容器（项目地址：https://github.com/whyour/qinglong）： docker run -dit \\ -v $PWD/ql:/ql/data \\ -p 5700:5700 \\ --name qinglong \\ --hostname qinglong \\ --restart unless-stopped \\ whyour/qinglong:latest 其中-dit是后台运行、交互式操作、终端，-v是映射，-p是端口转发，--name是容器命名，--hostname是主机名，--restart unless-stopped是容器退出时总是重启，镜像是whyour/qinglong:latest 接着放行 5700 端口： ufw allow 5700 在浏览器地址栏键入ip:5700即可访问，由于是第一次访问，需要进行初始化： 通知设置，可以采用钉钉、server酱等方式 然后是账号密码设置，本处不赘述。 ","date":"2022-02-18","objectID":"/qinglong/:2:1","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"反向代理 接着就可以正常使用了，但你肯定不会满足于用ip:5700的方式访问的，于是我还需要用到Nginx反向代理： 本处默认你已经部署好了 SSL证书，因此只讲解修改Nginx配置文件（可以用nginx -t指令找到配置文件位置）： server { listen 80; listen [::]:80; listen 81 http2; server_name 你的域名; #修改本处域名 root /usr/share/nginx/html; location / { #反向代理 proxy_ssl_server_name on; proxy_pass http://ip:5700; #修改本处ip proxy_set_header Accept-Encoding ''; #过滤器模块 sub_filter \"ip:5700\" \"你的域名\"; #修改本处 sub_filter_once off; } } 修改完后重启 Nginx 服务 nginx -s reload 这样一来你就可以在浏览器中键入域名来访问青龙面板了！ ","date":"2022-02-18","objectID":"/qinglong/:2:2","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"配置环境变量 在浏览器地址栏键入m.jd.com访问京东手机版网页，使用手机验证码登录，按下F12在Cookies中找到pt_key、pt_pin，复制下来，在面板中点击环境变量，点击添加变量，将刚刚复制的内容填入对应位置（一行一个 cookie）： ","date":"2022-02-18","objectID":"/qinglong/:2:3","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"设置脚本订阅 在订阅管理处添加订阅即可 ql repo https://ghproxy.com/https://github.com/KingRan/KR.git \"jd_|jx_|jdCookie\" \"activity|backUp\" \"^jd[^_]|USER|utils|function|sign|sendNotify|ql|JDJR\" 注意，本处使用了https://ghproxy.com代理，国外鸡可直接删除代理。 ","date":"2022-02-18","objectID":"/qinglong/:2:4","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"青龙面板实现每日签到 安装依赖 首先进入容器 docker exec -it qinglong bash apk add --no-cache gcc g++ python python-dev py-pip mysql-dev linux-headers libffi-dev openssl-dev 如果上述命令安装依赖失败，请使用下方命令 apk add --no-cache --virtual .build-deps gcc musl-dev python2-dev python3-dev libffi libffi-dev openssl openssl-dev pip3 install pip setuptools --upgrade pip3 install cryptography~=3.2.1 现在安装dailycheckin pip3 install dailycheckin --upgrade /ql/scripts/config.json 配置文件 详解参考配置 - DailyCheckIn (sitoi.github.io) { \"DINGTALK_SECRET\": \"\", \"DINGTALK_ACCESS_TOKEN\": \"\", \"FSKEY\": \"\", \"SCKEY\": \"\", \"SENDKEY\": \"\", \"BARK_URL\": \"\", \"QMSG_KEY\": \"\", \"QMSG_TYPE\": \"\", \"TG_BOT_TOKEN\": \"\", \"TG_USER_ID\": \"\", \"TG_API_HOST\": \"\", \"TG_PROXY\": \"\", \"COOLPUSHSKEY\": \"\", \"COOLPUSHQQ\": true, \"COOLPUSHWX\": true, \"COOLPUSHEMAIL\": true, \"QYWX_KEY\": \"\", \"QYWX_CORPID\": \"\", \"QYWX_AGENTID\": \"\", \"QYWX_CORPSECRET\": \"\", \"QYWX_TOUSER\": \"\", \"QYWX_MEDIA_ID\": \"\", \"PUSHPLUS_TOKEN\": \"\", \"PUSHPLUS_TOPIC\": \"\", \"MERGE_PUSH\": \"\", \"IQIYI\": [ { \"cookie\": \"__dfp=xxxxxx; QP0013=xxxxxx; QP0022=xxxxxx; QYABEX=xxxxxx; P00001=xxxxxx; P00002=xxxxxx; P00003=xxxxxx; P00007=xxxxxx; QC163=xxxxxx; QC175=xxxxxx; QC179=xxxxxx; QC170=xxxxxx; P00010=xxxxxx; P00PRU=xxxxxx; P01010=xxxxxx; QC173=xxxxxx; QC180=xxxxxx; P00004=xxxxxx; QP0030=xxxxxx; QC006=xxxxxx; QC007=xxxxxx; QC008=xxxxxx; QC010=xxxxxx; nu=xxxxxx; __uuid=xxxxxx; QC005=xxxxxx;\" }, { \"cookie\": \"多账号 cookie 填写，请参考上面，cookie 以实际获取为准（遇到特殊字符如双引号\\\" 请加反斜杠转义）\" } ], \"VQQ\": [ { \"auth_refresh\": \"https://access.video.qq.com/user/auth_refresh?vappid=xxxxxx\u0026vsecret=xxxxxx\u0026type=qq\u0026g_tk=\u0026g_vstk=xxxxxx\u0026g_actk=xxxxxx\u0026callback=xxxxxx\u0026_=xxxxxx\", \"cookie\": \"pgv_pvid=xxxxxx; pac_uid=xxxxxx; RK=xxxxxx; ptcz=xxxxxx; tvfe_boss_uuid=xxxxxx; video_guid=xxxxxx; video_platform=xxxxxx; pgv_info=xxxxxx; main_login=xxxxxx; vqq_access_token=xxxxxx; vqq_appid=xxxxxx; vqq_openid=xxxxxx; vqq_vuserid=xxxxxx; vqq_refresh_token=xxxxxx; login_time_init=xxxxxx; uid=xxxxxx; vqq_vusession=xxxxxx; vqq_next_refresh_time=xxxxxx; vqq_login_time_init=xxxxxx; login_time_last=xxxxxx;\" }, { \"auth_refresh\": \"多账号 refresh url，请参考上面，以实际获取为准\", \"cookie\": \"多账号 cookie 填写，请参考上面，cookie 以实际获取为准（遇到特殊字符如双引号\\\" 请加反斜杠转义）\" } ], \"YOUDAO\": [ { \"cookie\": \"JSESSIONID=xxxxxx; __yadk_uid=xxxxxx; OUTFOX_SEARCH_USER_ID_NCOO=xxxxxx; YNOTE_SESS=xxxxxx; YNOTE_PERS=xxxxxx; YNOTE_LOGIN=xxxxxx; YNOTE_CSTK=xxxxxx; _ga=xxxxxx; _gid=xxxxxx; _gat=xxxxxx; PUBLIC_SHARE_18a9dde3de846b6a69e24431764270c4=xxxxxx;\" }, { \"cookie\": \"多账号 cookie 填写，请参考上面，cookie 以实际获取为准（遇到特殊字符如双引号\\\" 请加反斜杠转义）\" } ], \"KGQQ\": [ { \"cookie\": \"muid=xxxxxx; uid=xxxxxx; userlevel=xxxxxx; openid=xxxxxx; openkey=xxxxxx; opentype=xxxxxx; qrsig=xxxxxx; pgv_pvid=xxxxxx;\" }, { \"cookie\": \"多账号 cookie 填写，请参考上面，cookie 以实际获取为准（遇到特殊字符如双引号\\\" 请加反斜杠转义）\" } ], \"ONEPLUSBBS\": [ { \"cookie\": \"acw_tc=xxxxxx; qKc3_0e8d_saltkey=xxxxxx; qKc3_0e8d_lastvisit=xxxxxx; bbs_avatar=xxxxxx; qKc3_0e8d_sendmail=xxxxxx; opcid=xxxxxx; opcct=xxxxxx; oppt=xxxxxx; opsid=xxxxxx; opsct=xxxxxx; opbct=xxxxxx; UM_distinctid=xxxxxx; CNZZDATA1277373783=xxxxxx; www_clear=xxxxxx; ONEPLUSID=xxxxxx; qKc3_0e8d_sid=xxxxxx; bbs_uid=xxxxxx; bbs_uname=xxxxxx; bbs_grouptitle=xxxxxx; opuserid=xxxxxx; bbs_sign=xxxxxx; bbs_formhash=xxxxxx; qKc3_0e8d_ulastactivity=xxxxxx; opsertime=xxxxxx; qKc3_0e8d_lastact=xxxxxx; qKc3_0e8d_checkpm=xxxxxx; qKc3_0e8d_noticeTitle=xxxxxx; optime_browser=xxxxxx; opnt=xxxxxx; opstep=xxxxxx; opstep_event=xxxxxx; fp=xxxxxx;\" }, { \"cookie\": \"多账号 cookie 填写，请参考上面，cookie 以实际获取为准（遇到特殊字符如双引号\\\" 请加反斜杠转义）\" } ], \"BAIDU\": [ { \"data_url\": \"https://cdn.jsdelivr.net/gh/Sitoi/Sitoi.github.io/baidu_urls.txt\", \"submit_url\": \"http://data.zz.baidu.com/urls?site=https://sitoi.cn\u0026token=xxxxxx\", \"times\": 10 }, { \"data_url\": \"多账号 data_url 链接地址，以实际获取为准\", \"submit_url\": \"多账号 submit_url 链接地址，以实际获取为准\", \"times\": 10 } ], \"FMAPP\": [ { \"blackbox\": \"eyJlcnJxxxxxx\", \"cookie\": \"sensorsdata2015jssdkcross=xxxxxx\", \"device_id\": \"xxxxxx-xxxx-xxxx-xxxx-xxxxxx\", \"fmversion\": \"xxxxxx\", \"os\": \"xxxxxx\", \"token\": \"xxxxxx.xxxxxx-xxxxxx-xxxxxx.xxxxxx-xxxxxx\", \"userage","date":"2022-02-18","objectID":"/qinglong/:3:0","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"常见问题解决 ","date":"2022-02-18","objectID":"/qinglong/:4:0","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"ql指令 # 更新并重启青龙 ql update # 运行自定义脚本extra.sh ql extra # 添加单个脚本文件 ql raw \u003cfile_url\u003e # 添加单个仓库的指定脚本 ql repo \u003crepo_url\u003e \u003cwhitelist\u003e \u003cblacklist\u003e \u003cdependence\u003e \u003cbranch\u003e \u003cextensions\u003e # 删除旧日志 ql rmlog \u003cdays\u003e # 启动tg-bot ql bot # 检测青龙环境并修复 ql check # 重置登录错误次数 ql resetlet # 禁用两步登录 ql resettfa # 依次执行，如果设置了随机延迟，将随机延迟一定秒数 task \u003cfile_path\u003e # 依次执行，无论是否设置了随机延迟，均立即运行，前台会输出日，同时记录在日志文件中 task \u003cfile_path\u003e now # 并发执行，无论是否设置了随机延迟，均立即运行，前台不产生日，直接记录在日志文件中，且可指定账号执行 task \u003cfile_path\u003e conc \u003cenv_name\u003e \u003caccount_number\u003e(可选的) # 指定账号执行，无论是否设置了随机延迟，均立即运行 task \u003cfile_path\u003e desi \u003cenv_name\u003e \u003caccount_number\u003e file_url: 脚本地址 repo_url: 仓库地址 whitelist: 拉取仓库时的白名单，即就是需要拉取的脚本的路径包含的字符串 blacklist: 拉取仓库时的黑名单，即就是需要拉取的脚本的路径不包含的字符串 dependence: 拉取仓库需要的依赖文件，会直接从仓库拷贝到scripts下的仓库目录，不受黑名单影响 branch: 拉取仓库的分支 days: 需要保留的日志的天数 file_path: 任务执行时的文件路径 env_name: 任务执行时需要并发或者指定时的环境变量名称 account_number: 任务执行时指定某个环境变量需要执行的账号序号 ","date":"2022-02-18","objectID":"/qinglong/:4:1","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["青龙面板"],"content":"HTTP2问题 你可能会遇到这样的报错： HTTP/2 stream 0 was not closed cleanly: PROTOCOL_ERROR (err 1) 只需要在容器中执行以下命令即可解决： git config --global http.version HTTP/1.1 ","date":"2022-02-18","objectID":"/qinglong/:4:2","tags":["青龙面板","docker"],"title":"青龙面板教程","uri":"/qinglong/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述数据结构技术中的查找。","date":"2022-02-17","objectID":"/data_structure-8/","tags":["数据结构","学习"],"title":"数据结构学习(八)","uri":"/data_structure-8/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(八) ","date":"2022-02-17","objectID":"/data_structure-8/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(八)","uri":"/data_structure-8/"},{"categories":["算法与数据结构"],"content":"技术 ","date":"2022-02-17","objectID":"/data_structure-8/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(八)","uri":"/data_structure-8/"},{"categories":["算法与数据结构"],"content":"查找 查找的基本概念 列表：由同一类型的数据元素（或记录）构成的集合，可利用任意数据结构实现 关键字：数据元素的某个数据项的值可标识列表中的一个数据元素 主关键字可唯一标识列表中的一个数据元素，否则为次关键字 查找：根据给定的关键字值，在特定的列表中确定一个其关键字与给定值相同的数据元素，并返回该数据元素在列表中的位置 查找对象 K（找什么） 查找范围 L（在哪找） K 在 L 中的位置（查找的结果） 平均查找长度（ASL）：查找过程中对关键码的比较次数的平均值 $$ ASL=P_1C_1+P_2C_2+…+P_nC_n=\\sum_{i=1}^nP_iC_i\\\\ P_i为查找概率，C_i为查找次数 $$ 查找基本方法： 线性表查找法 树表式查找法 计算式（哈希）查找法 基于线性表的查找法 顺序查找法 数据类型定义 #define KeyType int #define OtherType int #define LIST_SIZE 20 typedef struct { KeyType key; OtherType other_data; } RecordType; typedef struct { RecordType r[LIST_SIZE + 1]; // r[0]为工作单元 int length; } RecordList; 顺序结构算法 此处为从后往前的顺序： //不设置监视哨，在顺序表中查找关键字等于k的元素 int SeqSearch_1(RecordList L, KeyType k) { int i; for (i = L.length; i \u003e= 1 \u0026\u0026 L.r[i].key != k; i--) ; if (i \u003e= 1) return i; else return 0; } //设置监视哨，顺序表L由后往前查找关键字k，查到返回k在L中的位置，否则返0 int SeqSearch_2(RecordList L, KeyType k) { int i; L.r[0].key = k; for (i = L.length; L.r[i].key != k; i--) ; return i; } 性能分析 $$ n为表长，c_i为比较次数\\\\ c_1=n-1+1\\\\ c_2=n-2+1\\\\ …\\\\ c_n=n-n+1\\\\ 即c_i=n-i+1\\\\ 查找每个元素的概率相等，即P_i=\\frac{1}{n}\\\\ 查找成功时平均查找长度为\\\\ ASL_{succ}=\\sum_{i=1}^nP_iC_i=\\frac{1}{n}\\sum_{i=1}^nC_i=\\frac{1}{n}\\sum_{i=1}^n(n-i+1)=\\frac{n+1}{2} $$ 注意 ASL为$O(n)$ 折半查找法 定义 折半查找（二分查找），要求： 采用顺序存储 关键字有序排列 基本过程 中间记录关键字与查找关键字比较： 如果两者相等，则查找成功； 否则如查找关键字小于中间位置关键字，则查前部子表，否则查找后部子表。 算法 int BinSrchZ(SqList L, KeyType k) { int low, high, mid; low = 1; high = L.length; //置区间初值 while (low \u003c= high) { mid = (low + high) / 2; if (k == L.r[mid].key) return mid; //查找成功 else if (k \u003c L.r[mid].key) high = mid - 1; //继续在前半区间查找 else low = mid + 1; //继续在后半区间查找 } return 0; } 性能分析 折半查找过程可用判定树描述判定树结构： 树中每一结点表示表中一记录结点值记录在表中的位置 从根到被查结点路径关键字比较次数为被查结点层数 成功进行最多比较次数不超过树深度$[\\log_2n] +1$ 假定表的长度$n=2h-1$，则相应判定树必为深度是 h 的满二叉树，$h=\\log_2(n+1)$ 折半查找成功的平均查找长度： $$ ASL_{bs}=\\sum_{i=1}^nP_iC_i=\\frac{1}{n}\\sum_{j=1}^hj×2^{j-1}=\\frac{n+1}{n}\\log_2(n+1)-1 $$ 每个记录的查找概率相等，j 为每层的比较次数，$2^{j-1}$为每层的元素个数 注意 ASL为$O(\\log_2n)$ 优点： 比较次数少 查找速度快 平均性能好 适用于固定长度频繁查找的有序表 缺点： 要求待查表为有序表 插入删除时需再排序 分块查找法 对所查表要求 等长分块，最后一块可不满 块内无序 块间有序 基本思想 分块构造索引表 定块可用顺序或折半查找关键字 k 与索引表关键字比较，确定该查记录所在块 块内顺序查找 平均查找长度 查找索引表的平均查找长度$L_B$，相应块内顺序查找的平均查找长度$L_W$ 平均查找长度：$ASL_{bs}=L_B+L_W$ 假定将长度为 n 的表分成 b 块，每块含 s 个元素，则$b=\\frac{n}{s}$， 又假定表中每个元素的查找概率相等，则每个索引项的查找概率为$\\frac{1}{b}$，块中每个元素的查找概率为$\\frac{1}{s}$。则有 顺序法平均查找长度： $$ L_B=\\frac{1}{b}\\sum_{j=1}^bj=\\frac{b+1}{2}\\\\ L_W=\\frac{1}{s}\\sum_{i=1}^si=\\frac{s+1}{2}\\\\ $$ 将$b=\\frac{n}{s}$代入得 $$ ASL_{bs}=\\frac{\\frac{n}{s}+1}{2}+1\\\\ =\\frac{b+1+s+1}{2}\\\\ =\\frac{b+s}{2}+1 $$ 折半法平均查找长度： $$ L_B=\\log_2(b+1)-1\\\\ ASL_{bs}=\\log_2(b+1)-1+\\frac{s+1}{2}\\\\ =\\log_2(\\frac{s}{n}+1)+\\frac{s-1}{2} $$ 基于树的查找法 步骤： 将待查表组织成特定树 在树结构上实现查找 有三种树： 二叉排序树 平衡二叉树 B 树 此处重点讲述二叉排序树 二叉排序树 定义 二叉树排序树或者是一棵空树，或者是具有如下性质的二叉树： 若它的左子树非空，则左子树上所有结点的值均小于根结点的值 若它的右子树非空，则右子树上所有结点的值均大于根结点的值 它的左右子树也分别为二叉排序树 插入和生成 若二叉排序树是空树，则key成为二叉排序树的根 若二叉排序树非空，key与二叉排序树的根比较： key的值小于根结点的值，则将key插入左子树 key的值大于等于根结点的值，则将key插入右子树 void CreateBST(BSTree *bst) //从键盘输入元素的值，创建相应的二叉排序树 { KeyType key; *bst = NULL; scanf(\"%d\", \u0026key); while (key != ENDKEY) { InsertBST(bst, key); scanf(\"%d\", \u0026key); } } void InsertBST(BSTree *bst, KeyType key) // key插入到bst为根的二叉排序树，从根比 { BiTree s; if (!*bst) { s = (BSTree)malloc(sizeof(BSTNode)); s-\u003ekey = key; s-\u003eLChild = s-\u003eRChild = NULL; *bst = s; } else if (key \u003c (*bst)-\u003ekey) InsertBST(\u0026((*bst)-\u003eLChild), key); else InsertBST(\u0026((*bst)-\u003eRChild), key); } 注意 插入一个结点InsertBST(bst, key)时间复杂度为$O(\\log_2n)$，创建二叉排序树 n 个结点的时间复杂度为$O(n\\log_2n)$。 技巧 对二叉排序树进行中序遍历，一定会得到一个递增有序序列。 查找 方法： 根据二叉排序树的特点，关键字 k 与根 t 比较： key = t：返回根结点地址 key \u003c t：进一步查左子树 key \u003e t：进一步查右子树 算法： 递归 BSTree SearchBST(BSTree bst, KeyType key) { if (!bst) return NULL; else if (bst-\u003ekey == key) return bst; else if (bst-\u003ekey \u003e key) return SearchBST(bst-\u003eLChild, key); else return SearchBST(bst-\u003eRChild, key); } 非递归 BSTree SearchBST_2(BSTree bst, KeyType key) //非递归查找 { BSTree q; q = bst; while (q) { if (q-\u003ekey == key) return q; //查找成功 else if (q-\u003ekey \u003e key) q = q-\u003eLChild; else q = q-\u003eRChild; } return NULL; //查找失败 } 查找性能 平均查找长度和二叉排序树的形态有关： 就平均性能而言，二叉排序树上的查找和二分查找相差不大，并且二叉排序树上的插入和删除结点十分方便，无需移动大量结点 最好情况： 二叉排序树接近二","date":"2022-02-17","objectID":"/data_structure-8/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(八)","uri":"/data_structure-8/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述非线性结构中的图。","date":"2022-02-11","objectID":"/data_structure-7/","tags":["数据结构","学习"],"title":"数据结构学习(七)","uri":"/data_structure-7/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(七) ","date":"2022-02-11","objectID":"/data_structure-7/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(七)","uri":"/data_structure-7/"},{"categories":["算法与数据结构"],"content":"非线性结构 ","date":"2022-02-11","objectID":"/data_structure-7/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(七)","uri":"/data_structure-7/"},{"categories":["算法与数据结构"],"content":"图 图的定义与基本术语 图的定义 图（Graph）是一种网状数据结构，其形式化定义如下： Graph=(V,R) V={x|x∈DataObject} R={VR} VR={\u003cx,y\u003e|P(x,y)∧(x,y∈V)} 其中， DataObject：具有相同特性的元素的集合 V：顶点（vertex）集合 VR：顶点间关系的集合 P(x,y)：表示 x 和 y 之间有特定的关联属性 P 图的抽象类型定义 数据对象 V：具有相同特性的元素的集合 结构关系：多对多 R={VR} VR={\u003cx,y\u003e|P(x,y) (xy∈V)} 操作集合： 创建GreateGraph(G) 销毁DestoryGraph(G) 确定顶点位置LocateVertex (G, v) 取第 i 个顶点GetVertex(G, i) 找顶点 v 的第一个邻接点FirstAdjVertex(G, v) 找顶点 v 的下一个邻接点NextAdjVertex(G, v, w) 插入顶点InsertVertex(G, u) 删除顶点及弧DeleteVertex(G, v) 插入弧lnsertArc (G, v, w) 删除弧DeleteArc (G, v, w) 遍历TraverseGraph(G) 基本术语 图 无向图：图中边无方向 有向图：图中边有方向 有向完全图：图中每个顶点和其余 n-1 个顶点都有弧相连（总共$n×(n-1)$条边） 无向完全图：图中每个顶点和其余 n-1 个顶点都有边相连（总共$\\frac{n×(n-1)}{2}$条边） 子图：若 G' 的顶点包含于 G 的顶点，则称图 G' 为 G 的子图 连通图：对于图中任意两个顶点都是连通的 连通分量：无向图中的极大连通子图 强连通图：任意两个顶点之间互相可达 强连通分量：有向图的极大强连通子图 邻接点：两顶点之间存在边，则称其互为邻接点 路径和回路 路径：顶点序列 路径长度：顶点序列上经过的边的个数 回路或环：起点和终点相同 简单路径：顶点序列中的顶点各不相同的路径 简单回路：除了第一个和最后一个顶点外，其余各顶点均不重复出现的回路 度 无向图的度：顶点 V 的度 TD(V)——和 V 相连的边的个数 有向图的度：入度+出度 入度 ID(V)：进来的弧 出度 OD(V)：出去的弧 度的计算公式：n 个顶点，e 条边或弧，则有 $$ 2e=\\sum_{i=1}TD(V_i) $$ 权和网 权：图的边或弧上与它相关的数（可以表示从一个顶点到另一个顶点的距离或耗费等信息） 赋权图（网）：带权的图 生成树：极小连通子图，含有连通图全部顶点 n 并有 n-1 条边 顶点在图中的位置：人为排列中的位置序号，可将任一顶点看作图的第一个顶点，对任一顶点其邻接点间不存在顺序关系 图的存储结构 显然，我们需要存储顶点和顶点间关系两部分信息，对此我们有如下四种办法 邻接矩阵表示法（数组表示法） 定义 用两个数组来表示图：存储顶点信息的一维数组、存储顶点关联关系的二维数组（邻接矩阵） 表示 G 是一具有 n 个顶点的无权图，G 的邻接矩阵是如下性质的 n×n 矩阵 A： $$ A[i,j]= \\begin{cases} 1 \u0026若\u003cv_i,v_j\u003e或(v_i,v_j)∈VR\\\\ 0 \u0026反之 \\end{cases} $$ 若图 G 是一个有 n 个顶点的网，则它的邻接矩阵是具有如下性质的 n×n 矩阵 A： $$ A[i,j]= \\begin{cases} W_{ij} \u0026若\u003cv_i,v_j\u003e或(v_i,v_j)∈VR\\\\ 0或∞ \u0026反之 \\end{cases} $$ 例如： $$ A=\\left( \\begin{array}{cccc} 0 \u0026 1 \u0026 1 \u0026 1\\\\ 1 \u0026 0 \u0026 0 \u0026 0\\\\ 1 \u0026 0 \u0026 0 \u0026 1\\\\ 1 \u0026 0 \u0026 1 \u0026 0\\\\ \\end{array} \\right) $$ C语言类型描述 #define VRType int #define InfoType char #define VertexType int #define MAX_VERTEX_NUM 20 #define INFINITY 32678 typedef enum { DG, //有向 DN, //有向网 UDG, //无向 UDN //无向网 } GraphKind; typedef struct { VRType adj; //对于无权图，用 1 或 0 表示是否相邻；对于带权图，直接为权值 InfoType *info; //弧或边额外含有的信息指针 } ArcNode; typedef struct { VertexType vexs[MAX_VERTEX_NUM]; //顶点 ArcNode arcs[MAX_VERTEX_NUM][MAX_VERTEX_NUM]; //顶点之间的关系 int vexnum, arcnum; //顶点数，弧数 GraphKind kind; //图的种类 } AdjMatrix; 特点 存储空间： 无向图 邻接矩阵是对称矩阵，可采用下三角压缩存储只需$\\frac{n×(n-1)}{2}$空间 有向图 邻接矩阵不一定是对称矩阵，所以需要$n^2$个存储空间。 便于运算： 根据$A[i,j]=0或1$来判定图中任意两个顶点之间是否有边相连 便于求各个顶点的度 无向图：其邻接矩阵第 i 行元素之和就是图中第i 个顶点的度 $$ TD(v_i)=\\sum_{j=1}^nA[i,j] $$ 有向图：第 i 行元素之和就是图中第 i 个顶点的出度；第 i 列元素之和就是图中第 i 个顶点的入度。 $$ OD(v_i)=\\sum_{j=1}^nA[i,j]\\\\ ID(v_i)=\\sum_{j=1}^nA[j,i] $$ 便于实现一些基本操作 创建有向网的算法 bool CreateDN(AdjMatrix *G) { int i, j, k, weight; VertexType v1, v2; scanf(\"%d,%d\", \u0026G-\u003earcnum, \u0026G-\u003evexnum); for (i = 0; i \u003c G-\u003evexnum; i++) for (j = 0; j \u003c G-\u003evexnum; j++) G-\u003earcs[i][j].adj = INFINITY; //初始化 for (i = 0; i \u003c G-\u003evexnum; i++) scanf(\"%c\", \u0026G-\u003evexs[i]); //读取顶点的一维数组 for (k = 0; k \u003c G-\u003earcnum; k++) { scanf(\"%c,%c,%d\", \u0026v1, \u0026v2, \u0026weight); i = LocateVex_M(G, v1); j = LocateVex_M(G, v2); G-\u003earcs[i][j].adj = weight; //生成顶点 } return true; } 邻接表表示法 基本思想 采用链式结构存储图，只存储图中有关联的边的信息： 对图中 n 个顶点均建有关联的边链表 每个顶点信息与其边链表的头指针构成表头结点表 结构构成 表头结点表： 由所有表头结点以顺序结构的形式存储，以便可以随机访问任一顶点的邻接点单链表。 $$ \\begin{array}{|c|c|} \\hline vexdata(数据域) \u0026 firstarc(链域)\\\\\\hline \\end{array} $$ 边表： 由表示图中顶点间邻接关系的 n 个边链表组成。 $$ \\begin{array}{|c|c|c|} \\hline adjvex(邻接点域) \u0026 info(数据域) \u0026 nextarc(链域)\\\\\\hline \\end{array} $$ 图例 结构类型定义 #define VertexType int #define InfoType int #define MAX_VERTEX_NUM 20 typedef enum { DG, DN, UDG, UDN } GraphKind; typedef struct ArcNode { int adjvex; //邻接点在数组中的位置下标 struct ArcNode *nextarc; //指向下一个邻接点的指针 InfoType *info; //信息域 } ArcNode; typedef struct VNode { VertexType data; //顶点的数据域 ArcNode *firstarc; //指向邻接点的指针 } VNode; typedef struct { VNode vertex[MAX_VERTEX_NUM]; //存储各链表头结点的数组 int vexnum, arcnum; //顶点数和边或弧数 GraphKind kind; //图的种类 } AdjList; 存储空间 n 个顶点，e 条边的无向图： 采取邻接表作为存储结构，需要 n 个表头结点和 2e 个表结点。 无向图的度 在无向图的邻接表中，顶点$V_i$的度恰好就是第 i 个边链表上结点的个数 有向图的度 有向图中，第 i 个边链表上顶点的个数是顶点$V_i$的出度。 求该顶点的入度，须遍历整个邻接表。在所有单链表中，查找邻接点域的值为 i 的结点并计数求和。 解决方案 逆邻接表法： 对每一顶点$V_i$再建立一个所有以顶点$V_i$为弧头的弧的表（逆邻接表)。求顶点$V_i$的入度即是计算逆邻接表中第 i 个顶点的边链表中节点个数 正向邻接表求出度，逆向邻接表求入度。 十字链表 定义 十字链表是有向图的","date":"2022-02-11","objectID":"/data_structure-7/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(七)","uri":"/data_structure-7/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述非线性结构中的树。","date":"2022-02-02","objectID":"/data_structure-6/","tags":["数据结构","学习"],"title":"数据结构学习(六)","uri":"/data_structure-6/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(六) ","date":"2022-02-02","objectID":"/data_structure-6/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(六)","uri":"/data_structure-6/"},{"categories":["算法与数据结构"],"content":"非线性结构 ","date":"2022-02-02","objectID":"/data_structure-6/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(六)","uri":"/data_structure-6/"},{"categories":["算法与数据结构"],"content":"树 树的定义与基本术语 树的基本概念 树（Tree）是n (n≥0）个结点的有限集合T。当n=0时，称为空树；当n\u003e0时，该集合满足如下条件: 必有一个称为根（root）的特定结点，它没有直接前驱，但有零个或多个直接后继 其余 n-1 个结点可以划分成 m (m≥0）个互不相交的有限集 T1，T2，T3,…，Tm，其中 Ti 又是一棵树，称为根 root 的子树。每棵子树的根结点有且仅有一个直接前驱，但有零个或多个直接后继。 树的图解表示 倒置树结构法（树形表示法） 文氏图表示法（嵌套集合形式） 广义表形式（嵌套括号表示法） 凹入表示法 树的相关术语 结点：包括一个数据元素及若干指向其它结点的分支信息。 结点的度：结点的子树个数 叶结点：度为 0 的结点，即无后继的结点，也称为终端结点 分支结点：度不为 0 的结点称为非终端结点 树的度：树中所有结点的度的最大值 结点的层次：从根结点开始定义根结点的层次为 1，根的直接后继的层次为 2，依此类推 树的高度：树中所有结点的层次的最大值 有序树：各子树之间有先后次序 森林：多颗互不相交的树的集合 孩子结点：直接后继结点 双亲结点：直接前驱结点 兄弟结点：同一双亲结点的孩子结点之间互称兄弟结点 祖先结点：从根到该结点路径上的所有结点 孙子结点：直接后继和间接后继 树的抽象数据类型 数据对象 D：该集合中的所有元素具有相同的特性 结构关系 R：若 D 为空集，则为空树；若 D 中仅含有一个数据元素，则 R 为空集，否则 R={H}，H 是如下的二元关系: D中存在唯一的根元素 root，在关系 H 中无前驱 除 root 以外，D 中每个结点在关系 H 下都有且仅有一个前驱 操作集合： 初始化树lnitTree(Tree) 销毁树DestoryTree(Tree) 创建树CreateTree(Tree) 判空TreeEmpty(Tree) 求根Root(Tree) 求双亲Parent(Tree，x) 找 x 结点的第一个孩子FirstChild(Tree，x) 找 x 结点的下一个兄弟NextSibling(Tree，x) 插入孩子结点InsertChild(Tree，p, Child) 删除孩子结点DeleteChild(Tree，p, i) 遍历树TraverseTree(Tree，Visit()) 二叉树 二叉树的定义与基本操作 二叉树（Binary Tree）： 每个结点的度都不大于 2 每个结点的孩子结点次序不能任意颠倒 10 种操作： 初始化lnitiate(bt) 创建Create(bt) 销毁Destory(bt） 判空Empty(bt) 求根Root(bt) 求双亲结点Parent(bt, x) 求左孩子LeftChild(bt，x) 求右孩子RightChild(bt，x) 遍历Traverse(bt) 清空Clear(bt) 二叉树性质 在二叉树的第 i 层的最大结点数为$2^{i-1}$ 深度为 k 的二叉树的最大结点数： $$ \\sum_{i=1}^{k}2^{i-1}=2^{k-1} $$ 对任意一棵二叉树，若终端结点数为$n_0$，而其度数为 2 的结点数为$n_2$，则$n_0=n_2+1$ 满二叉树：有最大结点数，即每层结点都是满的 完全二叉树：深度为 k，结点数为 n 的二叉树，结点 1~n 的位置序号分别与满二叉树的结点 1~n 的位置序号一一对应 注意 满二叉树必为完全二叉树，而完全二叉树不一定是满二叉树 具有 n 个结点的完全二叉树的深度为 $$ [\\log_2n]+1\\\\ eg:[\\log_27]+1=3 $$ 对于有 n 个结点的完全二叉树，按照从上到下和从左到右的顺序编号结点，则序号 i 结点有以下关系： 若 i =1，则 i 无双亲结点； 若 i\u003e1，则 i 的双亲结点为$[\\frac{i}{2}]$ 若$2×i\u003en$，则 i 无左孩子; 若$2×i≤n$，则 i 结点的左孩子结点为$2×i$ 若$2×i+1\u003en$，则 i 无右孩子; 若$2×i+1≤n$，则 i 的右孩子结点为$2×i+1$ 二叉树存储结构 顺序存储 以完全二叉树的形式来存储数据元素，但对于一般二叉树，这将造成极大的空间浪费。 举个栗子 单支树是其极端情况，例如一颗深度 4 的单支树，我们需要用 15 个结点空间来存储这 4 个结点。 链式存储 我们采用二叉链表来存储二叉树，其中每个结点需要有三个域： $$ \\begin{array}{|c|c|c|} \\hline LChild \u0026 Data \u0026 RChild\\\\\\hline \\end{array} $$ typedef struct Node { char data; struct Node *LChild, *RChild; } BiTNode, *BiTree; 有时，为了寻找其双亲结点，我们还会增设Parent域形成三叉链表 $$ \\begin{array}{|c|c|c|c|} \\hline LChild \u0026 Data \u0026 Parent \u0026 RChild\\\\\\hline \\end{array} $$ 二叉树的遍历与线索化 二叉树的遍历 含义：指按一定规律对二叉树中的每个结点访问且仅访问一次。 目的：将非线性结构经过遍历得到结点访问序列，也就是线性化过程 按照先左后右，相对于根的顺序，有以下三种方式： DLR 先序遍历 LDR 中序遍历 LRD 后序遍历 对于下面这个二叉树，三种遍历方法有不同的结果 DLR的递归定义 void PreOrder(BiTree root) { if (root) { Visit(root-\u003edata); PreOrder(root-\u003eLChild); PreOrder(root-\u003eRChild); } } 结果：ABDFGCEH LDR的递归定义 void InOrder(BiTree root) { if (root) { InOrder(root-\u003eLChild); Visit(root-\u003edata); InOrder(root-\u003eRChild); } } 结果：BFDGACEH LRD的递归定义 void PostOrder(BiTree root) { if (root) { PostOrder(root-\u003eLChild); PostOrder(root-\u003eRChild); Visit(root-\u003edata); } } 结果：FGDBHECA 遍历算法应用 输出二叉树中的结点（先序遍历） void PreOrder(BiTree root) { if (root) { printf(\"%c\",root-\u003edata); PreOrder(root-\u003eLChild); PreOrder(root-\u003eRChild); } } 输出二叉树中的叶子结点（先序遍历） void PreOrder(BiTree root) { if (root) { if (root-\u003eLChild == NULL \u0026\u0026 root-\u003eRChild == NULL) printf(\"%c\", root-\u003edata); PreOrder(root-\u003eLChild); PreOrder(root-\u003eRChild); } } 统计叶子结点数目（后序遍历） //方法一 int LeafCount = 0; void leaf_1(BiTree root) { if (root) { leaf_1(root-\u003eLChild); leaf_1(root-\u003eRChild); if (root-\u003eLChild == NULL \u0026\u0026 root-\u003eRChild == NULL) LeafCount++; } } //方法二 int leaf_2(BiTree root) { int LeafCount; if (root) LeafCount = 0; else if (root-\u003eLChild == NULL \u0026\u0026 root-\u003eRChild == NULL) LeafCount = 1; else LeafCount = leaf_2(root-\u003eLChild) + leaf_2(root-\u003eRChild); return LeafCount; } 建立二叉链表存储的二叉树 void CreateBiTree(BiTree *bt) { char ch; ch = getchar(); if (ch == '.') *bt = NULL; else { *bt = (BiTree)malloc(sizeof(BiTNode)); (*bt)-\u003edata = ch; CreateBiTree(\u0026((*bt)-\u003eLChild)); CreateBiTree(\u0026((*bt)-\u003eRChild)); } } 按树状横向打印二叉树（中序遍历） void PrintTree(BiTree root, int nLayer) { if (!root) return; PrintTree(root-\u003eRChild, nLayer + 1); for (int i = 0; i \u003c nLayer; i++) printf(\" \"); printf(\" %c\\n\", root-\u003edata); PrintTree(root-\u003eLChild, nLayer + 1); } 基于栈的递归消除 在数据结构学习(三)#栈的应用与递归中已经简单地介绍了递归的一系列问题，但并没有介绍基于栈的递归消除方法。本节将讲解此部分内容。 中序遍历的非递归算法（直接实现栈操作） void ","date":"2022-02-02","objectID":"/data_structure-6/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(六)","uri":"/data_structure-6/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述线性结构中的数组与广义表","date":"2022-01-29","objectID":"/data_structure-5/","tags":["数据结构","学习"],"title":"数据结构学习(五)","uri":"/data_structure-5/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(五) ","date":"2022-01-29","objectID":"/data_structure-5/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(五)","uri":"/data_structure-5/"},{"categories":["算法与数据结构"],"content":"线性结构 ","date":"2022-01-29","objectID":"/data_structure-5/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(五)","uri":"/data_structure-5/"},{"categories":["算法与数据结构"],"content":"数组 数组的定义与运算 数组：是一组有固定个数的数据元素集合，是一般线性表的推广，组成线性表的元素为带有结构信息的元素。 —维数组为向量形式的线性表; 二维数组是由一维数组组成的线性表，依次类推可得到多维数组定义。 对于数组 ADT 数据对象：高维数组组成的线性表 $$ D={a_{j1j2…jn}|\\ n\u003e0,1≤j_i≤b_i,a_{j1j2…jn}∈ElementSet} $$ 其中，n 称为数组的维数，j 是数组的第 i 维下标，b 是数组第 i 维的长度。 结构关系：线性序列 $$ R={R_1,R_2,…,R_n} $$ 有 4 种基本操作： 初始化InitArray(A, n, bound1,…, boundn) 销毁DestroyArray(A) 取值GetValue(A, e, index1,…, indexn) 修改SetValue(A, e, index1,…, indexn) 数组的顺序存储与实现 数组适合顺序存储： 给定数组维数及各维长度，数组元素个数固定 元素存取运算不改变数组大小 同时，计算机内存储器是一维的，可直接顺序存储一维数组，但高维数组则是按照某种次序把高维映射到一维。 按行序存储，如 BASIC、C 语言 按列序存储，如 FORTRAN 语言（世界上第一个被正式推广使用的高级语言） 对于数组中，给定下标计算其在一维空间的存储位置有以下公式： $$ 数组元素地址=基址+(该变量线性序号-1)*size $$ 举个栗子 对于一维数组A=(a1,a2,…,an)，每个元素占据size个存储单元。 则元素 ai 的存储地址为 $$ Loc(a[i])=Loc(a[1])+(i-1)×size $$ 问题 二维数组a[5][4]按行序存放，每个元素占 4 单元,首元素地址是 2000 ，求a[3][2]的内存地址。 答案 类似与举个栗子中一维数组的公式，二维数组（下标从 1 开始）中有 $$ Loc(a[i][j])=Loc(a[1][1])+(n×(i-1)+(j-1))×size $$ 故本题答案为 $$ Loc(a[3][2]) = 2000+(4×(3-1) +(2-1))×4=2036 $$ 我们还可以对此推广至一般三维数组，其下限为c1、c2、c3，上限为d1、d2、d3，则 $$ Loc(A[j_1][j_2][j_3])=Loc(A[c_1][c_2][c_3])+((d_2-c_2+1)×(d_3-c_3+1)×(j_1-c_1)+(d3-c3+1)×(j_2-c_2)+(j_3-c_3))×size $$ 信息 上述数组可记作A[c1..d1,c2..d2,c3..d3] 再做进一步的推广至 n 维，有 $$ Loc[j_1,j_2,…,j_n]=Loc[c_1,c_2,…,c_n]+\\sum_{i=1}^Na_i×(j_i-c_i) $$ 其中 $$ a_i=size×\\prod_{k=i+1}^n(d_k-c_k+1)\\ (1≤i≤n) $$ 注意 地址计算的题目容易出现在各种考试中，但这些公式不应该去死记硬背，而是重在理解！ 规律分布特殊矩阵的压缩存储 原则：对有规律的元素和值相同的元素只分配一个存储单元，对于零元素不分配空间。 思想：按规律找出地址计算公式 三角矩阵 $$ A= \\begin{pmatrix} a_{11} \u0026 \u0026 \\\\ a_{21} \u0026 a_{22} \u0026 \\\\ a_{31} \u0026 a_{32} \u0026 a_{33}\\\\ \\end{pmatrix} \\rightarrow \\begin{array}{|c|} \\hline a_{11}\\\\\\hline a_{21}\\\\\\hline a_{22}\\\\\\hline ··· \\\\\\hline a_{nn}\\\\\\hline \\end{array} $$ 显然，此一维存储空间的大小以及地址计算公式为： $$ \\sum_{i=1}^ni=\\frac{n(n+1)}{2}\\\\ Loc[i,j]=Loc[1,1]+(\\frac{i(i-1)}{2}+j-1)*size\\ (i\u003ej) $$ 带状矩阵 $$ A_{n×n}= \\begin{pmatrix} a_{11} \u0026 a_{12} \u0026\\\\ a_{21} \u0026 a_{22} \u0026 a_{23}\\\\ \u0026 a_{32} \u0026 a_{33} \u0026 a_{34}\\\\ \u0026 \u0026 a_{43} \u0026 a_{44} \u0026 a_{45}\\\\ \u0026 \u0026 \u0026 … \u0026 … \u0026 … \\end{pmatrix} \\rightarrow \\begin{array}{|c|} \\hline a_{11}\\\\\\hline a_{12}\\\\\\hline a_{21}\\\\\\hline a_{22}\\\\\\hline a_{23}\\\\\\hline ··· \\\\\\hline a_{nn}\\\\\\hline \\end{array} $$ 显然，此一维存储空间的大小为 $$ 3n-2 $$ 又注意到元素下标 i、j 有以下关系： $$ j-i= \\begin{cases} -1 \u0026,j\u003ci对角线下 \\\\ 0 \u0026,j=i对角线 \\\\ 1 \u0026,j\u003ei对角线上 \\end{cases} $$ 故而 $$ 前i-1行元素个数=3(i-1)-1\\\\ 当前行元素序号=j-i+1 $$ 由此，地址计算公式为 $$ Loc(A[i][j])=Loc(A[1][1])+(3(i-1)-1+j-i+1)*size\\\\ =Loc(A[1][1])+(2(i-1)+j-1)*size $$ 举个栗子 基地址为 2000，size 为1，求元素 a23 的地址？ WP：前 1 行有 3(2-1)-1=2 个元素，第 2 行元素序号为 3-2+1=2，故 $$ Loc(A[2][3])=2000+(2+2)×1=2004 $$ 稀疏矩阵的压缩存储 稀疏矩阵：指矩阵中大多数元素为零的矩阵。一般地，当非零元素个数只占矩阵元素总数的25%~30%，或低于这个百分数时，我们称这样的矩阵为稀疏矩阵。 三元组表表示法 由于稀疏矩阵中非零元的毫无规律，我们需要在存储值的同时也存储其行号和列号，这样的方法称为三元组表表示法。 #define MAXSIZE 1000 typedef struct { int row, col; int e; } Triple; typedef struct { Triple data[MAXSIZE + 1]; int m, n, len; // m行n列，非零元有len个 } TSmatrix; 经典转置法 void TransMatrix(int source[n][m], int dest[m][n]) { int i, j; for (i = 0; i \u003c m; i++) for (j = 0; j \u003c n; j++) dest[i][j] = source[j][i]; } 列序递增转置法 $$ \\begin{pmatrix} 1 \u0026 \u0026 2\\\\ \u0026 3 \u0026 \\\\ 4 \u0026 \u0026 5\\\\ \u0026 6 \u0026 \\\\ \\end{pmatrix} $$ 此稀疏矩阵的三元组表为 row col e 1 1 1 1 2 1 3 2 3 2 2 3 4 3 1 4 5 3 3 5 6 4 2 6 易于发现，仅做行列互换（交换row和col）并没有完成转置操作，因为行列互换后没有做到以行序为主序，此时还需要对行下标做排序。 对此，我们有两种方法，其一是依次扫描col为 1 到 n，即列序递增转置法。 void TransposeTSMatrix(TSmatrix A, TSmatrix *B) { int i, j, k; B-\u003em = A.n; B-\u003en = A.m; B-\u003elen = A.len; if (B-\u003elen) { j = 1; for (k = 1; k \u003c= A.n; k++) for (i = 1; i \u003c= A.len; i++) if (A.data[i].col == k) { B-\u003edata[j].row = A.data[i].col; B-\u003edata[j].col = A.data[i].row; B-\u003edata[j].e = A.data[i].e; j++; } } } 易得出，该算法时间复杂度为 $$ O(A.n×A.len) $$ 此算法大大降低了存储空间的开销，但时间耗费并未降低，原因在于要多次扫描稀疏矩阵三元组。 一次定位法 为了提高算法性能，我们想通过一次循环完成转置，即对 A 中非零元“一次定位”直接放到 B 三元表中。 需设置两个数组存放预先计算的值，实现一次定位： num[col]存放 A 三元组 col 列非零元个数 position[col]存放 A 三元组 col 列第一个非零元位置 由此，我们可得出一条递归关系position[col] = position[col-1] + num[col-1]其中 2\u003c=col\u003c=A.n。 void FastTransposeTSMatrix(TSmatrix A, TSmatrix *B) { int col, t, p, q, num[MAXSIZE], position[MAXSIZE]; B-\u003elen = A.len; B-\u003em = A.n; B-\u003en = A.m; if (B-\u003elen) { for (col = 1; col \u003c= A.n; col++) num[col] = 0; for (t = 1; t \u003c= A.len; t++) num[A.data[t].col]+","date":"2022-01-29","objectID":"/data_structure-5/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(五)","uri":"/data_structure-5/"},{"categories":["算法与数据结构"],"content":"广义表 广义表是线性表的推广，是 n 个数据元素的有限序列。记作： $$ GL=(d_1,d_2,…,d_n) $$ 称 n 为广义表长度，GL 为广义表名。 若广义表的元素也是广义表，则称其为子表，也就是说广义表是递归定义的。 规定：广义表元素大写，单元素小写，d1 为表头，其余元素构成的表 (d2, d3, …, dn) 是表尾。 广义表的存储结构 广义表的头尾链表存储结构 由于广义表的特性，我们需要有两类结点：单元素结点、表结点。 对于表结点，需要有三个域：标志域、指向表头的指针域、指向表尾的指针域。 而对于但元素结点，只需要两个域：标志域、值域。 typedef enum { ATOM, LIST } ElemTag; // ATOM表示原子默认值0，LIST表示子表默认值1 typedef struct GLNode { ElemTag tag; //标志域 union { int atom; //原子结点值域 struct { struct GLNode *hp, tp; } htp; //表结点 } atom_htp; //联合体域 } * GList; 广义表的同层结点链存储结构 单元素结点和子表结点均由三个域组成。 typedef enum { ATOM, LIST } ElemTag; typedef struct GLNode { ElemTag tag; //标志域 union { int atom; //原子结点值域 struct GLNode *hp; } atom_hp; //联合体域 struct GLNode *tp; } * GList; ","date":"2022-01-29","objectID":"/data_structure-5/:1:2","tags":["数据结构","学习"],"title":"数据结构学习(五)","uri":"/data_structure-5/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述线性结构中的字符串","date":"2022-01-28","objectID":"/data_structure-4/","tags":["数据结构","学习"],"title":"数据结构学习(四)","uri":"/data_structure-4/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(四) ","date":"2022-01-28","objectID":"/data_structure-4/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(四)","uri":"/data_structure-4/"},{"categories":["算法与数据结构"],"content":"线性结构 ","date":"2022-01-28","objectID":"/data_structure-4/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(四)","uri":"/data_structure-4/"},{"categories":["算法与数据结构"],"content":"串 串的定义 字符串（string）：零个或多个字符组成的有限序列。记为 $$ S=‘a_1a_2…a_n’\\ (n≥0),a_i∈V字符集合 $$ 组成线性表的每个元素就是一个单字符串是特定的线性表 串的名字：S 串的值：单引号括起来的字符序列，可以是字母，数字或其他字符 串的长度：n，串中字符的个数 空串（Null String）：n=0 时的串 举个栗子 ch='hello world'就是字符串长度为 11 ，串名为 ch 的字符串 子串：串中任意个连续字符组成的子序列。 主串：包含子串的串。 求子串：sub(主串，起始位置，长度) 举个栗子 sub('china',2,2)='in' 模式串在主串中的位置（串的模式匹配）：从主串的起始位置起，模式串在主串中首次出现的位置序号 举个栗子 主串'Beijing,China'模式串in： 若起始位置为 0，则模式串第一个字符在主串中的位置为 4； 若起始位置为 5，则模式串第一个字符在主串中的位置为 10。 串相等：当且仅当两个串长度相等且对应位置的字符都相等。 空串与空格串的区别： 空格串：一个或多个空格组成的串，其长度为空格个数。 空串：无任何字符组成的串，其长度为零。 对于串 ADT： 数据对象：字符集 $$ D={a_i|\\ a_i∈CharacterSet,\\ i=1,2,…,n;\\ n≥0} $$ 数据关系：线性关系 $$ R={\u003ca_{i-1},a_i\u003e|\\ a_{i-1},a_i∈D,\\ i=1,2,…,n;\\ n≥0} $$ 有 13 种基本操作运算： 赋值StrAsign(S, str) 插入StrInsert(S, pos, T) 删除StrDelete(S, pos, len) 拷贝StrCopy(S, T) 判空StrEmpty(S) 比较StrCompare(S, T) 求串长StrLength(S) 清空StrClear(S) 连接StrCat(S, T) 求子串SubString(Sub, S, pos, len) 串的模式匹配Strlndex(S, T, pos) 置换StrReplace(S, T, V) 消除StrDestroy(s) 串的顺序存储 定长顺序串 #define MAXLEN 20 typedef struct { char ch[MAXLEN]; int len; } SString; 串插入 在进行串的插人时，插人位置 pos 将串分为两部分（假设为 A、B，长度为 LA、LB），及待插人部分（假设为 C，长度为 LC），则串由插人前的 AB 变为 ACB ，可能有三种情况： 插入后串长 (LA+LB+LC) ≤ MAXLEN： 将 B 后移 LC 个元素位置，再将 C 插人 插入后串长 \u003e MAXLEN 且 pos + LC \u003c MAXLEN： B 后移时会有部分字符被舍弃 插入后串长 \u003e MAXLEN 且 pos + LC \u003e MAXLEN： B 的全部字符被舍弃（不需后移），并且在插人时也有部分字符被舍弃 bool StrInsert(SString *s, int pos, SString t) //在串s中序号为pos的字符之前插入串t { int i; if (pos \u003c 0 || pos \u003e s-\u003elen) //插入位置不合法 return false; if (s-\u003elen + t.len \u003c= MAXLEN) //插入后串长≤MAXLEN { for (i = s-\u003elen + t.len - 1; i \u003e= t.len + pos; i--) s-\u003ech[i] = s-\u003ech[i - t.len]; for (i = 0; i \u003c t.len; i++) s-\u003ech[i + pos] = t.ch[i]; s-\u003elen += t.len; } else if (pos + t.len \u003c= MAXLEN) //插入后串长\u003eMAXLEN,但串t可以全部插入 { for (i = MAXLEN - 1; i \u003e t.len + pos - 1; i--) s-\u003ech[i] = s-\u003ech[i - t.len]; for (i = 0; i \u003c t.len; i++) s-\u003ech[i + pos] = t.ch[i]; s-\u003elen = MAXLEN; } else //串t的部分要舍弃 { for (i = 0; i \u003c MAXLEN - pos; i++) s-\u003ech[i + pos] = t.ch[i]; s-\u003elen = MAXLEN; } return true; } 串的模式匹配 int index(SString s, int pos, SString t) //从主串s的pos位置起,与模式串t逐位匹配 { int i, j; if (!t.len) return 0; //空串是任意串的子串 i = pos; j = 0; while (i \u003c s.len \u0026\u0026 j \u003c t.len) if (s.ch[i] == t.ch[j]) { i++; j++; } else { i = i - j + 1; //对应字符不等，主串从起始位置下一位起 j = 0; } if (j \u003e= t.len) return i - j; else return -1; //匹配不成功，返回-1 } 注意到时间主要耗费在了 while 循环即回溯中，这种算法也称为 BF 算法（或暴力匹配算法）其时间复杂度为 $$ O(s.len*t.len) $$ 对于该算法的改进，重点在于实现非回溯，其中的佼佼者 KMP 算法能在时间复杂度上达到 $$ O(n+m) $$ 这里仅给出其代码，详解：KMP算法（快速模式匹配算法）C语言详解 #include \u003cstdio.h\u003e#include \u003cstring.h\u003e void Next(char *T, int *next) { int i = 1; next[1] = 0; int j = 0; while (i \u003c strlen(T)) { if (j == 0 || T[i - 1] == T[j - 1]) { i++; j++; next[i] = j; } else { j = next[j]; } } } int KMP(char *S, char *T) { int next[10]; Next(T, next); //根据模式串T,初始化next数组 int i = 1; int j = 1; while (i \u003c= strlen(S) \u0026\u0026 j \u003c= strlen(T)) { // j==0:代表模式串的第一个字符就和当前测试的字符不相等；S[i-1]==T[j-1],如果对应位置字符相等，两种情况下，指向当前测试的两个指针下标i和j都向后移 if (j == 0 || S[i - 1] == T[j - 1]) { i++; j++; } else { j = next[j]; //如果测试的两个字符不相等，i不动，j变为当前测试字符串的next值 } } if (j \u003e strlen(T)) { //如果条件为真，说明匹配成功 return i - (int)strlen(T); } return -1; } int main() { int i = KMP(\"ababcabcacbab\", \"abcac\"); printf(\"%d\", i); return 0; } 堆串 堆：系统将一个地址连续、容量很大的存储空间作为字符串的可用空间。 每建立新串时，需提供串值的起始位置指针和串长度,示统从堆串区分配空间。 串的链式存储 块链串是有头尾指针的链表，其中单个结点称为块。 结点大小：data 域存放字符个数 结点大小为 1 时，存储密度低，处理简单，是单链表 结点大小大于 1 时，存储密度高，管理复杂 链域大小：next 域占用字符个数 #define BLOCK_SIZE 4 typedef struct { char ch[BLOCK_SIZE]; struct Block *next; } Block; typedef struct { Block *head; Block *tail; int len; } BLString; 这里仅给出普通模式匹配算法（BF算法）用链式存储的实现，其他内容的具体操作与单链表类似，请看数据结构学习(二) Block *StrIndex(BLString *s, BLString *t) { Block *sp, *tp, *start; if (!t-\u003elen) return s-\u003ehead-\u003enext; start = s-\u003ehead-\u003enext; sp = start; tp = t-\u003ehead-\u003enext; while (sp != NULL \u0026\u0026 tp != NULL) { if (sp-\u003ech == tp-\u003ech) { sp = sp-\u003enext; tp = tp-\u003enext; } else { start = start-\u003enext; sp = start; tp = t-\u003ehead-\u003enext; } } if (tp == NULL) return start; else return NULL; } 问题 假设主串S='aaabbbababaabb' ,模式串P='abaa' ，用 BF 算法从主串的第 6 个字符开始进行模式匹配，需要做多少趟匹配，第2趟匹配做多少次比较？ 答案 4趟，4次 ","date":"2022-01-28","objectID":"/data_structure-4/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(四)","uri":"/data_structure-4/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述线性结构中的限定性线性表——栈和队列。","date":"2022-01-24","objectID":"/data_structure-3/","tags":["数据结构","学习"],"title":"数据结构学习(三)","uri":"/data_structure-3/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(三) ","date":"2022-01-24","objectID":"/data_structure-3/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(三)","uri":"/data_structure-3/"},{"categories":["算法与数据结构"],"content":"线性结构 ","date":"2022-01-24","objectID":"/data_structure-3/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(三)","uri":"/data_structure-3/"},{"categories":["算法与数据结构"],"content":"限定性线性表——栈和队列 限定性：限制线性表插入和删除等运算的位置（只允许在端点位置操作） 栈 栈的定义与实现 栈的定义：把运算位置限制在表尾端 栈顶：允许运算端 栈底：不允许运算端 栈顶指示器：用来指示动态变化的栈顶位置 空栈：表中无任何元素 满栈：无法申请到栈区可用空间 栈的常见运算：进栈（入栈）、退栈（出栈） 上溢：栈已满还入栈 下溢：栈已空还出栈 栈的特性：后进先出（Last In First Out, LIFO） 对于栈 ADT： 数据元素：同一个数据对象的任意类型数据 关系：栈中数据元素之间是线性关系 有 7 种基本操作运算： 初始化InitStack(S) 清栈ClearStack(S) 判空IsEmpty(S) 判满IsFull(S) 进栈Push(S, x) 出栈Pop(S, x) 读栈顶GetTop(S, x) 问题 按1，2，3的顺序进栈，则出栈顺序有哪些? 答案 元素在进栈过程中也可以出栈，也就是并非所有元素全部进栈后再出栈。 因此，出栈顺序有：123，132，213，231，321 栈的顺序实现 用一组连续的存储单元依次存放自栈底到栈顶的数据元素 设一个位置指针top（栈顶指针）动态指示栈顶元素在顺序栈中的位置 top = -1 表示空栈 #define Stack_Size 50 typedef struct { int elem[Stack_Size]; int top; } SeqStack; void InitStack(SeqStack *S) { S-\u003etop = -1; } bool IsEmpty(SeqStack S) { return S.top == -1; } bool IsFull(SeqStack S) { return S.top == Stack_Size - 1; } bool push(SeqStack *S, int x) { if (IsFull(*S)) return false; S-\u003etop++; S-\u003eelem[S-\u003etop] = x; return true; } bool pop(SeqStack *S, int *x) { if (IsEmpty(*S)) return false; *x = S-\u003eelem[S-\u003etop]; S-\u003etop--; return true; } bool GetTop(SeqStack S, int *x) { if (IsEmpty(S)) return false; *x = S.elem[S.top]; return true; } 顺序实现的两栈共享技术 为两个栈申请一个共享的一维数组空间S[M]，将两个栈的栈底分别为一维数组的两端 0 和 M-1。 值得注意的是，判满条件应为S-\u003etop[0] + 1 == S-\u003etop[1]即栈顶指示器相邻，并且一个栈空并不会影响另一个栈是否为空。 #define M 100 typedef struct { int Stack[M]; //栈区 int top[2]; // top[0]、top[1]为两个栈顶指示器 } DqStack; void InitStack(DqStack *S) { S-\u003etop[0] = -1; S-\u003etop[1] = M; } bool push(DqStack *S, int x, int i) { if (S-\u003etop[0] + 1 == S-\u003etop[1]) return false; switch (i) { case 0: S-\u003etop[0]++; S-\u003eStack[S-\u003etop[0]] = x; break; case 1: S-\u003etop[1]--; S-\u003eStack[S-\u003etop[1]] = x; break; default: return false; } return true; } bool pop(DqStack *S, int *x, int i) { switch (i) { case 0: if (S-\u003etop[0] == -1) return false; *x = S-\u003eStack[S-\u003etop[0]]; S-\u003etop[0]--; break; case 1: if (S-\u003etop[1] == M) return false; *x = S-\u003eStack[S-\u003etop[1]]; S-\u003etop[1]++; break; default: return false; } return true; } 栈的链式实现 采用带头结点的单链表实现链栈 头指针就作为栈顶指针 使用完毕时应释放其空间 typedef struct node { int data; struct node *next; } LinkStackNode; typedef LinkStackNode *LinkStack; bool push(LinkStack top, int x) { LinkStackNode *tmp; tmp = (LinkStackNode *)malloc(sizeof(LinkStackNode)); if (tmp == NULL) return false; tmp-\u003edata = x; tmp-\u003enext = top-\u003enext; //头插 top-\u003enext = tmp; return true; } bool pop(LinkStack top, int *x) { LinkStackNode *tmp; tmp = top-\u003enext; if (tmp == NULL) //栈空 return false; top-\u003enext = tmp-\u003enext; *x = tmp-\u003edata; free(tmp); return true; } 链式实现的多栈 top[0]、top[1]、……、top[M-1]分别为 M 个栈的栈顶指针。 #include \u003cstdio.h\u003e#include \u003cstdlib.h\u003e#include \u003cstdbool.h\u003e#define M 5 typedef struct node { int data; struct node *next; } LinkStackNode; typedef LinkStackNode *LinkStack; void InitStack(LinkStack *top) { *top = (LinkStack *)malloc(sizeof(LinkStackNode)); (*top)-\u003enext = NULL; } bool push(LinkStack top, int x) { LinkStackNode *tmp; tmp = (LinkStackNode *)malloc(sizeof(LinkStackNode)); if (tmp == NULL) return false; tmp-\u003edata = x; tmp-\u003enext = top-\u003enext; //头插 top-\u003enext = tmp; return true; } bool pop(LinkStack top, int *x) { LinkStackNode *tmp; tmp = top-\u003enext; if (tmp == NULL) //栈空 return false; top-\u003enext = tmp-\u003enext; *x = tmp-\u003edata; free(tmp); return true; } int main() { LinkStack top[M]; int tmp; for (int i = 0; i \u003c 5; i++) { InitStack(\u0026top[i]); push(top[i], i + 1); pop(top[i], \u0026tmp); printf(\"栈%d顶元素值%d\\n\", i + 1, tmp); } return 0; } /* 输出： 栈1顶元素值1 栈2顶元素值2 栈3顶元素值3 栈4顶元素值4 栈5顶元素值5 */ 两种存储结构的栈满 顺序栈判满与数组定义长度有关 链栈判满与可否申请系统空间有关 栈的应用与递归 括号匹配 #include \u003cstdio.h\u003e#include \u003cstdbool.h\u003e#include \u003cctype.h\u003e#define Stack_Size 50 typedef struct { char elem[Stack_Size]; int top; } Stack; void InitStack(Stack *S) { S-\u003etop = -1; } bool IsEmpty(Stack S) { return S.top == -1; } bool IsFull(Stack S) { return S.top == Stack_Size - 1; } bool push(Stack *S, char x) { if (IsFull(*S)) return false; S-\u003etop++; S-\u003eelem[S-\u003etop] = x; return true; } bool pop(Stack *S, char *x) { if (IsEmpty(*S)) return false; *x = S-\u003eelem[S-\u003etop]; S-\u003etop--; return true; } bool GetTop(Stack S, char *x) { if (IsEmpty(S)) return false; *x = S.elem[S.top]; ","date":"2022-01-24","objectID":"/data_structure-3/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(三)","uri":"/data_structure-3/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述线性结构中的线性表。","date":"2022-01-20","objectID":"/data_structure-2/","tags":["数据结构","学习"],"title":"数据结构学习(二)","uri":"/data_structure-2/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(二) ","date":"2022-01-20","objectID":"/data_structure-2/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(二)","uri":"/data_structure-2/"},{"categories":["算法与数据结构"],"content":"线性结构 ","date":"2022-01-20","objectID":"/data_structure-2/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(二)","uri":"/data_structure-2/"},{"categories":["算法与数据结构"],"content":"线性表 线性表定义 线性表（LinearList）：由 n 个类型相同数据元素的有限序列，记作 $$ (a_1,a_2,···,a_i,a_{i+1},···,a_n) $$ 称 n 为线性表长度，特别的，当 n = 0 时，称为空表。 每个数据元素只有一个直接前驱和一个直接后继（首尾元素除外），即为一对一的线性关系。 线性表特点： 同一性 有穷性 有序性 对于线性表 ADT： 数据元素：同类型数据元素的集合 $$ D={ a_i|\\ a_i\\in D0,\\ i=1,2,…,n\\ n≥0 ，D0为某一数据对象} $$ 关系：有序对偶 $$ s={\u003ca_i, a_{i+1}\u003e|\\ a_i, a_{i+1}\\in D0,\\ i=1,2,…, n-1} $$ 有 9 种基本操作运算： 初始化InitList(L) 销毁DestroyList(L) 置空ClearList(L) 判空EmptyList(L) 求长度ListLength(L) 查找Locate(L, e) 存取GetData(L, i) 插入InsList(L, i, e) 删除DelList(L, i, \u0026e) 线性表的顺序存储 #define MAXSIZE 100 //线性表数据类型定义 typedef struct { int elem[MAXSIZE]; //线性表占用的数组空间 int last; //线性表中最后一个元素在数组中的位置下标 } SeqList; /* 两种变量定义方式 SeqList L1 使用L1.elem[i-1]访问 SeqList *L2 使用L2-\u003eelem[i-1]访问 */ 查找操作 //按内容查找 int Locate(SeqList L, int e) { int i = 0; while ((i \u003c= L.last) \u0026\u0026 (L.elem[i] != 0)) i++; if (i \u003c= L.last) retrun i + 1; //若找到值为e的元素，则返回其序号 else return -1; //若没找到，返回空序号 } //按序号查找 int GetData(SeqList L, int i) { if (i \u003c= L.last) return L.elem[i - 1]; else { printf(\"序号超过上限\"); return 0; } } 插入操作 //在表的第i个位置之前插入一个新元素e int InsList(SeqList *L, int i, int e) { int k; if ((i \u003c 1) || (i \u003e L-\u003elast + 2)) { printf(\"插入位置i值不合法\"); return 0; } if (L-\u003elast \u003e= MAXSIZE - 1) { printf(\"表已满无法插入\"); return 0; } for (k = L-\u003elast; k \u003e= i - 1; k--) L-\u003eelem[k + 1] = L-\u003eelem[k]; L-\u003eelem[i - 1] = e; L-\u003elast++; return 1; } 删除操作 //将表的第i个元素删去 int DelList(SeqList *L, int i, int *e) { int k; if ((i \u003c 1) || (i \u003e L-\u003elast + 1)) { printf(\"删除位置不合法！\"); return 0; } *e = L-\u003eelem[i - 1]; for (k = i; k \u003c= L-\u003elast; k++) L-\u003eelem[k - 1] = L-\u003eelem[k]; L-\u003elast--; return 1; } 顺序表合并算法 有两个顺序表 LA 和 LB，其元素均为递增有序排列，编写算法，将两个有序表合并成一个递增有序的顺序表 LC。 void merg(SeqList *LA, SeqList *LB, SeqList *LC) { int i, j, k; i = 0; j = 0; k = 0; while (i \u003c= LA-\u003elast \u0026\u0026 j \u003c= LB-\u003elast) if (LA-\u003eelem[i] \u003c= LB-\u003eelem[j]) { LC-\u003eelem[k] = LA-\u003eelem[i]; i++; k++; } else { LC-\u003eelem[k] = LB-\u003eelem[j]; j++; k++; } while (i \u003c= LA-\u003elast) //表A长于表B { LC-\u003eelem[k] = LA-\u003eelem[i]; i++; k++; } while (j \u003c= LB-\u003elast) //表B长于表A { LC-\u003eelem[k] = LB-\u003eelem[j]; j++; k++; } LC-\u003elast = LA-\u003elast + LB-\u003elast + 1; } 比较循环的时间复杂度为 $$ O(LA-\u003elast+LB-\u003elast) $$ 复制循环时间复杂度为 $$ O(max(LA-\u003elast,LB-\u003elast)) $$ 顺序表优缺点总结 优点 无需为表示结点间的逻辑关系而增加额外的存储空间 可方便地随机存取查找表中的任一元素 缺点 大量插入删除时效率低，除表尾位置外，在其它位置插入删除都必须移动大量元素（平均移动次数为表长度一半） 由于顺序表要求占用连续的存储空间,存储分配只能预先进行静态分配。因此当表长变化较大时，难以确定合适的存储规模。 总结：便于随机存取，不适合动态变化 线性表的链式存储 单链表 typedef struct { int data; struct Node *next; } Node, *LinkList; LinkList L; 求长度 int ListLength(LinkList L) { Node *p; int j; p = L-\u003enext; j = 0; while (p != NULL) { p = p-\u003enext; j++; } return j; } 建立空表 void InitList(LinkList *L) { *L = (LinkList)malloc(sizeof(Node)); (*L)-\u003enext = NULL; } 建表 /* 头插法建表eg: 输入：123$ 链表：321 */ LinkList CreateFromHead(LinkList L) { Node *s; char c; int flag = 1; while (flag) { c = getchar(); if (c != '$') { s = (Node *)malloc(sizeof(Node)); s-\u003edata = c; s-\u003enext = L-\u003enext; L-\u003enext = s; } else flag = 0; } } /* 尾插法建表eg: 输入：123$ 链表：123 */ LinkList CreateFromTail(LinkList L) { Node *r, *s; char c; int flag = 1; r = L; while (flag) { c = getchar(); if (c != '$') { s = (Node *)malloc(sizeof(Node)); s-\u003edata = c; r-\u003enext = s; r = s; } else { flag = 0; r-\u003enext = NULL; } } } 查找 //按序号查找（第i个） Node *Get(LinkList L, int i) { int j; Node *p; p = L; j = 0; while ((p-\u003enext != NULL) \u0026\u0026 (j \u003c i)) { p = p-\u003enext; j++; } if (i == j) return p; else return NULL; } //按值查找 Node *Locate(LinkList L, int key) { Node *p; p = L-\u003enext; while (p != NULL) if (p-\u003edata != key) p = p-\u003enext; else break; return p; } 前插 int InsList(LinkList L, int i, int e) { Node *pre, *s; int k; pre = L; k = 0; while (pre != NULL \u0026\u0026 k \u003c i - 1) { pre = pre-\u003enext; k++; } if (!pre) { printf(\"插入位置不合理！\"); return 0; } s = (Node *)malloc(sizeof(Node)); s-\u003edata = e; s-\u003enext = pre-\u003enext; pre-\u003enext = s; return 1; } 删除 void DelList(LinkList L, int i, int *e) { Node *p, *r; int k; p = L; k = 0; while (p-\u003enext != NULL \u0026\u0026 k \u003c i - 1) { p = p-\u003enext; k++; } if (k != i - 1) { printf(\"删除结点的位置i不合理！\"); return; } r = p-\u003enext; p-\u003enext = r-\u003enext; *e = r-\u003edata; free(r); } 示例 #include \u003cstdio.h\u003e#include \u003cstdlib.h\u003e","date":"2022-01-20","objectID":"/data_structure-2/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(二)","uri":"/data_structure-2/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述。本节讲述数据结构绪论——一些重要术语含义。","date":"2022-01-20","objectID":"/data_structure-1/","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["算法与数据结构"],"content":"数据结构——用C语言描述(一) ","date":"2022-01-20","objectID":"/data_structure-1/:0:0","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["算法与数据结构"],"content":"数据结构绪论 ","date":"2022-01-20","objectID":"/data_structure-1/:1:0","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["算法与数据结构"],"content":"数据结构基础概念 数据（Data）：描述客观事物的数值、字符，能被机器输入且处理的的各种符号的集合。 数据元素（Data Element）：组成数据的基本单位，是数据集合的个体。一条记录就是一个数据元素。 数据对象（Data Object）：性质相同的数据元素的集合，是数据的一个子集。 数据结构（Data Structure）：指相互之间存在一种或多种特定关系的数据元素集合。即数据元素之间的相互关系，即数据的组织形式。一句话总结：带有结构的数据元素的集合。 数据类型（Data Type）：一组性质相同的值集合以及定义在这个值集合上的一组操作的总称。即值域、定义域及运算集合。 抽象数据类型（Abstract Data Type）：定义了一个数据对象，数据对象中各元素之间的结构关系，以及一组处理数据的操作。包括定义和实现两方面，其中定义是独立于实现的。 ADT 三要素： 数据元素 数据关系 数据操作 ","date":"2022-01-20","objectID":"/data_structure-1/:1:1","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["算法与数据结构"],"content":"数据结构内容 逻辑结构：数据元素之间逻辑关系描述。 四种基本数据逻辑结构表现为四种数据元素关系： 集合结构：属于关系 线性结构：一对一的线性关系 树形结构：一对多的层次关系 图形结构：多对多的任意关系 存储结构（物理结构）：逻辑结构在计算机中存储映像，是逻辑结构在计算机中的实现。包括数据元素的表示和关系的表示。 数据元素之间关系在计算机中表示方法： 顺序映像，一组连续单元，如数组。 非顺序映像，一组任意存储单元，如链表。 运算集合 ","date":"2022-01-20","objectID":"/data_structure-1/:1:2","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["算法与数据结构"],"content":"算法与算法描述 算法（algorithm）定义：规则的有限集合，是为解决特定问题而规定一系列操作。 算法特性： 有限性：有限步骤 确定性：无二义性 输入：有多个或0个输入 输出：至少有一个输出 可行性：原则上能精确进行，操作可通过已实现的基本运算执行有限次而完成 算法设计要求： 正确性 可读性 健壮性（鲁棒性）：对非法输入的抵抗能力 高效率与低存储量 算法描述：自然语言、框图、高级语言 ","date":"2022-01-20","objectID":"/data_structure-1/:1:3","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["算法与数据结构"],"content":"算法性能评价 性能评价：问题规模 N 的函数 数量关系评价：时间和空间 算法执行时间：本质是语句执行次数的比较 语句频度：该语句在一个算法中的重复执行的次数 算法的时间复杂度: $$ T(n)=O(f(n)) $$ 例如： for (int i = 0; i \u003c n; i++) for (int j = 0; j \u003c n; j++) x++; 这样的一段代码其时间复杂度为 $$ o(n^2) $$ 再例如，下方有一个算法的执行时间 $$ f(n)=2n^3+2n^2+n $$ 其时间复杂度为 $$ o(n^3) $$ 但这样一个算法只是理论上可行，但实际上不可行，因为其执行次数上升太快，程序无法实现。 最坏时间复杂度：算法在最坏情况下基本操作执行时间的上界。 例如，冒泡排序算法最坏时间复杂度为 $$ o(n^2) $$ 而其最好时间复杂度为 $$ o(n) $$ 算法空间复杂度：以存储单元个数刻画随问题规模增加的函数 f(n)，是考虑程序运行时占用内存的大小，记作 $$ S(n)=O(f(n)) $$ ","date":"2022-01-20","objectID":"/data_structure-1/:1:4","tags":["数据结构","学习"],"title":"数据结构学习(一)","uri":"/data_structure-1/"},{"categories":["计算机网络"],"content":"本文讲述了什么是全双工，介绍了全双工、半双工、单工的区别。","date":"2022-01-12","objectID":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/","tags":["计算机网络"],"title":"全双工，半双工与单工","uri":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/"},{"categories":["计算机网络"],"content":"全双工、半双工、单工 ","date":"2022-01-12","objectID":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/:0:0","tags":["计算机网络"],"title":"全双工，半双工与单工","uri":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/"},{"categories":["计算机网络"],"content":"定义 为了便于理解，这里打个比方，全双工就是双向两车道，半双工就是双向单车道，而单工则是单行路。 ","date":"2022-01-12","objectID":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/:1:0","tags":["计算机网络"],"title":"全双工，半双工与单工","uri":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/"},{"categories":["计算机网络"],"content":"全双工 全双工（Full Duplex）是通讯传输的一个术语。通信允许数据在两个方向上同时传输，它在能力上相当于两个单工通信方式的结合。全双工指可以同时（瞬时）进行信号的双向传输（A→B且B→A）。指A→B的同时B→A，是瞬时同步的。 ","date":"2022-01-12","objectID":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/:1:1","tags":["计算机网络"],"title":"全双工，半双工与单工","uri":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/"},{"categories":["计算机网络"],"content":"半双工 半双工(Half Duplex)数据传输指数据可以在一个信号载体的两个方向上传输，但是不能同时传输。例如，在一个局域网上使用具有半双工传输的技术，一个工作站可以在线上发送数据，然后立即在线上接收数据，这些数据来自数据刚刚传输的方向。像全双工传输一样，半双工包含一个双向线路（线路可以在两个方向上传递数据）。 ","date":"2022-01-12","objectID":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/:1:2","tags":["计算机网络"],"title":"全双工，半双工与单工","uri":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/"},{"categories":["计算机网络"],"content":"单工 单工（Simplex Communication）模式的数据传输是单向的。通信双方中，一方固定为发送端，一方则固定为接收端。信息只能沿一个方向传输，使用一根传输线。移动通信按照用户的通话状态和频率使用的方法，可分为三种工作方式：单工制、半双工制和双工制。 ","date":"2022-01-12","objectID":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/:1:3","tags":["计算机网络"],"title":"全双工，半双工与单工","uri":"/%E5%85%A8%E5%8F%8C%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E4%B8%8E%E5%8D%95%E5%B7%A5/"},{"categories":["计算机网络"],"content":"本文介绍了socket网络编程，讲解了TCP通信、I/O复用以及非阻塞I/O。","date":"2022-01-12","objectID":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/","tags":["socket"],"title":"Socket网络编程详解","uri":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/"},{"categories":["计算机网络"],"content":"Socket网络编程详解 ","date":"2022-01-12","objectID":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/:0:0","tags":["socket"],"title":"Socket网络编程详解","uri":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/"},{"categories":["计算机网络"],"content":"Socket简介 上图表示的是国际标准化组织(ISO)的计算机通信开放系统互连(OSI)模型； 1、2层随系统提供的设备驱动和网络硬件实现，一般不必关心，网络层 IPv4 或者 IPv6，传输层可以选择 TCP 或者 UDP，OSI 上面的 3 层合并为一层应用层，我们使用的套接口就是应用层到传输层的接口，主要介绍如何使用套接口编写使用 TCP 或者 UDP 的网络应用程序，其实可以绕过传输层，应用直接使用 IPv4 或者 IPv6，称为原始套接口(raw socket); 上三层（应用层）处理应用程序（如FTP、telnet、HTTP）的细节，不知道通信细节；下四层则不知道应用程序，但能处理所有的通信细节，发送数据、等待确认、给无序到达的数据排序、计算与验证校验和等等； 上三层通常形成用户进程，而下四层通常作为操作系统内核的一部分。 UDP 是英文 UserDatagramProtocol 的缩写，即用户数据报协议，主要用来支持那些需要在计算机之间传输数据的网络应用。包括网络视频会议系统在内的众多的客户/服务器模式的网络应用都需要使用 UDP 协议。UDP 协议从问世至今已经被使用了很多年，虽然其最初的光彩已经被一些类似协议所掩盖，但是即使是在今天，UDP 仍然不失为一项非常实用和可行的网络传输层协议。 UDP 和 TCP 的主要区别是两者在如何实现信息的可靠传递方面不同。TCP 中包含了专门的传递保证机制，当数据接收方收到发送方传来的信息时，会自动向发送方发出确认消息；发送方只有在接收到该确认消息之后才继续传送其它信息，否则将一直等待直到收到确认信息为止。 UDP 并不提供数据传送的保证机制。如果在从发送方到接收方的传递过程中出现数据报的丢失，协议本身并不能做出任何检测或提示。因此，通常人们把 UDP 协议称为不可靠的传输协议。 相对于 TCP，UDP 的另外一个不同之处在于如何接收突法性的多个数据报。不同于 TCP，UDP 并不能确保数据的发送和接收顺序，事实上，UDP 协议的这种乱序性基本上很少出现，通常只会在网络非常拥挤的情况下才有可能发生 。 UDP 具有 TCP 所望尘莫及的速度优势 ，TCP 中植入了各种安全保障功能，在实际执行的过程中会占用大量的系统开销，无疑使速度受到严重的影响。UDP 由于排除了信息可靠传递机制，将安全和排序等功能移交给上层应用来完成，极大降低了执行时间，使速度得到了保证。 只有理解了某些特性，才能更容易的编写更健壮的客户、服务器程序，netstat 工具是调试客户、服务程序最好的工具，tcp 的三路握手、tcp 的连接终止序列、tcp 的 time_wait 状态、套接口的缓冲机制等。 总结：UDP是一种简单的、不可靠的数据报协议；TCP是一种精致的、可靠的字节流协议 ","date":"2022-01-12","objectID":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/:1:0","tags":["socket"],"title":"Socket网络编程详解","uri":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/"},{"categories":["计算机网络"],"content":"TCP通信 ","date":"2022-01-12","objectID":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/:2:0","tags":["socket"],"title":"Socket网络编程详解","uri":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/"},{"categories":["计算机网络"],"content":"TCP简介 TCP 提供客户与服务器的连接； TCP 提供可靠性； TCP 通过给所发送数据的字节关联一个序号进行排序； TCP 提供流量控制； TCP 的连接是全双工的。（全双工？半双工？单工？） 一个TCP客户建立与一个给定的服务器的连接，跨越连接与那个服务器交换数据，然后终止连接； 当TCP向另一端发送数据时，它要求对方返回一个确认。如果没有收到确认，自动重传数据并等待更长时间，在数次重传失败后才放弃； TCP总是告诉对方它能够接收多少字节的数据，叫通告窗口； 在给定的连接上应用进程在任何时刻既可以发送也可以接收数据。 ","date":"2022-01-12","objectID":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/:2:1","tags":["socket"],"title":"Socket网络编程详解","uri":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/"},{"categories":["计算机网络"],"content":"TCP三次握手","date":"2022-01-12","objectID":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/:2:2","tags":["socket"],"title":"Socket网络编程详解","uri":"/socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3/"},{"categories":["常见问题"],"content":"本文讲述了环境变量字符数达到上限，无法继续添加的问题，提供了一种一劳永逸的解决方案。","date":"2022-01-09","objectID":"/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AD%97%E7%AC%A6%E6%95%B0%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","tags":["windows"],"title":"环境变量字符数解决方案","uri":"/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AD%97%E7%AC%A6%E6%95%B0%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["常见问题"],"content":"各位可能遇见过这样一个：Path 变量字符数超过1023个，无法再继续添加了。 其实你可以另外新建一个环境变量（比如我的是myEnvExtension），然后在这个变量下添加你要添加的 Path，然后再在 Path 中添加一个变量值为 %myEnvExtension% 即可。 ","date":"2022-01-09","objectID":"/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AD%97%E7%AC%A6%E6%95%B0%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/:0:0","tags":["windows"],"title":"环境变量字符数解决方案","uri":"/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AD%97%E7%AC%A6%E6%95%B0%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"categories":["web"],"content":"本系列教程第二章讲述了如何从GitHub pages迁移至Vercel，并提供了一些简单的博客美化教程。","date":"2022-01-08","objectID":"/hugo-2/","tags":["Hugo","blog"],"title":"Hugo博客系列(二)","uri":"/hugo-2/"},{"categories":["web"],"content":"Hugo博客系列（二） 本系列教程链接： 第一期 第二期 ","date":"2022-01-08","objectID":"/hugo-2/:0:0","tags":["Hugo","blog"],"title":"Hugo博客系列(二)","uri":"/hugo-2/"},{"categories":["web"],"content":"前言 上一期教程讲述了如何利用 GitHub pages 来部署，但我发现这并不是很好用。一是因为 GitHub pages 在国内访问速度较慢，二是百度不会收录 GitHub pages，这就导致了站点流量难以增长，但 Vercel 就不存在这些问题，因此我将本站迁移至了 Vercel。与此同时，还做了一些简单的美化操作。 ","date":"2022-01-08","objectID":"/hugo-2/:1:0","tags":["Hugo","blog"],"title":"Hugo博客系列(二)","uri":"/hugo-2/"},{"categories":["web"],"content":"从 GitHub pages 迁移至 Vercel 首先前往 Vercel 官网，使用 GitHub 登录。 未完待续 ","date":"2022-01-08","objectID":"/hugo-2/:2:0","tags":["Hugo","blog"],"title":"Hugo博客系列(二)","uri":"/hugo-2/"},{"categories":null,"content":"主题作者 本网站采用 Hugo-LoveIt 主题，下方是主题作者的 GitHub 链接。 \rDillon\r\"LoveIt主题作者\"\r\r\r\r","date":"2022-01-05","objectID":"/friends/:1:0","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"大佬们 ","date":"2022-01-05","objectID":"/friends/:2:0","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"JAVA \r雨临Lewis的博客\r\"不想当写手的码农不是好咸鱼_(xз」∠)_\"\r\r\r\r","date":"2022-01-05","objectID":"/friends/:3:0","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"本站友链信息 name=\"Sukun的博客\" url=\"https://www.sukun.xyz\" logo=\"https://www.sukun.xyz/images/avatar.png\" word=\"Sukun的博客，记录学习历程！\" ","date":"2022-01-05","objectID":"/friends/:4:0","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"交换友链 注意 各位大佬想交换友链的话可以在下方留言，我看到后将以回复+邮件的形式通知！ 你需要留下以下信息： //必填 name=\"站点名称\" //必填 url=\"站点地址\" //必填 logo=\"你的站点图标或个人头像\" //必填 word=\"站点描述\" //选填——默认分组是大佬们 group=\"分组\" 警告 如果贵站存在以下情况之一： 链接失效、无法访问、删除本站友链、友链入口不易找到。 我将删除贵站友链并邮件通知，直至贵站恢复正常为止！ ","date":"2022-01-05","objectID":"/friends/:5:0","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":" new Artitalk({ appId: 'LLhNra6D2fqcyOGJYWIrwoB8-MdYXbMMI', // Your LeanCloud appId appKey: '1m4bN4Gx2xYFmRwyrT1Y1qPa' // Your LeanCloud appKey }) ","date":"2022-01-05","objectID":"/bbs/%E5%85%AC%E5%91%8A%E7%95%99%E8%A8%80/:0:0","tags":null,"title":"公告留言","uri":"/bbs/%E5%85%AC%E5%91%8A%E7%95%99%E8%A8%80/"},{"categories":["生活"],"content":"站点日志 站点日志 不断更新中 ","date":"2022-01-05","objectID":"/logs/:0:0","tags":["站点日志","生活"],"title":"站点日志","uri":"/logs/"},{"categories":["生活"],"content":"2021年 ","date":"2022-01-05","objectID":"/logs/:1:0","tags":["站点日志","生活"],"title":"站点日志","uri":"/logs/"},{"categories":["生活"],"content":"2021年10月 大一参加学校工作室招新，购买了云服务器，顺便利用 WordPress 开通了我的第一个私人博客。（顺便提一嘴，服务器至今仍在跑青龙面板为我捞点豆子） ","date":"2022-01-05","objectID":"/logs/:1:1","tags":["站点日志","生活"],"title":"站点日志","uri":"/logs/"},{"categories":["生活"],"content":"2021年11月 嫌弃 WordPress 过于臃肿，且对技术锻炼程度不高，遂放弃 WordPress 转投 Hexo ","date":"2022-01-05","objectID":"/logs/:1:2","tags":["站点日志","生活"],"title":"站点日志","uri":"/logs/"},{"categories":["生活"],"content":"2022年 ","date":"2022-01-05","objectID":"/logs/:2:0","tags":["站点日志","生活"],"title":"站点日志","uri":"/logs/"},{"categories":["生活"],"content":"2022年1月 2022年1月1日 元旦第一天，突然想起那个开通了之后一直没写的博客，又发现 Hugo 在博客上是更好的选择，于是本网站就此诞生！ 2022年1月2日 开始写文章了！ 2022年1月3日 为网站添加了小游戏 mikutap。 2022年1月4日 加入了抓猫小游戏，一起来抓猫呀！ 2022年1月5日 添加了更丰富的评论功能，采用 Waline 实现。 添加了站点日志、友链墙。 添加了 artitalk 实现的 BBS 功能——公告板/留言板！ 2022年1月6日 添加了站点持续时间功能。 2022年1月7日 添加了搜索、GitHub conrner 、最近更新文章、上次更新时间功能 把源码和网页文件分开为了两个仓库。 2022年1月8日 将站点从 GitHub pages 迁移至了 Vercel。 2022年1月20日 期末考完差不多1周了，寒假开卷！数据结构！大雾！微积分！ 这里分享一下我的数据结构学习资料：（西北大学）数据结构网课，LeetCode 刷题 2022年1月27日 制作了两个小网页，有兴趣的可以看看第一个，第二个（都是拿大佬的作品改的，做着玩，代码里都有作者的链接） ","date":"2022-01-05","objectID":"/logs/:2:1","tags":["站点日志","生活"],"title":"站点日志","uri":"/logs/"},{"categories":null,"content":"一起来抓猫 点击圆点围住猫咪，别让它到达地图边缘！ window.game = new CatchTheCatGame({ w: 11, h: 11, r: 20, backgroundColor: 0xeeeeee, parent: 'catch-the-cat', statusBarAlign: 'center', credit: '一起来抓猫！' }); ","date":"2022-01-04","objectID":"/games/catch-the-cat/:1:0","tags":null,"title":"Catch the Cat","uri":"/games/catch-the-cat/"},{"categories":["web"],"content":"本系列教程第一章讲解了几种常见的博客框架选择，最终以 Hugo 框架为基础，教授了如何在 GitHub pages 上部署个人博客，还使用 GitHub actions 以及一个简单的 bat 脚本实现自动化发布。","date":"2022-01-04","objectID":"/hugo-1/","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"Hugo博客系列（一） 本系列教程链接： 第一期 第二期 ","date":"2022-01-04","objectID":"/hugo-1/:0:0","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"前言 ","date":"2022-01-04","objectID":"/hugo-1/:1:0","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"为什么要有自己的博客？ 写博文能很好地分享自己的想法，能记录生活，还能充当一个电子笔记的作用，有效防止今后某一天面对一个以前遇到过的问题但现在不会解决的情况出现。一篇好的博文能为你带来大量的流量，你可以在搜索引擎中搜索到自己，我相信这是一件足够令人雀跃的事情。并且你还能利用他做一篇网页简历，当你找工作时你可以有着更加花里胡哨的简历！除此以外，你还能通过交换友链建立一个优质的社交圈，因为大家都写了很多高质量的文章，你能与他们进行深入交流，这不像同学圈一样脆弱，它能稳定存在很久！ 在其他博客平台写作你讲或多或少地受到限制，想自己 DIY 页面还得向官方申请，甚至不会审批通过。而且你无法使用多种多样的第三方插件，还得面对审查，写的文章有可能被删除、撤回。有广告干扰，任谁也不喜欢看着一篇文章然后突然蹦出来一个广告吧？当然，你也可以自己接点广告在网站上。 ","date":"2022-01-04","objectID":"/hugo-1/:1:1","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"常见博客框架的选择 hexo hexo 以前影响力还不错，但这几年已经不如从前人们预判的那么发展的好了，GitHub 上 hexo 项目有着 34k 个 star 看出，其中最为出名的主题便是 Next，有着 15.7k 个 star，这也是因为 Next 目前是 hexo 主题中功能最齐全最好用的一个。而如此之多的人使用也就意味着 hexo 这个框架的作者用收到非常多的反馈，因此 hexo 更新优化做的很好，作者也很有动力继续做下去。 但是这样的一个框架缺点也是有的： 环境配置麻烦 因为要使用 hexo 你得在本地安装 Node.js、Git，会熟练使用 GitHub，而且由于 GitHub 的特殊性，你还得学会翻墙，不然还用不了，这就对一点基础都没有的小白不是很友好了。 无后端 这意味着你没有一个后台还方便地对网站进行操作，只能通过先写好 Markdown 文件然后 Git 推送到云端。并且原生的 hexo 是没有评论系统的，想加评论还得找第三方评论系统。除此以外，一旦本地文件被你不小心删除掉了，那当你下次 push 的时候你之前的博文也就跟着丢失了。 渲染时间久 200 篇左右的博文用 Hexo 需要 10 分钟去生成静态网页，当你写博客写的时间久了之后文章多了起来，相信我，你会无法忍受这种折磨。 总结：hexo 适合有一定基础的人，然后写博客时间不长或者只是随便写来玩的人。当然尤其其广泛的传播性，当你遇到问题的时候拿到网上去搜一般都是有解决方案的，这也可以为你省下一点力气。 最后，如果你想用 hexo，我建议主题用 Next。 Hugo Hugo 几年前的影响力是不如 hexo 的，但现在越来越多的人从 hexo 迁移到了 Hugo，Hugo使用人数也多了起来，GitHub 上 Hugo 项目有 56.2k 个 star，已远远超过了 hexo，因此你也不用太担心 Hugo 会不会太小众化的问题，但是 Hugo 上的主题选择会更少一些，其中最受欢迎的是 wowchemy，但也仅有 6.1k 个star，而本站采用的是 LoveIt 主题，它的 star 就更少了，才 1.6k 个。当然，如果你是搞前端开发的，或者乐意自己写主题，那这些就不重要了。 Hugo优点： 速度快 Hugo 采用 Go 语言编写，它的速度用作者的话来形容就是世界上最快的构建网站工具。并且 Hugo 是即时渲染的，这意味着你可以边写边改样式，直到你满意为止。即使是你写了几百篇文章，它也能在几秒之内全部渲染完成。 The world’s fastest framework for building websites 配置更为简单 你需要安装只是 Hugo，不像 hexo 还得安装 Node.js。并且Hugo 中是不区分站点和主题的配置文件的，Hugo 中只有一个位于站点根目录下的 config.toml 配置文件，你只用在这里面进行修改就可以了。 方便自定义 你可以在不修改主题文件的前提下方便地定制主题。在 Hugo 中，如果你想要定制主题，你只需在站点目录下新建相应的文件即可。这是非常利于主题的维护的，你只需使用 Git 的 submodule 的方式安装 Hugo 的主题，然后更新时只需直接在站点根目录下敲一条命令回车即可，非常方便！ 缺点： 主题比较少，很可能大家都是用的同一个主题，并且主题作者更新会更少一点。 总结：如果你喜欢 DIY，我建议使用 Hugo。如果你是个专业博主，写了很多文章需要渲染，我建议使用 Hugo！ Typecho 这是一个非常轻量级的博客框架，但是需要你拥有一个服务器。并且它对服务器要求极低，即使只有 512M 内存或是更低，它也能跑起来。它可以满足你对博客的基本需求，而且 Typecho 是带后端的，意味着只要你能上网，你就可以自由地写你的文章，不会被设备所拘束。当然，你将免除配置环境的苦恼。 缺点： 更新慢 奇慢无比，作者已经 9 年没有进行更新了，一些插件也已经不能用了。 自由度低 你不能随心所欲地进行 DIY，当然，如果你只是用来写博客的话问题不是很大。 WordPress 世界上最受欢迎的建站工具！具体有多受欢迎？每三个网站就有一个是 WordPress 搭建，并且美国白宫自2017年起，其官网 Whitehouse.gov 网站的內容管理系統（Content management system，CMS）从 Drupal 换成 WordPress！ WordPress 是一个以 PHP 和 MySQL 为平台的自由开源的博客软件和内容管理系统。WordPress 具有插件架构和模板系统。截至2018年4月，排名前1000万的网站中超过30.6%使用WordPress 。WordPress是最受欢迎的网站内容管理系统。全球有大约30%的网站(7亿5000个)都是使用WordPress架设网站的。WordPress 是目前因特网上最流行的博客系统。 并且 WordPress 并不只是可以用来写博客，它能用来打造一切你想要的网站，哪怕是用来建个电商网站也没有问题！ 优点： 超广泛传播性 你在使用 WordPress 遇到的任何问题，你都可以在网上找到对应的解决方案，它的使用人数之多以至于每一个坑都有人替你趟过了！ DIY 自由度高，难度低 你可以随心所欲地添加插件，WordPress 提供了大量的优质插件，甚至有大量的人就以制作 WordPress 上的插件谋生！ 安装简单 网上有非常多的 WordPress 一键安装脚本，你可以根据自己的需求进行选择，无需面对安装过程中的问题！并且其安装时间非常短，只需要5分钟就能搞定！ 缺点： 需要有一定性能的服务器 PHP，MySQL这些对服务器有一定的要求，会占用比较多的内存，它不像 Typecho 一样轻便。 太过臃肿，不简洁 太多的功能与选择造成了页面的繁琐，并且你会对着页面一直修改，这不利于你专心地撰写博文。 总结：适合有服务器，懒得折腾环境配置，喜欢开箱即用的人。 ","date":"2022-01-04","objectID":"/hugo-1/:1:2","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"Hugo快速上手教程 ","date":"2022-01-04","objectID":"/hugo-1/:2:0","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"Hugo安装 首先，请前往 GitHub 上下载最新版的 Hugo 压缩包，Releases · gohugoio/hugo (github.com)，建议选择 extended 版本，这将更有利于后续的 DIY 操作！ 下载完成后解压到一个你认为合适的位置，然后把 hugo.exe 所在的文件夹添加至环境变量中的 Path 中即可。 当然，你也可以采用源码编译的方式进行安装，这里就采用最简单的方法了。 注意 如果你的path变量下的字符数达到了上限，你可以查看这篇文章中的解决方案。 检查一下上一步操作是否正确 hugo version 然后找一个合适的文件夹，在该目录下输入以下指令新建一个 Hugo 项目 hugo new site my_website cd my_website ","date":"2022-01-04","objectID":"/hugo-1/:2:1","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"Hugo主题选择、安装与快速上手 我这里采用 LoveIt 主题进行演示，事实上还有很多主题也很棒，比如 even、meme、wowchemy。 LoveIt 主题的仓库是: https://github.com/dillonzq/LoveIt. 你可以下载主题的 最新版本 .zip 文件 并且解压放到 themes目录. 另外, 也可以直接把这个主题克隆到 themes 目录: git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 或者, 初始化你的项目目录为 git 仓库, 并且把主题仓库作为你的网站目录的子模块: git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt 那么如何更新主题呢？ git submodule update --rebase --remote 把 \\themes\\LoveIt\\exampleSite目录下的config.toml复制下来，替换掉站点根目录下的同名文件。 然后对这个文件进行一些自定义修改。 然后进入根目录下的archetypes文件夹中，修改default.md文件为下面的内容（这个文件是模板文件，通过指令创建的文章将以模板为基础内容） --- title: \"{{ replace .Name \"-\" \" \" | title }}\" date: {{ .Date }} tags: [\"\"] categories: [\"\"] toc: enable: true description: draft: true --- \u003c!--more--\u003e 现在开始撰写文章 hugo new posts/first_post.md 注意，后缀为md，建议使用 Typora 进行编辑。 首先修改 frontmatter，其中title表示文章标题，date为生成文章当时的时间，tags为标签，categories为目录，toc enable为启用文章目录（需要自己在文章中生成），description为文章摘要，draft表示是否为草稿（写完了文章把这里改为 false 即可），\u003c!--more--\u003e为 LoveIt 主题的摘要标识符，该标识符上方的内容为文章摘要，如果上方为空，则采用 frontmatter 中设置的descriptions为文章摘要。 例如本文的 frontmatter 为 title:\"Hugo博客系列(一)\"date:2022-01-04T18:40:38+08:00tags:[\"Hugo\"]categories:[\"web\"]toc:enable:truedescription:本系列教程第一章讲解了几种常见的博客框架选择，最终以 Hugo 框架为基础，教授了如何在 GitHub pages 上部署个人博客，还使用 GitHub actions 以及一个简单的 bat 脚本实现自动化发布。draft:true 写完了文章进行网页的构建 hugo serve -D -e production -D表示草稿也要渲染，-serve表示启动一个本地服务器，即时渲染，方便修改。 注意 hugo serve 的默认运行环境是 development, 而 hugo 的默认运行环境是 production。 由于本地 development 环境的限制, 评论系统**, **CDN 和 fingerprint 不会在 development 环境下启用。 你可以使用 hugo serve -e production 命令来开启这些特性。 值得一提的是不论输入的是server还是serve都是一样的。 在浏览器中前往它给出的 http://localhost:1313 就能看到你刚生成的博客了。 技巧 当你运行 hugo serve 时, 当文件内容更改时, 页面会随着更改自动刷新. 现在再输入指令 hugo -D 这会生成一个 public 目录, 其中包含你网站的所有静态内容和资源. 现在可以将其部署在任何 Web 服务器上。 确认无误后就要把它发到公网上了，这里采用 GitHub pages 进行部署（当然，也有很多种方法也能达成这一目的） ","date":"2022-01-04","objectID":"/hugo-1/:2:2","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"GitHub pages部署 如果你是第一次使用 GitHub，请自行搜索如何配置，这里不做讲解！ 首先确保你有一个 GitHub 账号，然后新建一个仓库，名为yourname.github.io，注意，你应该保证这里的 your name 为你的 GitHub 账号名称！然后再进行以下步骤： cd public git init git remote add origin https://github.com/yourname/yourname.github.io.git #此URL可在你的repo中找到 git add . git commit -m \"update %date%,%time%\" git push origin master 如果一切顺利的话打开你的 GitHub repo，你就能看到相应的文件了，接着在 settings 页面中下滑，找到 GitHub pages，选择分支master，root路径，然后保存即可。如果你有自己的域名，还可以在下方的custom domain中输入你的域名，等待一段时间就可以用这个域名访问了。 当然，在此之前你还需要再次修改config.toml文件中的baseURL为https://yourname.github.io，否则发布到网上也无法访问！ ","date":"2022-01-04","objectID":"/hugo-1/:2:3","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["web"],"content":"GitHub actions实现自动部署(CI/CD) 是否觉得这个发布太过于繁琐了？别担心，这里提供两种解决方案！分别是本地 bat 脚本和GitHub actions。 首先是本地 bat 脚本，这将免除每次发布都要敲至少 5 行指令的痛苦。只需要每次要发布的时候双击运行一下程序即可。 hugo -D cd public git add . git commit -m \"update %date%,%time%\" git push origin master pause 另一种方法是前往 GitHub，新建一个仓库。 点击Actions选择simple workflow，内容如下 name:CI#自动化的名称on:push:# push的时候触发branches:# 那些分支需要触发- masterjobs:build:runs-on:ubuntu-latest# 镜像市场steps:- name:checkout# 步骤的名称uses:actions/checkout@v2.3.4#软件市场的名称with:# 参数submodules:true- name:Setup Hugouses:peaceiris/actions-hugo@v2.4.13with:hugo-version:0.91.2extended:true- name:Buildrun:hugo -D- name:Deployuses:peaceiris/actions-gh-pages@v3with:deploy_key:${{ secrets.ACTIONS_DEPLOY_KEY }}EXTERNAL_REPOSITORY:14772/14772.github.io# 注意要修改本处地址PUBLISH_BRANCH:masterPUBLISH_DIR:./public 值得注意的是在最后一条Deploy中应使用with而非env，应使用deploy_key而非其他的名字。但目前网上大部分教程都没提及这一点，甚至有的还错误地使用！ 然后在本地输入以下命令在当前目录下生成密钥对 ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key) -t rsa表示 rsa 加密，-b 4096则表示长度为 4096bit，-C后面的是备注，-f后面的是文件名，-N是新密语 现在前往yourname.github.io仓库，选择Settings \u003e Deploy keys \u003e Add deploy key，勾选 Allow write access，内容为公钥(有pub字样的文件) 再前往之前存放了master.yml文件的仓库，选择Settings \u003e Secrets \u003e New secret，名称填ACTIONS_DEPLOY_KEY，内容为私钥 然后在站点根目录下执行以下命令 git remote add origin https://github.com/yourname/yourrepo. #此repo为你放了master.yml文件的仓库 现在再来写一个 bat 脚本 git add . git commit -m \"update %date%,%time%\" git push origin master 之后直接双击运行它就行了 注意 如果你自定义了域名，那么你需要在站点根目录static文件夹下新建一个CNAME文件，内容为你的自定义域名！否则每次 deploy 后域名都会变成 yourname.github.io，达不到自定义的目的！ 总结：第二种更复杂，但也更好，因为它将源文件也上传到了云端，便于多地更新博客，不至于丢失文章。并且，其在本地占用的内存更小（毕竟网页源代码全在云端），对于文章很多的朋友来说也更友好。 ","date":"2022-01-04","objectID":"/hugo-1/:2:4","tags":["Hugo","blog"],"title":"Hugo博客系列(一)","uri":"/hugo-1/"},{"categories":["计算机网络"],"content":"近些年来国民\"翻墙\"需求日益剧增，具备\"翻墙\"能力的人也越来越多，本文分析了\"翻墙\"的原因与违法性，并从技术层面分析了 GFW 的封锁措施与几种常见的\"翻墙\"方法。","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"浅析“翻墙” 警告 声明 撰写本文是出于学习计算机网络知识，解析技术以及简单普法的目的。不传播、售卖“翻墙”工具，不教授“翻墙”方法，本文也不出现“翻墙”教程。本人对网民浏览本文后做出的不理智行为概不负责！ ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:0:0","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"什么是“翻墙”？ 首先，我们要知道翻墙翻的是什么？答案是 GFW(Great Fire Wall)也就是长城防火墙。这里借用维基百科来解释：防火长城（英语：Great Firewall，常用简称：GFW），中文也称中国国家防火墙，俗称墙、网络长城、防火墙等等，中国国家互联网信息办公室称为数据跨境安全网关 ，是中华人民共和国政府监控和过滤互联网国际出口内容的软硬件系统集合。随着使用的拓广，“墙”有时也被用作动词，中国网友所说的“被墙”即指网站内容被防火长城所屏蔽或者指服务器的通讯被封阻，“翻墙”也被引申为突破网络审查浏览中国大陆境外被屏蔽的网站或使用服务的行为。 ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:1:0","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"为什么要“翻墙” 一方面，普通人翻墙原因如下： 使用国外的 app 和服务，例如看 YouTube，使用海外版腾讯视频（海外版往往比国内版体验感好，无广告简洁）。 好奇，想见识一下墙外的世界。（这点原因是主要因素，大多数人都是出于这一点） 满足在国内无法实现的欲望，比如逛 P 站（懂的都懂） 与外国人聊天，增长外语水平 做外贸，面外海外经商却不想支付昂贵的官方信道费用 …… 另一方面，作为一名程序员，其翻墙原因如下： 使用 GitHub，对于一名程序员来说，GitHub 算得上是必需品，根本离不开 逛 StackOverflow 社区，寻找 bug 解决方案 下载、使用专业工具，因为有些工具是海外的，国内没有替代品 查阅文档、学习技术 阅读科研论文、查询数据、与海外团队交流 …… ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:2:0","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"”翻墙“犯法吗？ 需要明确的是，在这一问题上，国内暂无一个统一见解。但我个人观点是只要不传播、不扩散、不进行违法违规活动，不发表、不转发、不支持反动言论，只是简单地浏览，同时也没有人举报你翻墙了，那么警察也不会闲得来抓你。 引用 《计算机信息网络国际互联网安全保护管理办法》（以下简称其为“办法”）第5条规定，任何单位和个人不得利用国际互联网制作、复制、查阅和传播下列信息： （一）煽动抗拒、破坏宪法和法律、行政法规实施的； （二）煽动颠覆国家政权，推翻社会主义制度的； （三）煽动分裂国家、破坏国家统一的； （四）煽动民族仇恨、民族歧视，破坏民族团结的； （五）捏造或者歪曲事实，散布谣言，扰乱社会秩序的； （六）宣扬封建迷信、淫秽、色情、赌博、暴力、凶杀、恐怖、教唆犯罪的； （七）公然侮辱他人或者捏造事实诽谤他人的； （八）损害国家机关信誉的； （九）其他违反宪法和法律、行政法规的。 如果按照上述规定，那么在翻墙过程中将难免会遇到不良内容，容易触犯该办法。而这也警示我们：不传播、不扩散、不进行有违法律法规的网络活动！ 另一方面，国内翻墙用户众多，所谓法不责众，如果按照翻墙即违法来处办的话，这对于警力要求过高。按照下图显示的份额来看，谷歌 2020 年在中国就有着 3.49% 的市场份额，而 2020 年中国网民共计 9.40亿，不难得出中国有3200万谷歌用户的数据，如果我们保守估计，以其中有一半的人都有着正规渠道访问谷歌（比如各高校、科研实验室、跨国公司、银行等有资质购买专线的），那么具有翻墙能力的人也有 1600 万之巨，这已经是一个庞大的数字，这也是国内对翻墙不再如从前那么敏感的原因之一。 同时，近些年来国民的民族自豪感、国家认同感大幅提升，这一现象在年轻人身上表现尤为明显，恰如年轻一辈的口号“请党放心，强国有我”。这使得 GFW 封锁国民访问外网的一大原因——防止国外媒体恶意抹黑中国的言论对国民的思想造成影响——不怎么适用，因为国民不再容易被误导了，”国外的空气也不怎么香甜“。并且有能力进行翻墙的人大多数都是接受了高等教育的人，思想较为深刻，有稳固而正确的三观，放他们出去逛一逛问题也不是很大。 当然了，如果你不是一个普通的翻墙用户，而是以此牟利，那你肯定触犯了法律，必将接受法律的制裁。一方面，你使得国家将面对更多的不可确定因素，因为受传播者不一定遵纪守法，你需要为此负责！ 引用 除了办法中的条例以外，对提供“翻墙”服务的卖家而言，《互联网信息服务管理办法》 规定的惩罚措施更重。 第 4 条规定：“国家对经营性互联网信息服务实行许可制度；对非经营性互联网信息服务实行备案制度。未取得许可或者未履行备案手续的，不得从事互联网信息服务。” 第 19 条规定：“违反本办法的规定，未取得经营许可证，擅自从事经营性互联网信息服务，或者超出许可的项目提供服务的，由省、自治区、直辖市电信管理机构责令限期改正，有违法所得的，没收违法所得，处违法所得 3 倍以上 5 倍以下的罚款；没有违法所得或者违法所得不足 5 万元的，处 10 万元以上 100 万元以下的罚款；情节严重的，责令关闭网站。” 总结：作为一名普通翻墙用户，只要老老实实地，不犯法。而如果你进行了违法乱纪的活动，或者是翻墙服务提供商或者教授、传播翻墙方法，那就犯法了！ ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:3:0","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"“翻墙”原理解析 要知道翻墙的原理，我们就得先知道GFW是如何把这堵墙树立起来，如何阻断不正常通信的。 ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:4:0","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"GFW的封锁 关键字过滤 由于 Http 协议数据包头部是明文的，所以 GFW 一旦发现连接有敏感词，马上就会伪装成连接两方，向真正的对方发送 RST 数据包（重置连接、复位连接），真正的双方一看，出现异常了，TCP连接就会中断掉。表现为有的页面正在打开，然后过了一会又没了，显示无法连接。 IP封锁 GFW 可以在出境的网关上加一条伪造的路由规则，这样对于一些被过滤了的 IP 的数据包就无法正确地被送达，所以也就无法访问了。GFW 封路由是直接封独立 IP ，这样可能因为某个敏感站点，导致跟他同一台主机的其他站点也无法访问，理解起来就像旁注（从旁注入）。而且 GFW 封 IP 有的时候是直接封 IP 段的，国外几大 VPS 服务商（比如 Bandwagon 搬瓦工）更是重点监测，有时就因为其中一个 IP 不对，GFW 能给你把这整个机房里的服务器的 IP 全封了，当然这样一来难免会有无辜之人中枪。 DNS污染、劫持 ​ DNS 也就是域名解析服务，GFW 会对所有经过骨干出口路由的在 UDP 的 53 端口上的域名查询进行检测，一旦发现有黑名单里的域名，它就会伪装成目标域名的解析服务器给查询者返回虚假结果。由于 UDP 是一种无连接不可靠的协议，查询者只能接受最先返回的结果，故而你将看到明明地址栏中的 URL 是对的，但是浏览器渲染的却是不是目标网页或者干脆访问不了。 特定端口封锁 对于一些特点的 IP ，GFW 会丢弃特定端口上的数据包，使得某些功能无法使用，比如 443 端口 SSL，22 端口的 SSH。 GWF 曾经干过一件事，针对 Google 的一些 IP 上的 443 端口，实施间歇性封锁，不明所以的用户就会觉得这是 Google 抽风了，久而久之自然不能忍受 “老是出问题” 的产品。同样的还有 GitHub 的 443 端口、前段时间的 steam 的 443 端口也都被间歇性封锁了。 值得一提的是这个一般是人为干预的，理由就是常发生在白天。加密连接干扰 加密连接不总是加密的，公钥还是明文的，所以 GFW 就能识别出特定服务的证书。然后在遇到 “黑名单” 加密连接时，它会发送RST数据包，干扰双方正常的 TCP 连接，进而切断加密连接的握手。 主动嗅探 现在我们假设你能伪装你的流量，当它和其他流量混杂在一起时从外观上看没有什么区别，你以为这就可以高枕无忧了？错！事实上，GFW 是被动监测+主动嗅探来实现封锁的，即使一个流量没有任何翻墙特征，但是这股流量太大了，或者时间太长了，GFW 也将主动地发一个连接请求过去，由于这根本就是个假流量，连接返回的内容也不正常，GFW 一看就知道不对劲了，然后再来个人工检测，你不就暴露了么。另一方面，每逢政治敏感时期（比如每年两会、国庆、建党节）或者每年 6 月的大扫除时期，这个时期人工检测大大增多， GFW 敏感系数提升，更容易发现不正常流量，并且从前稳妥起见，只是怀疑还怕误杀的流量，放在这个时期就大概率给你封了。 ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:4:1","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"对抗GFW的技术 直接访问IP GFW 不是对域名进行各种干扰吗，现在我直接绕过域名解析，对那些还进入监控名单的 IP 直接访问就能躲开 GFW 的干扰。但是很可惜 GFW 对付这种方法的策略也很简单粗暴但有效，那就是见一个封一个。比如早些年谷歌在国内还能正常访问靠的就是大量的镜像 IP，但随着这些年来 GFW 的不懈努力，谷歌服务的 IP 已经被杀绝了。这种办法的失效也就是个时间问题，因为人家封锁只需要找到 IP 然后加入黑名单就行，而被封锁的一方的要付出的努力就大得多了。 VPN隧道 首先我们明确，虚拟专用网络（VPN）是一门网络技术，而非一个软件，它为我们提供了一种通过公用网络(如最大的公用因特网)安全地对企业内部专用网络进行远程访问的连接方式。在 VPN 隧道中通信能确保通信通道的专用性，并且传输的数据是经过压缩、加密的，所以VPN通信同样具有专用网络的通信安全性。VPN 原本用意是为了让人不在公司也能访问公司内网，但其优越的安全性也让他也有了对抗 GFW 的功能，这里不展开讲解。但是值得注意的是，那些名叫某某加速器、某某 VPN 的翻墙工具往往都不咋地，而且还有跑路的风险，甚至有的还是“家庭小作坊”，而那些大的服务商提供的虽然稳定速度快，但是又是重点监测，譬如某海外服务商的 VPN 长期坚挺，一直加 IP 来对抗 GFW ，但代价就是价格高昂。就像这张图讲的道理： 代理服务器 这里故意把 VPN 和代理分开，事实上 VPN 也是代理的一种，但其在网络七层协议中跑在数据链路层/第二层，而socks5、Trojan、v2ray之类的则是在OSI七层模型中的第五层/会话层的，（ HTTP 在第七层/应用层， Ping 指令使用 ICMP 协议，工作于第三层/网络层）。而更低层可以代理更高层，更高层代理不了更底层。表现出来的则是你挂了梯子（非 VPN 类）发现依然没法加速 LOL 等游戏（游戏跑网络层），这也是你再挂了梯子之后依然可以用 Ping 来看主机与服务器直接的延迟的原因。但如果开了 VPN ，那他可以加速游戏，可以代理 ICMP 指令。 说完了 VPN 与这里说的代理的区别，现在再来说常见的几种“翻墙”代理协议。 注意 世界上没有永远安全的协议，所谓道高一尺，魔高一丈，这是一场长期的军备竞赛，双方都在不断推陈出新！ Socks5 协议与 HTTP 协议 Socks5 把你的网络数据由代理服务器转发到目的地，这个过程中你是没有一条专用通道的，只是数据包的发出，然后被代理服务器收到，然后代理服务器再进行转发，整个过程并没有额外的处理。 但是在连接建立时、传输流量过程中有着极为明显的流量特征。因此网上也不乏唱衰 Socks5 协议的声音，甚至有流言称 Socks5 协议已被 GFW 攻破，能被其拿捏，但目前暂无明确证据，同时 Socks5协议依然是用的最多的代理协议，因此我对这种观点持保留观点。 对抗措施：流量加密、反检测、免杀 Socks5 + HTTP 代理并不会让本来明文传输的浏览加密，但是可以改变请求的 IP，服务器看到访问者的 IP 就是你的代理代理服务器的IP。 如果流量本身没有加密，实战中流控设备很容易识别到客户端连接成功的流量规则。 如果想要加密 Socks5 的流量，则需要安装魔改版 Socks 服务端和客户端，比如著名的 SS/SSR 就是用 Socks5 来实现的，Cobalt Strike 也有相关插件对流量进行加密。 v2ray协议 VMess协议 VMess 协议是由 V2Ray 原创并使用于 V2Ray 的加密传输协议，如同 Shadow socks 一样为了对抗墙的深度包检测而研发的。在 V2Ray 上客户端与服务器的通信主要是通过 VMess 协议通信。 VLESS协议 VLESS 是一种无状态的轻量级数据传输协议，被定义为下一代 V2ray 数据传输协议。作者对该协议的愿景是“可扩展性空前，适合随意组合、全场景广泛使用，符合很多人的设想、几乎所有人的需求，足以成为 v2ray 的下一代主要协议，乃至整个 XX 界的终极协议。”，由此可见 VLESS 协议的强大。 注意 VLESS 命名源自“less is more”，写法与 VMess 近似 VLESS和VMESS区别如下： VLESS协议不依赖于系统时间，不使用 alterId 。一些人的 V2ray 用不了，最后找出原因是电脑时间和服务器只相差两分钟，简直要让人抓狂；VLESS 协议去掉了时间要求，双手举赞； VLESS 协议不带加密，用于科学上网时要配合TLS等加密手段； VLESS 协议支持分流和回落，比 Nginx 分流转发更简洁、高效和安全； 使用TLS的情况下，VLESS 协议比 VMESS 速度更快，性能更好，因为 VLESS 不会对数据进行加解密； V2ray 官方对 VLESS 的期望更高，约束也更严格。例如要求客户端统一使用 VLESS 标识，而不是 Vless 、vless 等名称；VLESS 分享链接标准将由官方统一制定（尚未出炉）； VLESS 协议的加密更灵活，不像 VMESS 一样高度耦合（仅对开发者有用） 对于普通用户来说，VLESS 协议的主要优势是：1. 不需要客户端和服务器时间一致； 2. VLESS 协议不自带加密，使用 TLS 的情况下性能比 VMESS 更好。 XTLS协议 XTLS官方库 的介绍仅有一句话：THE FUTURE。V2fly 官网（V2fly 社区是 V2ray 技术的主要推动力量） 称 XTLS为黑科技，VLESS协议作者的形容是：划时代的革命性概念和技术。 XTLS 的原理是：使用 TLS 代理时，https 数据其实经过了两层 TLS：外层是代理的 TLS，内层是 https 的 TLS。XTLS 无缝拼接了内外两条货真价实的 TLS，使得代理几乎无需再对 https 流量进行数据加解密，只起到流量中转的作用，极大的提高了性能。 VLESS + XTLS 的组合可以理解为是增强版 ECH，即多支持身份认证、代理转发、明文加密、UDP over TCP 等。但从其原理可知，VLESS + XTLS对http流量是没有多大优势的。好消息是，目前超过 90% 的流量都是 https 的，因此 VLESS + XTLS 能极大的提升性能，无愧于上面的评价。 注意 需要说明的是，XTLS 是科学上网的 future ，不是 TLS 发展的 future。 Trojan协议 Trojan 协议简单来说是通过 TLS 协议（安全传输层协议）伪装成访问 HTTPS（超文本传输协议）的正常流量。由于 TLS 是一个完整的加密协议通过目前的任何技术手段都无法得到其加密内容，所以 Trojan 的安全性可见一斑。但目前 Trojan 还属于是一个新兴的技术，在各方面都存在问题，但其有着最值得期待的未来，我们需要做的是给予其时间，让其成长。 在安全性方面，GFW 的主动嗅探主要是其接入目标服务器进行数据检测，而 Trojan 和其他协议不同，当 GFW 接入时不会主动断开介入服务，而是会将接入点连接到一个常规的 web 服务器。这个时候 GWF 就会以为这个服务器是一个常规服务器，从而做出错误的判断。当然，如果是人工来检测，进行了精密的流量分析的话 Trojan 也无能为力。 找 GFW 的 BUG 这个比较少，就是寻找 GFW 的漏洞，然后依次为突破点来翻墙，这里我也没怎么了解，不做展开。 注意 最后，如果你有任何想法，欢迎来评论区告诉我！ ","date":"2022-01-02","objectID":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/:4:2","tags":["翻墙"],"title":"浅析翻墙","uri":"/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/"},{"categories":["计算机网络"],"content":"本文讲解了如何使用python实现TCP通信，并以此为基础，搭建了一个简单的TCP通信网络聊天室。","date":"2022-01-02","objectID":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/","tags":["python","Socket"],"title":"TCP通信Python实现","uri":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/"},{"categories":["计算机网络"],"content":"Socket网络编程详解 本部分内容在此不做详细讲解，具体请看这篇文章 ","date":"2022-01-02","objectID":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/:1:0","tags":["python","Socket"],"title":"TCP通信Python实现","uri":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/"},{"categories":["计算机网络"],"content":"简单的TCP通信代码详解 ","date":"2022-01-02","objectID":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/:2:0","tags":["python","Socket"],"title":"TCP通信Python实现","uri":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/"},{"categories":["计算机网络"],"content":"Server ","date":"2022-01-02","objectID":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/:2:1","tags":["python","Socket"],"title":"TCP通信Python实现","uri":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/"},{"categories":["计算机网络"],"content":"Client ","date":"2022-01-02","objectID":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/:2:2","tags":["python","Socket"],"title":"TCP通信Python实现","uri":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/"},{"categories":["计算机网络"],"content":"TCP网络通信室代码详解","date":"2022-01-02","objectID":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/:3:0","tags":["python","Socket"],"title":"TCP通信Python实现","uri":"/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/"},{"categories":null,"content":"博主相关情况 电科在读学子，软工专业 兴趣爱好： 游戏（PC、手游） 热爱技术 看剧（不多） 主要研究方向：运维 联系方式： email :1477264431@qq.com csdn :https://blog.csdn.net/sk14772 GitHub :https://github.com/14772 ","date":"2022-01-02","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"创建博客目的 创建本博客主要用于记录学习过程，并防止后面学着学着忘了以前学的内容 ","date":"2022-01-02","objectID":"/about/:1:1","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"本站相关情况 hugo v0.91.2-1798BD3F+extended windows/amd64 BuildDate=2021-12-23T15:33:34Z VendorInfo=gohugoio LoveIt: v0.2.10 ","date":"2022-01-02","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":["web"],"content":"本文利用 Nginx 和 docker 进行网站部署，实现一个简单的公网 HTTPS 访问，并添加了基于 docker 容器集群的负载均衡功能。","date":"2022-01-02","objectID":"/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/","tags":["Nginx"],"title":"简易建站","uri":"/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/"},{"categories":["web"],"content":"快速建站 公网访问 docker部署 SSL证书部署 负载均衡 买好一个 VPS ，拿到 ip 地址和管理员密码，ssh 登录上去 这里采用 docker 部署，首先利用官方脚本安装 docker 并设置开机自启动 curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo systemctl enable docker 然后启动 Nginx 镜像的容器，把宿主机8080，8443端口转发到容器的80，443端口 docker run -dit --name web -p 8080:80 -p 8443:443 nginx 然后访问一下ip:8080能看到Nginx欢迎界面 现在进入容器进行配置，首先是安装 vim ，然后写一个简单的网页文件 docker exec -it web bash apt update apt install vim cd /etc/nginx/conf.d vim default.conf 然后修改Nginx配置文件中的 root 位置，修改 server_name 为你要绑定的域名，再重启 Nginx 服务（nginx 配置文件详解见文末） nginx -s reload 这一步完成后就可以看见你写的网页了 这里考虑到只有一台服务器，因此我的负载均衡思路是搭建Nginx集群，把刚刚写的配置文件和网页文件拷贝到每一个容器中，配置负载均衡，让其中一个容器成为主服务器 现在要做的就是把配置文件和网页文件拷贝到宿主机中。(这里我登录的 root 用户，所以拷贝到了 root 目录下)然后再映射这两个文件夹到新创建的Nginx集群的每个容器中去。 docker cp web:/etc/nginx ~/conf docker cp web:/var/www/html ~/html docker run -d -it -p 8081:80 -p 8444:443 --name web1 -v ~/conf:/etc/nginx -v ~/html:/var/www/html nginx docker run -d -it -p 8082:80 -p 8445:443 --name web2 -v ~/conf:/etc/nginx -v ~/html:/var/www/html nginx 这里以web容器为主服务器，首先查看他们的ip地址，然后编辑web的Nginx配置文件（这里顺手把原来的web容器删除，以映射的方式重建了一下，这样就能直接编辑宿主机中的文件就能编辑到映射到容器中的文件） docker network ls docker network inspect f1c912c35ca8 现在就能根据得到的ip地址编辑web容器的default.conf文件 upstream 172.17.0.2 { server 172.17.0.3 weight=1; server 172.17.0.4 weight=2; } server { listen 80; listen 443 ssl; server_name sukunblog.cn sukunblog.cn 172.17.0.2; ssl_certificate /etc/nginx/sukunblog.cn.pem; ssl_certificate_key /etc/nginx/sukunblog.cn.key; ssl_session_timeout 10m; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES128-GCMSHA256: ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_prefer_server_ciphers on; client_max_body_size 1024m; location / { root /var/www/html; index Hello.html; proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.17.0.2; } } ","date":"2022-01-02","objectID":"/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/:1:0","tags":["Nginx"],"title":"简易建站","uri":"/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/"},{"categories":["web"],"content":"Nginx 配置文件详解 ######Nginx配置文件nginx.conf中文详解##### #定义Nginx运行的用户和用户组 user www www; #nginx进程数，建议设置为等于CPU总核心数。 worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] error_log /usr/local/nginx/logs/error.log info; #进程pid文件 pid /usr/local/nginx/logs/nginx.pid; #指定进程可以打开的最大描述符：数目 #工作模式与连接数上限 #这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 #现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。 #这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 worker_rlimit_nofile 65535; events { #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on; } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_leve","date":"2022-01-02","objectID":"/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/:2:0","tags":["Nginx"],"title":"简易建站","uri":"/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/"}]